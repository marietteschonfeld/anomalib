/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  1.00it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  1.00it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.29it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.29it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.32it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.32it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.32it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.32it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.33it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.33it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.33it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.33it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.33it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.33it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.34it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.34it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.34it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.34it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.34it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.34it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.34it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.34it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.34it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.34it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.34it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.34it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.90it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.86it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.82it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.86it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.89it/s][A
Detected KeyboardInterrupt, attempting graceful shutdown ...
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.37it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.37it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.37it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.37it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.37it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.37it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.38it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.38it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.38it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.38it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.38it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.89it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.85it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.81it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.85it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.87it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.89it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.91it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:52<00:00,  0.08it/s, pixel_AUPRO=0.935]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:52<00:00,  0.08it/s, pixel_AUPRO=0.935]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [06:30<00:00,  0.07it/s, pixel_AUPRO=0.935]INFO:anomalib.callbacks.timer:Training took 391.85 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:38,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:32,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:40<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 487.41269063949585 seconds
Throughput (batch_size=32) : 0.41032989875088344 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [08:05<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8519001007080078     â”‚
â”‚        pixel_AUPRO        â”‚     0.943231463432312     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.30it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.30it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.33it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.33it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.33it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.33it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.33it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.33it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.33it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.33it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.34it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.34it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.34it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.34it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.34it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.34it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.34it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.34it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.34it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.34it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.34it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.34it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.34it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.34it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.34it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.34it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.34it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.34it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.34it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.34it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.35it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.35it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.35it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.35it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.35it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.35it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.35it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.35it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.35it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.35it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.88it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.80it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.76it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.81it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.84it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.86it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.88it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:09<00:00,  0.07it/s, pixel_AUPRO=0.947]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:09<00:00,  0.07it/s, pixel_AUPRO=0.947]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:47<00:00,  0.06it/s, pixel_AUPRO=0.947]INFO:anomalib.callbacks.timer:Training took 468.34 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:38,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:19,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:40<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 491.2535524368286 seconds
Throughput (batch_size=32) : 0.4071217378641113 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [08:09<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.882099986076355     â”‚
â”‚        pixel_AUPRO        â”‚    0.9468481540679932     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.00it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.22it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.22it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.22it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.22it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.22it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.22it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.23it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.23it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.25it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.25it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.26it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.26it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.29it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.29it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.29it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.30it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.30it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.30it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.30it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.30it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.30it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.31it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.31it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.31it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.31it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.31it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.31it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.31it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.31it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.31it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.31it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.31it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.31it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.31it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.31it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.31it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.31it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.32it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.32it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.32it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.32it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.32it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.32it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.36it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.87it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.83it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.77it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.82it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.84it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.86it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.88it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:11<00:00,  0.07it/s, pixel_AUPRO=0.942]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:11<00:00,  0.07it/s, pixel_AUPRO=0.942]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:50<00:00,  0.06it/s, pixel_AUPRO=0.942]INFO:anomalib.callbacks.timer:Training took 471.13 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:40,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:32,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:19,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:32<00:12,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:38<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:41<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 477.78524351119995 seconds
Throughput (batch_size=32) : 0.41859811016811305 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [07:56<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8737000226974487     â”‚
â”‚        pixel_AUPRO        â”‚    0.9417703151702881     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.37it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.37it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:15,  1.38it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:15,  1.38it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.38it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.38it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.38it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.38it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.37it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.37it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.37it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.37it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.37it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.37it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.88it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.84it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.81it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.84it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.87it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.88it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.90it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:13<00:00,  0.07it/s, pixel_AUPRO=0.947]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:13<00:00,  0.07it/s, pixel_AUPRO=0.947]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:51<00:00,  0.06it/s, pixel_AUPRO=0.947]INFO:anomalib.callbacks.timer:Training took 472.64 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:38,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:30<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:36<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 492.77712893486023 seconds
Throughput (batch_size=32) : 0.40586299212445354 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [08:11<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.909600019454956     â”‚
â”‚        pixel_AUPRO        â”‚    0.9472154974937439     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.30it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.30it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.34it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.34it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.34it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.35it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.35it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.35it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.35it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.35it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.35it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.35it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.35it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.35it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.35it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.35it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.35it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.35it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.35it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.39it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.39it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.96it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.87it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.82it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.87it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.91it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.93it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.95it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:11<00:00,  0.07it/s, pixel_AUPRO=0.946]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:11<00:00,  0.07it/s, pixel_AUPRO=0.946]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:50<00:00,  0.06it/s, pixel_AUPRO=0.946]INFO:anomalib.callbacks.timer:Training took 471.60 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:41,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:33,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 479.0321044921875 seconds
Throughput (batch_size=32) : 0.41750855135694104 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [07:57<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9228000044822693     â”‚
â”‚        pixel_AUPRO        â”‚    0.9456433653831482     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.37it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.37it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.37it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.37it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.37it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.37it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.38it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.38it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.38it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.38it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.38it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.38it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:07<00:13,  1.38it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:07<00:13,  1.38it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.38it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.38it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.38it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.38it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.38it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.38it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.38it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.38it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.38it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.38it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.38it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:09,  0.64it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:07,  0.65it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.66it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.66it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:07<00:03,  0.67it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:08<00:01,  0.67it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:10<00:00,  0.67it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:18<00:00,  0.07it/s, pixel_AUPRO=0.953]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:18<00:00,  0.07it/s, pixel_AUPRO=0.953]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:56<00:00,  0.06it/s, pixel_AUPRO=0.953]INFO:anomalib.callbacks.timer:Training took 477.05 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:41,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:33,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:20<00:26,  0.15it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:26<00:20,  0.15it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:33<00:13,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:40<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:42<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 484.18067622184753 seconds
Throughput (batch_size=32) : 0.41306894269436245 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [08:02<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.933899998664856     â”‚
â”‚        pixel_AUPRO        â”‚     0.952895998954773     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa capsules with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/17 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.95it/s]Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.95it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:12,  1.22it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:12,  1.22it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.24it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.24it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.25it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.25it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.25it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.25it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.26it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.26it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.26it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:07,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:07<00:06,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:07<00:06,  1.26it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.26it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.26it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.26it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.26it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.26it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:10<00:03,  1.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:10<00:03,  1.26it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:11<00:02,  1.27it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:11<00:02,  1.27it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.27it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.27it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.27it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.27it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.27it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.27it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.14it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.91it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.82it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.88it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.93it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:57<00:00,  0.29it/s, pixel_AUPRO=nan.0]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:57<00:00,  0.29it/s, pixel_AUPRO=nan.0]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:25<00:00,  0.20it/s, pixel_AUPRO=nan.0]INFO:anomalib.callbacks.timer:Training took 86.39 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.17it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17<00:11,  0.18it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 125.48399806022644 seconds
Throughput (batch_size=32) : 1.2750629759438132 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:03<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6308333277702332     â”‚
â”‚        pixel_AUPRO        â”‚    0.6663526296615601     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa capsules with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/17 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.97it/s]Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.97it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:12,  1.16it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:12,  1.16it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:12,  1.13it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:12,  1.13it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:11,  1.11it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:11,  1.11it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:04<00:10,  1.12it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:04<00:10,  1.12it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:05<00:09,  1.14it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:05<00:09,  1.14it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:06<00:08,  1.16it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:06<00:08,  1.16it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:07,  1.17it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:07,  1.17it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:07<00:06,  1.18it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:07<00:06,  1.18it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:08<00:05,  1.19it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:08<00:05,  1.19it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:09<00:04,  1.20it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:09<00:04,  1.20it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:04,  1.21it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:04,  1.21it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:10<00:03,  1.22it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:10<00:03,  1.22it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:11<00:02,  1.22it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:11<00:02,  1.22it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:12<00:01,  1.23it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:12<00:01,  1.22it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:13<00:00,  1.23it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:13<00:00,  1.23it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.24it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.24it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.17it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.93it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.85it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.91it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.97it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:17<00:00,  0.22it/s, pixel_AUPRO=nan.0]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:17<00:00,  0.22it/s, pixel_AUPRO=nan.0]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:49<00:00,  0.16it/s, pixel_AUPRO=nan.0]INFO:anomalib.callbacks.timer:Training took 110.01 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.17it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17<00:11,  0.17it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 125.03853988647461 seconds
Throughput (batch_size=32) : 1.2796054732026438 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:03<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6192499995231628     â”‚
â”‚        pixel_AUPRO        â”‚    0.5750835537910461     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa capsules with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/17 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.98it/s]Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.98it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.27it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.27it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:10,  1.28it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:10,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.29it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.29it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.29it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.29it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.30it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:06,  1.31it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:06,  1.31it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:06<00:06,  1.31it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:06<00:06,  1.31it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.31it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.31it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.31it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.31it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.31it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.31it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:09<00:03,  1.31it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:09<00:03,  1.31it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:10<00:02,  1.31it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:10<00:02,  1.31it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.31it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.31it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.32it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.32it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:12<00:00,  1.32it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:12<00:00,  1.32it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.16it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.95it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.85it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.92it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.98it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:19<00:00,  0.22it/s, pixel_AUPRO=0.406]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:19<00:00,  0.22it/s, pixel_AUPRO=0.406]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:46<00:00,  0.16it/s, pixel_AUPRO=0.406]INFO:anomalib.callbacks.timer:Training took 107.03 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.18it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:11,  0.18it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 125.48413872718811 seconds
Throughput (batch_size=32) : 1.2750615466059176 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:03<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6296666860580444     â”‚
â”‚        pixel_AUPRO        â”‚    0.5842023491859436     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa capsules with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/17 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.95it/s]Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.95it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:12,  1.18it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:12,  1.18it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:12,  1.15it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:12,  1.15it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:11,  1.14it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:11,  1.14it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:04<00:10,  1.12it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:04<00:10,  1.12it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:05<00:09,  1.12it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:05<00:09,  1.12it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:06<00:08,  1.12it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:06<00:08,  1.12it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:07<00:08,  1.11it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:07<00:08,  1.11it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:08<00:07,  1.11it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:08<00:07,  1.11it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:08<00:06,  1.13it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:08<00:06,  1.13it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:09<00:05,  1.14it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:09<00:05,  1.14it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:10<00:04,  1.15it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:10<00:04,  1.15it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:11<00:03,  1.16it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:11<00:03,  1.16it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:12<00:02,  1.15it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:12<00:02,  1.15it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:13<00:01,  1.14it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:13<00:01,  1.14it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:13<00:00,  1.14it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:13<00:00,  1.14it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:14<00:00,  1.16it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:14<00:00,  1.16it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.16it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.92it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.82it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.87it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.91it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:21<00:00,  0.21it/s, pixel_AUPRO=0.402]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:21<00:00,  0.21it/s, pixel_AUPRO=0.402]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:48<00:00,  0.16it/s, pixel_AUPRO=0.402]INFO:anomalib.callbacks.timer:Training took 109.63 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:22,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.17it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17<00:11,  0.17it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 124.85121726989746 seconds
Throughput (batch_size=32) : 1.2815253507230095 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:03<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.5809999704360962     â”‚
â”‚        pixel_AUPRO        â”‚    0.5645555853843689     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa capsules with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/17 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.99it/s]Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.99it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.25it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.25it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.27it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.28it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.28it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.28it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.29it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.29it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:06,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:06,  1.30it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:06<00:06,  1.30it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:06<00:06,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.30it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.30it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.30it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.30it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:09<00:03,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:09<00:03,  1.30it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:10<00:02,  1.30it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:10<00:02,  1.30it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.30it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:12<00:00,  1.31it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:12<00:00,  1.31it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.32it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.98it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.87it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.93it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.98it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:20<00:00,  0.21it/s, pixel_AUPRO=0.573]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:20<00:00,  0.21it/s, pixel_AUPRO=0.573]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:48<00:00,  0.16it/s, pixel_AUPRO=0.573]INFO:anomalib.callbacks.timer:Training took 109.02 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.17it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:11,  0.18it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 127.57454800605774 seconds
Throughput (batch_size=32) : 1.2541686606046416 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:06<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6444999575614929     â”‚
â”‚        pixel_AUPRO        â”‚    0.6352010369300842     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa capsules with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/17 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.98it/s]Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.98it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.25it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.25it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.27it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.28it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.29it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:03<00:09,  1.29it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.29it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:08,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:05<00:07,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:06,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:06,  1.30it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:06<00:06,  1.30it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:06<00:06,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:07<00:05,  1.30it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.30it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:08<00:04,  1.30it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.30it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:09<00:03,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:09<00:03,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:09<00:03,  1.30it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:10<00:02,  1.30it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:10<00:02,  1.30it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.30it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:11<00:01,  1.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:12<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:12<00:00,  1.31it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:12<00:00,  1.31it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.88it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.81it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.77it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.81it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.83it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:28<00:00,  0.19it/s, pixel_AUPRO=0.702]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:28<00:00,  0.19it/s, pixel_AUPRO=0.702]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:55<00:00,  0.15it/s, pixel_AUPRO=0.702]INFO:anomalib.callbacks.timer:Training took 116.55 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 136.61621952056885 seconds
Throughput (batch_size=32) : 1.1711640137715165 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:14<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6696667075157166     â”‚
â”‚        pixel_AUPRO        â”‚    0.7047271132469177     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa cashew with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.96it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.96it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.22it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.22it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.24it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.24it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.25it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.25it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.25it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.25it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.25it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.25it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.25it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.26it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.26it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.35it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.35it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.87it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.82it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.76it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.80it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  0.83it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:22<00:00,  0.18it/s, pixel_AUPRO=0.638]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:22<00:00,  0.18it/s, pixel_AUPRO=0.638]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:55<00:00,  0.13it/s, pixel_AUPRO=0.638]INFO:anomalib.callbacks.timer:Training took 116.80 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:26,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 191.4469919204712 seconds
Throughput (batch_size=32) : 0.7835066954842067 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:09<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.767799973487854     â”‚
â”‚        pixel_AUPRO        â”‚    0.8231343626976013     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa cashew with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:15,  0.92it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:15,  0.92it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:11,  1.16it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:11,  1.16it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:10,  1.15it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:10,  1.15it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:09,  1.12it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:09,  1.12it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:09,  1.10it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:09,  1.10it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:05<00:08,  1.10it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:05<00:08,  1.10it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:06<00:07,  1.12it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:06<00:07,  1.12it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:07<00:06,  1.13it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:07<00:06,  1.13it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:05,  1.14it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:05,  1.13it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.14it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.14it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:09<00:03,  1.15it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:09<00:03,  1.15it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:10<00:02,  1.15it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:10<00:02,  1.15it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:11<00:01,  1.16it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:11<00:01,  1.16it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:12<00:00,  1.17it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:12<00:00,  1.17it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:12<00:00,  1.24it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:12<00:00,  1.24it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.86it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.80it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.76it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.80it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  0.82it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:18<00:00,  0.11it/s, pixel_AUPRO=0.871]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:18<00:00,  0.11it/s, pixel_AUPRO=0.871]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:56<00:00,  0.08it/s, pixel_AUPRO=0.871]INFO:anomalib.callbacks.timer:Training took 177.88 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:26,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:30<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 191.09497666358948 seconds
Throughput (batch_size=32) : 0.7849499898894017 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:09<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8040000200271606     â”‚
â”‚        pixel_AUPRO        â”‚     0.871076762676239     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa cashew with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.19it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.19it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.22it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.22it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.22it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.22it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.23it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.23it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.23it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.23it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.24it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.24it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.24it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.24it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.24it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.24it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.24it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.24it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.24it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.24it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.24it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.24it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.25it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.25it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.25it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.25it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.89it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.81it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.77it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.81it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.84it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:19<00:00,  0.11it/s, pixel_AUPRO=0.866]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:19<00:00,  0.11it/s, pixel_AUPRO=0.866]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:57<00:00,  0.08it/s, pixel_AUPRO=0.866]INFO:anomalib.callbacks.timer:Training took 178.33 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 190.58218622207642 seconds
Throughput (batch_size=32) : 0.7870620175655456 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:09<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8077999949455261     â”‚
â”‚        pixel_AUPRO        â”‚    0.8660513758659363     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa cashew with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.96it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.96it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.21it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.21it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.23it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.23it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.27it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.27it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.27it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.88it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.81it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.78it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.82it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.84it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:18<00:00,  0.11it/s, pixel_AUPRO=0.868]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:18<00:00,  0.11it/s, pixel_AUPRO=0.868]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:57<00:00,  0.08it/s, pixel_AUPRO=0.868]INFO:anomalib.callbacks.timer:Training took 178.34 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:26,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 190.84082698822021 seconds
Throughput (batch_size=32) : 0.785995336360908 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:09<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9220000505447388     â”‚
â”‚        pixel_AUPRO        â”‚    0.8680670857429504     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa cashew with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.21it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.21it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.23it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.23it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.27it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.27it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.27it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.96it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.84it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.79it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.84it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.88it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:21<00:00,  0.11it/s, pixel_AUPRO=0.884]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:21<00:00,  0.11it/s, pixel_AUPRO=0.884]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:02<00:00,  0.08it/s, pixel_AUPRO=0.884]INFO:anomalib.callbacks.timer:Training took 182.99 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 191.26061701774597 seconds
Throughput (batch_size=32) : 0.7842701876575163 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:09<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9320000410079956     â”‚
â”‚        pixel_AUPRO        â”‚    0.8837656378746033     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa cashew with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.20it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.20it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.23it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.23it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.24it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.24it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.25it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.26it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.26it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.34it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:06,  0.63it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:03<00:04,  0.65it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:03,  0.65it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:06<00:01,  0.66it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  0.66it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:25<00:00,  0.10it/s, pixel_AUPRO=0.889]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:25<00:00,  0.10it/s, pixel_AUPRO=0.889]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:03<00:00,  0.08it/s, pixel_AUPRO=0.889]INFO:anomalib.callbacks.timer:Training took 184.59 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:07<00:28,  0.14it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:20,  0.14it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:20<00:13,  0.15it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:27<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:32<00:00,  0.15it/s]INFO:anomalib.callbacks.timer:Testing took 193.19635343551636 seconds
Throughput (batch_size=32) : 0.7764121699639941 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:11<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9751999974250793     â”‚
â”‚        pixel_AUPRO        â”‚    0.8894824981689453     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa chewinggum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:02<00:37,  0.37it/s]Epoch 0:   7%|â–‹         | 1/15 [00:02<00:37,  0.37it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:05<00:33,  0.39it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:05<00:33,  0.39it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:06<00:26,  0.45it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:06<00:26,  0.45it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:08<00:22,  0.49it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:08<00:22,  0.49it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:10<00:20,  0.49it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:10<00:20,  0.49it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:11<00:17,  0.52it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:11<00:17,  0.52it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:13<00:14,  0.54it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:13<00:14,  0.54it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:15<00:13,  0.52it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:15<00:13,  0.52it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:16<00:11,  0.54it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:16<00:11,  0.54it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:17<00:08,  0.56it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:17<00:08,  0.56it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:20<00:07,  0.54it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:20<00:07,  0.54it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:21<00:05,  0.56it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:21<00:05,  0.56it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:22<00:03,  0.57it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:22<00:03,  0.57it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:24<00:01,  0.56it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:24<00:01,  0.56it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:25<00:00,  0.60it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:25<00:00,  0.60it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.97it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:03<00:05,  0.52it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:06<00:04,  0.50it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:07<00:01,  0.54it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:08<00:00,  0.56it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:08<00:00,  0.08it/s, pixel_AUPRO=nan.0]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:08<00:00,  0.08it/s, pixel_AUPRO=nan.0]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:42<00:00,  0.07it/s, pixel_AUPRO=nan.0]INFO:anomalib.callbacks.timer:Training took 223.57 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:24,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 412.5996105670929 seconds
Throughput (batch_size=32) : 0.36354857386761513 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:51<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8388000130653381     â”‚
â”‚        pixel_AUPRO        â”‚    0.6617763638496399     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa chewinggum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.98it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.98it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.26it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.26it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.29it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.26it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.26it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.25it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.25it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.27it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.35it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.35it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.89it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.85it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.75it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.81it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.85it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:48<00:00,  0.05it/s, pixel_AUPRO=0.764]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:48<00:00,  0.05it/s, pixel_AUPRO=0.764]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:22<00:00,  0.05it/s, pixel_AUPRO=0.764]INFO:anomalib.callbacks.timer:Training took 323.27 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 407.7519052028656 seconds
Throughput (batch_size=32) : 0.3678707520088022 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:46<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.885200023651123     â”‚
â”‚        pixel_AUPRO        â”‚    0.7640833854675293     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa chewinggum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.02it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.02it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.31it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.31it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.33it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.33it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.33it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.33it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.34it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.34it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.34it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.34it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.34it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.34it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.35it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.35it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.35it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.35it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.35it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.35it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.35it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.35it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.35it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.43it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.43it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.98it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.89it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.84it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.89it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.92it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:55<00:00,  0.05it/s, pixel_AUPRO=0.766]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:55<00:00,  0.05it/s, pixel_AUPRO=0.766]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:42<00:00,  0.04it/s, pixel_AUPRO=0.766]INFO:anomalib.callbacks.timer:Training took 343.18 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:26,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:20,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:13,  0.15it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 414.53968954086304 seconds
Throughput (batch_size=32) : 0.36184713740230134 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:53<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8830000162124634     â”‚
â”‚        pixel_AUPRO        â”‚    0.7660638689994812     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa chewinggum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.97it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.97it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.21it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.21it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.21it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.21it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:09,  1.21it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:09,  1.21it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.20it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.20it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.22it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.22it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.22it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.22it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.23it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.23it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.24it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.24it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.24it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.24it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.25it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.25it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.25it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.25it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.25it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.25it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.25it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.25it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.96it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.86it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.81it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.87it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.90it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:55<00:00,  0.05it/s, pixel_AUPRO=0.767]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:55<00:00,  0.05it/s, pixel_AUPRO=0.767]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:31<00:00,  0.05it/s, pixel_AUPRO=0.767]INFO:anomalib.callbacks.timer:Training took 332.49 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 398.99386858940125 seconds
Throughput (batch_size=32) : 0.3759456267593997 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:37<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9952000379562378     â”‚
â”‚        pixel_AUPRO        â”‚     0.767408013343811     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa chewinggum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.23it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.23it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.25it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.25it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.27it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.27it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.27it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.27it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.28it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.28it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.29it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.29it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.29it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.29it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.29it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.29it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.30it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.30it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.30it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.30it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.31it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.31it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.31it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.31it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.31it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.31it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.05it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.89it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.83it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.89it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.94it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:50<00:00,  0.05it/s, pixel_AUPRO=0.782]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:50<00:00,  0.05it/s, pixel_AUPRO=0.782]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:25<00:00,  0.05it/s, pixel_AUPRO=0.782]INFO:anomalib.callbacks.timer:Training took 326.03 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 412.07693362236023 seconds
Throughput (batch_size=32) : 0.3640096976101665 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:50<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.991599977016449     â”‚
â”‚        pixel_AUPRO        â”‚     0.78184974193573      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa chewinggum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.27it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.27it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.29it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.30it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.30it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.31it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.31it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.31it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.31it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.32it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.32it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.32it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.32it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.32it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.32it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.32it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.32it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.33it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.33it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.33it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.33it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.33it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.41it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.41it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:05,  0.69it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  0.71it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:02,  0.72it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.72it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  0.73it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:09<00:00,  0.05it/s, pixel_AUPRO=0.786]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:09<00:00,  0.05it/s, pixel_AUPRO=0.786]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:44<00:00,  0.04it/s, pixel_AUPRO=0.786]INFO:anomalib.callbacks.timer:Training took 345.34 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:27,  0.14it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:20,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:13,  0.15it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 408.02433347702026 seconds
Throughput (batch_size=32) : 0.36762513333888686 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:46<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9923999309539795     â”‚
â”‚        pixel_AUPRO        â”‚    0.7858366966247559     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:04<00:56,  0.25it/s]Epoch 0:   7%|â–‹         | 1/15 [00:04<00:56,  0.25it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:06<00:40,  0.32it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:06<00:40,  0.32it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:07<00:30,  0.40it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:07<00:30,  0.40it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:09<00:24,  0.44it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:09<00:24,  0.44it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:11<00:22,  0.44it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:11<00:22,  0.44it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:12<00:19,  0.47it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:12<00:19,  0.47it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:14<00:16,  0.50it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:14<00:16,  0.50it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:16<00:14,  0.48it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:16<00:14,  0.48it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:17<00:11,  0.50it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:17<00:11,  0.50it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:19<00:09,  0.52it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:19<00:09,  0.52it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:21<00:07,  0.51it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:21<00:07,  0.51it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:22<00:05,  0.52it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:22<00:05,  0.52it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:24<00:03,  0.53it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:24<00:03,  0.53it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:26<00:01,  0.53it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:26<00:01,  0.53it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:26<00:00,  0.56it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:26<00:00,  0.56it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.17it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:04<00:06,  0.49it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:06<00:04,  0.46it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:09<00:02,  0.44it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  0.50it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:12<00:00,  0.08it/s, pixel_AUPRO=0.765]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:12<00:00,  0.08it/s, pixel_AUPRO=0.765]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:40<00:00,  0.07it/s, pixel_AUPRO=0.765]INFO:anomalib.callbacks.timer:Training took 221.17 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:24,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.17it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 266.8121085166931 seconds
Throughput (batch_size=32) : 0.5621933758325486 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:25<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8046000003814697     â”‚
â”‚        pixel_AUPRO        â”‚    0.8287172913551331     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.99it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.99it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.24it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.24it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.24it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.24it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.26it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.27it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.27it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.27it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.27it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.27it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.27it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.27it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.27it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.27it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.18it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.96it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.87it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.94it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.00it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:38<00:00,  0.07it/s, pixel_AUPRO=0.801]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:38<00:00,  0.07it/s, pixel_AUPRO=0.801]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:06<00:00,  0.06it/s, pixel_AUPRO=0.801]INFO:anomalib.callbacks.timer:Training took 247.04 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.18it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:11,  0.18it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 264.25163745880127 seconds
Throughput (batch_size=32) : 0.5676407587952452 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:22<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8503999710083008     â”‚
â”‚        pixel_AUPRO        â”‚    0.8012158870697021     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.30it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.30it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.30it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.30it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.26it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.26it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.23it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.23it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.24it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.24it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.23it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.23it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.22it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.22it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.22it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.22it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.23it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.23it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.24it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.24it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.25it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.25it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.25it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.25it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.34it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.18it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.97it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.87it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.94it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.00it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:41<00:00,  0.07it/s, pixel_AUPRO=0.806]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:41<00:00,  0.07it/s, pixel_AUPRO=0.806]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:09<00:00,  0.06it/s, pixel_AUPRO=0.806]INFO:anomalib.callbacks.timer:Training took 249.98 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.17it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:11,  0.18it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 265.76020407676697 seconds
Throughput (batch_size=32) : 0.5644185912676049 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:24<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8540000319480896     â”‚
â”‚        pixel_AUPRO        â”‚    0.8060246706008911     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.98it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.98it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.25it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.25it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.27it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.27it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.28it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.28it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.29it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.29it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.30it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.31it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.31it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.31it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.31it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.31it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.31it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.31it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.31it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.31it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.31it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.31it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.31it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.31it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.31it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.31it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.31it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.14it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.94it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.85it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.92it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.98it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:42<00:00,  0.07it/s, pixel_AUPRO=0.816]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:42<00:00,  0.07it/s, pixel_AUPRO=0.816]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:10<00:00,  0.06it/s, pixel_AUPRO=0.816]INFO:anomalib.callbacks.timer:Training took 251.06 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  0.17it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:11,  0.18it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 266.10627937316895 seconds
Throughput (batch_size=32) : 0.5636845562357077 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:24<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8931999802589417     â”‚
â”‚        pixel_AUPRO        â”‚    0.8154991865158081     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.00it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.00it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.30it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.30it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.32it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.32it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:02<00:08,  1.33it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.33it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.34it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.34it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.35it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.35it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.35it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.35it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.35it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.35it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.35it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.35it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.35it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.35it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.35it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.35it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.35it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.35it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.44it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.44it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.32it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  1.00it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.88it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.94it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.02it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:48<00:00,  0.07it/s, pixel_AUPRO=0.820]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:48<00:00,  0.07it/s, pixel_AUPRO=0.820]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:16<00:00,  0.06it/s, pixel_AUPRO=0.820]INFO:anomalib.callbacks.timer:Training took 257.28 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:24,  0.17it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 262.55643248558044 seconds
Throughput (batch_size=32) : 0.5713057516053733 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:21<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8988000154495239     â”‚
â”‚        pixel_AUPRO        â”‚    0.8200944662094116     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.31it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.31it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.32it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.32it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.32it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.32it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.32it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.32it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.33it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.33it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.33it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.33it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.33it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.33it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.33it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.33it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.33it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.33it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.33it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.33it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.33it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.33it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.33it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.42it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.42it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.87it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.83it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.79it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.83it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.85it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:50<00:00,  0.07it/s, pixel_AUPRO=0.845]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:50<00:00,  0.07it/s, pixel_AUPRO=0.845]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:17<00:00,  0.06it/s, pixel_AUPRO=0.845]INFO:anomalib.callbacks.timer:Training took 258.60 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:24,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 266.6200063228607 seconds
Throughput (batch_size=32) : 0.5625984413876244 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:25<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.913599967956543     â”‚
â”‚        pixel_AUPRO        â”‚    0.8446060419082642     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:02<01:10,  0.40it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:02<01:10,  0.40it/s]Epoch 0:   7%|â–‹         | 2/29 [00:03<00:52,  0.52it/s]Epoch 0:   7%|â–‹         | 2/29 [00:03<00:52,  0.52it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:06<00:52,  0.49it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:06<00:52,  0.49it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:07<00:45,  0.55it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:07<00:45,  0.55it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:08<00:41,  0.58it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:08<00:41,  0.58it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:11<00:42,  0.54it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:11<00:42,  0.54it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:12<00:39,  0.56it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:12<00:39,  0.56it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:13<00:35,  0.59it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:13<00:35,  0.59it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:15<00:35,  0.57it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:15<00:35,  0.57it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:17<00:32,  0.58it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:17<00:32,  0.58it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:18<00:30,  0.60it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:18<00:30,  0.60it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:20<00:29,  0.58it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:20<00:29,  0.58it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:21<00:26,  0.59it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:21<00:26,  0.59it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:23<00:24,  0.61it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:23<00:24,  0.61it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:25<00:23,  0.59it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:25<00:23,  0.59it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:26<00:21,  0.60it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:26<00:21,  0.60it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:27<00:19,  0.61it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:27<00:19,  0.61it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:28<00:17,  0.62it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:28<00:17,  0.62it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:31<00:16,  0.61it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:31<00:16,  0.61it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:32<00:14,  0.62it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:32<00:14,  0.62it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:33<00:12,  0.62it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:33<00:12,  0.62it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:35<00:11,  0.61it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:35<00:11,  0.61it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:37<00:09,  0.62it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:37<00:09,  0.62it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:38<00:08,  0.62it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:38<00:08,  0.62it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:40<00:06,  0.61it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:40<00:06,  0.61it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:41<00:04,  0.62it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:41<00:04,  0.62it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:43<00:03,  0.63it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:43<00:03,  0.63it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:44<00:01,  0.63it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:44<00:01,  0.63it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:44<00:00,  0.65it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:44<00:00,  0.65it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.17it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.81it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:05<00:07,  0.57it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.60it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:09<00:03,  0.54it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:10<00:01,  0.57it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  0.62it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:42<00:00,  0.10it/s, pixel_AUPRO=0.895]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:42<00:00,  0.10it/s, pixel_AUPRO=0.895]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:10<00:00,  0.09it/s, pixel_AUPRO=0.895]INFO:anomalib.callbacks.timer:Training took 311.79 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:22<00:17,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:28<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:36<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 249.26806688308716 seconds
Throughput (batch_size=32) : 0.8023490634033156 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:07<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.698199987411499     â”‚
â”‚        pixel_AUPRO        â”‚    0.9071648120880127     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.33it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.33it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.35it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.36it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.37it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.37it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.37it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.37it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.38it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.38it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.38it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.38it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.42it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.42it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.08it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.94it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.85it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.93it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.99it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.03it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.07it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:20<00:00,  0.09it/s, pixel_AUPRO=0.890]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:20<00:00,  0.09it/s, pixel_AUPRO=0.890]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:47<00:00,  0.08it/s, pixel_AUPRO=0.890]INFO:anomalib.callbacks.timer:Training took 348.51 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:34,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:28,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 343.53928399086 seconds
Throughput (batch_size=32) : 0.5821750504822065 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:42<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7021999359130859     â”‚
â”‚        pixel_AUPRO        â”‚    0.8895091414451599     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.03it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.03it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.33it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.33it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.33it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.33it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.34it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.34it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.34it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.34it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.36it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.36it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.36it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.36it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.36it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.36it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.36it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.17it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.96it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.88it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.95it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:04<00:01,  1.01it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.05it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.09it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:26<00:00,  0.09it/s, pixel_AUPRO=0.881]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:26<00:00,  0.09it/s, pixel_AUPRO=0.881]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:54<00:00,  0.08it/s, pixel_AUPRO=0.881]INFO:anomalib.callbacks.timer:Training took 355.19 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:35,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:22,  0.18it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:22<00:16,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:28<00:11,  0.18it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:36<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 303.377876996994 seconds
Throughput (batch_size=32) : 0.6592438511987533 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:01<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6975000500679016     â”‚
â”‚        pixel_AUPRO        â”‚    0.8812823295593262     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.32it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.32it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.33it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.33it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.34it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.34it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.35it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.34it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.36it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.36it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.36it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.36it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.36it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.17it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.95it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.87it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.94it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:04<00:01,  1.00it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.05it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.08it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:28<00:00,  0.09it/s, pixel_AUPRO=0.887]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:28<00:00,  0.09it/s, pixel_AUPRO=0.887]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:56<00:00,  0.08it/s, pixel_AUPRO=0.887]INFO:anomalib.callbacks.timer:Training took 357.27 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:35,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:22,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:22<00:17,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:28<00:11,  0.18it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 331.7459456920624 seconds
Throughput (batch_size=32) : 0.60287096978013 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:30<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8499000072479248     â”‚
â”‚        pixel_AUPRO        â”‚    0.8865618109703064     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.27it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.27it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.29it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.29it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.30it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.30it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.31it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.31it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.32it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.32it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.32it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.32it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.33it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.33it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.32it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.32it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.33it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.33it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.33it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.33it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.34it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.34it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.34it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.34it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.34it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.34it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.34it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.34it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.34it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.34it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.34it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.34it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.34it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.34it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.34it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.34it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.34it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.34it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.38it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.32it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.99it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.89it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.95it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:04<00:01,  1.01it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.06it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.11it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:31<00:00,  0.09it/s, pixel_AUPRO=0.896]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:31<00:00,  0.09it/s, pixel_AUPRO=0.896]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:59<00:00,  0.08it/s, pixel_AUPRO=0.896]INFO:anomalib.callbacks.timer:Training took 360.80 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:36<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 294.35272455215454 seconds
Throughput (batch_size=32) : 0.6794569348875289 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:52<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8578499555587769     â”‚
â”‚        pixel_AUPRO        â”‚    0.8959689736366272     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.28it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.28it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.29it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.29it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.30it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.30it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.31it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.31it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.32it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.32it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.32it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.32it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.33it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.33it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.33it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.33it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.33it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.33it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.33it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.33it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.33it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.34it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.34it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.34it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.34it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.34it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.34it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.34it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.34it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.34it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.34it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.34it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.34it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.34it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.34it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.34it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.34it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.38it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.87it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.81it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.77it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.81it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.83it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:07<00:01,  0.85it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  0.86it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:36<00:00,  0.09it/s, pixel_AUPRO=0.923]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:36<00:00,  0.09it/s, pixel_AUPRO=0.923]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [06:04<00:00,  0.08it/s, pixel_AUPRO=0.923]INFO:anomalib.callbacks.timer:Training took 365.59 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:38,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 314.6107246875763 seconds
Throughput (batch_size=32) : 0.6357062372829461 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:13<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9185999631881714     â”‚
â”‚        pixel_AUPRO        â”‚    0.9227983355522156     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:04<01:59,  0.23it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:04<01:59,  0.23it/s]Epoch 0:   7%|â–‹         | 2/29 [00:05<01:12,  0.37it/s]Epoch 0:   7%|â–‹         | 2/29 [00:05<01:12,  0.37it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:07<01:06,  0.39it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:07<01:06,  0.39it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:08<00:55,  0.45it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:08<00:55,  0.45it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:10<00:49,  0.49it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:10<00:49,  0.49it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:12<00:48,  0.48it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:12<00:48,  0.48it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:13<00:43,  0.50it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:13<00:43,  0.50it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:15<00:39,  0.53it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:15<00:39,  0.53it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:17<00:39,  0.51it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:17<00:39,  0.51it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:18<00:36,  0.53it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:18<00:36,  0.53it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:20<00:33,  0.54it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:20<00:33,  0.54it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:22<00:31,  0.53it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:22<00:31,  0.53it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:23<00:29,  0.55it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:23<00:29,  0.55it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:24<00:26,  0.56it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:24<00:26,  0.56it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:26<00:24,  0.57it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:26<00:24,  0.57it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:28<00:23,  0.56it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:28<00:23,  0.56it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:29<00:21,  0.57it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:29<00:21,  0.57it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:31<00:18,  0.58it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:31<00:18,  0.58it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:33<00:17,  0.57it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:33<00:17,  0.57it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:34<00:15,  0.58it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:34<00:15,  0.58it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:36<00:13,  0.58it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:36<00:13,  0.58it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:38<00:12,  0.57it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:38<00:12,  0.57it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:39<00:10,  0.58it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:39<00:10,  0.58it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:40<00:08,  0.59it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:40<00:08,  0.59it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:43<00:06,  0.58it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:43<00:06,  0.58it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:44<00:05,  0.58it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:44<00:05,  0.58it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:45<00:03,  0.59it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:45<00:03,  0.59it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:47<00:01,  0.59it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:47<00:01,  0.59it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:48<00:00,  0.60it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:48<00:00,  0.60it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.15it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:09,  0.52it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:05<00:07,  0.51it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:08<00:06,  0.48it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:09<00:03,  0.52it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:10<00:01,  0.55it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  0.60it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:34<00:00,  0.14it/s, pixel_AUPRO=nan.0]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:34<00:00,  0.14it/s, pixel_AUPRO=nan.0]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:02<00:00,  0.12it/s, pixel_AUPRO=nan.0]INFO:anomalib.callbacks.timer:Training took 243.63 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:30<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:36<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 201.61342906951904 seconds
Throughput (batch_size=32) : 0.9919974126874123 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [03:20<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7731499671936035     â”‚
â”‚        pixel_AUPRO        â”‚    0.7501596808433533     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.29it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.29it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.30it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.30it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.31it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.30it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.31it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.31it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.32it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.32it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.32it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.32it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.32it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.32it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.33it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.33it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.33it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.33it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.33it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.33it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.33it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.38it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.13it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.90it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.80it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.87it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.93it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.98it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.02it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:13<00:00,  0.11it/s, pixel_AUPRO=0.713]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:13<00:00,  0.11it/s, pixel_AUPRO=0.713]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:41<00:00,  0.10it/s, pixel_AUPRO=0.713]INFO:anomalib.callbacks.timer:Training took 282.37 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:34,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:28,  0.18it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:16<00:22,  0.18it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:21<00:16,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:27<00:10,  0.18it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:32<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:34<00:00,  0.20it/s]INFO:anomalib.callbacks.timer:Testing took 212.79350662231445 seconds
Throughput (batch_size=32) : 0.9398783035000144 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [03:31<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7780500054359436     â”‚
â”‚        pixel_AUPRO        â”‚    0.7119712829589844     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.99it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.99it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.28it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.28it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.30it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.30it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.31it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.32it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.32it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.32it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.32it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.33it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.33it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.32it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.32it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.32it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.32it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.33it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.33it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.33it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.33it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.33it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.33it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.33it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.33it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.33it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.33it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.33it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.33it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.33it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.33it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.33it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.33it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.38it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.12it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.85it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.82it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.89it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.94it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.99it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.02it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:19<00:00,  0.11it/s, pixel_AUPRO=0.691]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:19<00:00,  0.11it/s, pixel_AUPRO=0.691]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:48<00:00,  0.10it/s, pixel_AUPRO=0.691]INFO:anomalib.callbacks.timer:Training took 289.17 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 290.95643067359924 seconds
Throughput (batch_size=32) : 0.6873881410250183 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:49<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7724000215530396     â”‚
â”‚        pixel_AUPRO        â”‚    0.6899771690368652     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.01it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.33it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.33it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.35it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.35it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.35it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.35it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.35it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.35it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.36it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.36it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.36it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.36it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.36it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.36it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.36it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.36it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.36it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.36it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.36it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.36it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.36it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.36it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.36it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.36it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.36it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.36it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.36it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.36it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.36it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.17it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.91it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.84it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.91it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.98it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.03it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.07it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:20<00:00,  0.11it/s, pixel_AUPRO=0.709]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:20<00:00,  0.11it/s, pixel_AUPRO=0.709]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:49<00:00,  0.10it/s, pixel_AUPRO=0.709]INFO:anomalib.callbacks.timer:Training took 290.30 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:34,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:28,  0.18it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:16<00:22,  0.18it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:22<00:16,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:27<00:11,  0.18it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:32<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:34<00:00,  0.20it/s]INFO:anomalib.callbacks.timer:Testing took 271.60404539108276 seconds
Throughput (batch_size=32) : 0.7363660571108944 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:30<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.696399986743927     â”‚
â”‚        pixel_AUPRO        â”‚     0.70745849609375      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.36it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.36it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.36it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.36it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.36it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.36it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.36it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.37it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.38it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.38it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.33it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:01<00:04,  1.01it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.90it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.96it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:04<00:01,  1.02it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.07it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.11it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:21<00:00,  0.11it/s, pixel_AUPRO=0.728]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:21<00:00,  0.11it/s, pixel_AUPRO=0.728]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:51<00:00,  0.10it/s, pixel_AUPRO=0.728]INFO:anomalib.callbacks.timer:Training took 292.20 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:34,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:28,  0.18it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 252.5008647441864 seconds
Throughput (batch_size=32) : 0.7920764952730912 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:11<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6553499698638916     â”‚
â”‚        pixel_AUPRO        â”‚    0.7281581163406372     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.32it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.33it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:18,  1.33it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.34it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.34it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.34it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.34it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.34it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.34it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.34it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.34it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.34it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.34it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.87it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.81it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.77it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.80it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.83it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:07<00:01,  0.84it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  0.86it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:36<00:00,  0.10it/s, pixel_AUPRO=0.825]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:36<00:00,  0.10it/s, pixel_AUPRO=0.825]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:05<00:00,  0.10it/s, pixel_AUPRO=0.825]INFO:anomalib.callbacks.timer:Training took 305.83 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:39,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:32,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 173.02186965942383 seconds
Throughput (batch_size=32) : 1.1559232390314584 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:51<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7583000063896179     â”‚
â”‚        pixel_AUPRO        â”‚    0.8003318905830383     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:05<02:43,  0.17it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:05<02:43,  0.17it/s]Epoch 0:   7%|â–‹         | 2/29 [00:08<01:49,  0.25it/s]Epoch 0:   7%|â–‹         | 2/29 [00:08<01:49,  0.25it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:09<01:23,  0.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:09<01:23,  0.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:11<01:11,  0.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:11<01:11,  0.35it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:14<01:07,  0.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:14<01:07,  0.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:15<00:59,  0.39it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:15<00:59,  0.39it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:18<00:57,  0.38it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:18<00:57,  0.38it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:19<00:52,  0.40it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:19<00:52,  0.40it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:21<00:47,  0.42it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:21<00:47,  0.42it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:24<00:46,  0.41it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:24<00:46,  0.41it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:26<00:42,  0.42it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:26<00:42,  0.42it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:28<00:40,  0.41it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:28<00:40,  0.41it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:30<00:37,  0.43it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:30<00:37,  0.43it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:32<00:35,  0.42it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:32<00:35,  0.42it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:34<00:32,  0.43it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:34<00:32,  0.43it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:36<00:29,  0.44it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:36<00:29,  0.44it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:38<00:27,  0.44it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:38<00:27,  0.44it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:40<00:24,  0.45it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:40<00:24,  0.45it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:41<00:22,  0.45it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:41<00:22,  0.45it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:44<00:20,  0.45it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:44<00:20,  0.45it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:46<00:17,  0.46it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:46<00:17,  0.46it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:48<00:15,  0.45it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:48<00:15,  0.45it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:50<00:13,  0.46it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:50<00:13,  0.46it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:51<00:10,  0.46it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:51<00:10,  0.46it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:54<00:08,  0.46it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:54<00:08,  0.46it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:55<00:06,  0.46it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:55<00:06,  0.46it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:58<00:04,  0.46it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:58<00:04,  0.46it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [01:00<00:02,  0.46it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [01:00<00:02,  0.46it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [01:00<00:00,  0.48it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [01:00<00:00,  0.48it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.02it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:08,  0.60it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:06<00:09,  0.43it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:09<00:07,  0.40it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:11<00:04,  0.44it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:12<00:02,  0.47it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  0.52it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:42<00:00,  0.13it/s, pixel_AUPRO=0.624]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:42<00:00,  0.13it/s, pixel_AUPRO=0.624]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:14<00:00,  0.11it/s, pixel_AUPRO=0.624]INFO:anomalib.callbacks.timer:Training took 255.02 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:30<00:12,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 346.82980132102966 seconds
Throughput (batch_size=32) : 0.5766517157355739 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:45<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.819350004196167     â”‚
â”‚        pixel_AUPRO        â”‚    0.8739853501319885     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.96it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.96it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.20it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.20it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.21it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.21it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.20it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.20it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:20,  1.19it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:20,  1.19it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.19it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.19it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.19it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.19it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.18it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.18it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.18it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.18it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:16,  1.18it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:16,  1.18it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:09<00:15,  1.19it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:09<00:15,  1.19it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:10<00:14,  1.19it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:10<00:14,  1.19it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.19it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.19it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.19it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.19it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.19it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.19it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:13<00:10,  1.20it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:13<00:10,  1.20it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:14<00:09,  1.20it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:14<00:09,  1.20it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:09,  1.20it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:09,  1.20it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.21it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.21it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.21it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.21it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:17<00:06,  1.21it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:17<00:06,  1.21it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:18<00:05,  1.21it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:18<00:05,  1.21it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.22it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.22it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:04,  1.22it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:04,  1.22it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:20<00:03,  1.22it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:20<00:03,  1.22it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:21<00:02,  1.22it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:21<00:02,  1.22it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:22<00:01,  1.22it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:22<00:01,  1.22it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.22it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.22it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:23<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:23<00:00,  1.26it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.03it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.89it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.81it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.88it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.92it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.96it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.99it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:26<00:00,  0.11it/s, pixel_AUPRO=0.858]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:26<00:00,  0.11it/s, pixel_AUPRO=0.858]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:59<00:00,  0.10it/s, pixel_AUPRO=0.858]INFO:anomalib.callbacks.timer:Training took 300.00 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 354.18423438072205 seconds
Throughput (batch_size=32) : 0.5646778726605168 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:52<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8240500092506409     â”‚
â”‚        pixel_AUPRO        â”‚    0.8577393293380737     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.25it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.25it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.27it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.29it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.29it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.30it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.30it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.30it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.30it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.31it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.31it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.30it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.31it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.31it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.31it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.31it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.31it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.31it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.31it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.31it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.31it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.31it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.31it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.31it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.31it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.31it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.32it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.32it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.32it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.32it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.32it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.32it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.32it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.32it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.32it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.32it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:03,  1.32it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:03,  1.32it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.32it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.32it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.32it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.32it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.33it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.36it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.04it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.90it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.83it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.90it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.94it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.98it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.00it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:24<00:00,  0.11it/s, pixel_AUPRO=0.866]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:24<00:00,  0.11it/s, pixel_AUPRO=0.866]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:56<00:00,  0.10it/s, pixel_AUPRO=0.866]INFO:anomalib.callbacks.timer:Training took 297.75 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 352.4707136154175 seconds
Throughput (batch_size=32) : 0.5674230291320628 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:50<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.813800036907196     â”‚
â”‚        pixel_AUPRO        â”‚    0.8660359978675842     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.27it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.28it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.28it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.28it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.05it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.91it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.84it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.91it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.95it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.99it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.01it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:28<00:00,  0.11it/s, pixel_AUPRO=0.847]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:28<00:00,  0.11it/s, pixel_AUPRO=0.847]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:01<00:00,  0.10it/s, pixel_AUPRO=0.847]INFO:anomalib.callbacks.timer:Training took 302.18 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 348.05731773376465 seconds
Throughput (batch_size=32) : 0.5746180005701924 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:46<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9143000245094299     â”‚
â”‚        pixel_AUPRO        â”‚    0.8469929099082947     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.97it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.97it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.24it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.24it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.28it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.28it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.28it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.32it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.32it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.21it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.94it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.81it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.85it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.88it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.91it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.96it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:26<00:00,  0.11it/s, pixel_AUPRO=0.851]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:26<00:00,  0.11it/s, pixel_AUPRO=0.851]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:58<00:00,  0.10it/s, pixel_AUPRO=0.851]INFO:anomalib.callbacks.timer:Training took 299.75 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:30<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:36<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 348.8945984840393 seconds
Throughput (batch_size=32) : 0.5732390265398428 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:47<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9171000123023987     â”‚
â”‚        pixel_AUPRO        â”‚    0.8510738611221313     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.99it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.99it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.25it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.25it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.22it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.22it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:20,  1.19it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:20,  1.19it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.17it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.17it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:06<00:19,  1.15it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:06<00:19,  1.15it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:18,  1.16it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:18,  1.16it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:17,  1.17it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:17,  1.17it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:16,  1.18it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:16,  1.18it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:09<00:15,  1.19it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:09<00:15,  1.19it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:10<00:14,  1.19it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:10<00:14,  1.19it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.20it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.20it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.20it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.20it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.20it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.20it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:13<00:10,  1.21it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:13<00:10,  1.21it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:14<00:09,  1.21it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:14<00:09,  1.21it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:09,  1.21it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:09,  1.21it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.21it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.21it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.22it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.22it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:17<00:06,  1.22it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:17<00:06,  1.22it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:18<00:05,  1.22it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:18<00:05,  1.22it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.22it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.22it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:04,  1.22it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:04,  1.22it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:20<00:03,  1.23it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:20<00:03,  1.23it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:21<00:02,  1.23it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:21<00:02,  1.23it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.23it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.23it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.23it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.23it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.26it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:07,  0.76it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.77it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.75it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:03,  0.77it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.78it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:07<00:01,  0.78it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  0.79it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:30<00:00,  0.11it/s, pixel_AUPRO=0.891]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:30<00:00,  0.11it/s, pixel_AUPRO=0.891]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:03<00:00,  0.10it/s, pixel_AUPRO=0.891]INFO:anomalib.callbacks.timer:Training took 303.98 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:39,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:32,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:40<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 350.694296836853 seconds
Throughput (batch_size=32) : 0.5702972697415786 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:49<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.947100043296814     â”‚
â”‚        pixel_AUPRO        â”‚    0.8905647993087769     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:03<01:41,  0.28it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:03<01:41,  0.28it/s]Epoch 0:   7%|â–‹         | 2/29 [00:06<01:23,  0.32it/s]Epoch 0:   7%|â–‹         | 2/29 [00:06<01:23,  0.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:07<01:06,  0.39it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:07<01:06,  0.39it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:10<01:05,  0.38it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:10<01:05,  0.38it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:12<00:57,  0.42it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:12<00:57,  0.42it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:13<00:52,  0.44it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:13<00:52,  0.44it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:16<00:50,  0.44it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:16<00:50,  0.44it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:17<00:46,  0.46it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:17<00:46,  0.46it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:18<00:42,  0.47it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:18<00:42,  0.47it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:21<00:41,  0.46it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:21<00:41,  0.46it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:23<00:37,  0.48it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:23<00:37,  0.48it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:25<00:36,  0.47it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:25<00:36,  0.47it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:27<00:33,  0.48it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:27<00:33,  0.48it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:28<00:30,  0.49it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:28<00:30,  0.49it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:31<00:29,  0.48it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:31<00:29,  0.48it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:32<00:26,  0.49it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:32<00:26,  0.49it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:34<00:24,  0.50it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:34<00:24,  0.50it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:36<00:22,  0.49it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:36<00:22,  0.49it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:38<00:20,  0.50it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:38<00:20,  0.50it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:40<00:18,  0.49it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:40<00:18,  0.49it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:42<00:16,  0.50it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:42<00:16,  0.50it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:43<00:13,  0.50it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:43<00:13,  0.50it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:46<00:12,  0.50it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:46<00:12,  0.50it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:47<00:09,  0.50it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:47<00:09,  0.50it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:49<00:07,  0.51it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:49<00:07,  0.51it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:51<00:05,  0.50it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:51<00:05,  0.50it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:53<00:03,  0.51it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:53<00:03,  0.51it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:55<00:01,  0.51it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:55<00:01,  0.51it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:56<00:00,  0.52it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:56<00:00,  0.52it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.01it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:04<00:10,  0.48it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:06<00:08,  0.46it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:09<00:06,  0.43it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:10<00:04,  0.47it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:11<00:01,  0.50it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  0.53it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:54<00:00,  0.12it/s, pixel_AUPRO=0.671]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:54<00:00,  0.12it/s, pixel_AUPRO=0.671]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:27<00:00,  0.11it/s, pixel_AUPRO=0.671]INFO:anomalib.callbacks.timer:Training took 268.01 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:36<00:06,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 389.652095079422 seconds
Throughput (batch_size=32) : 0.513278389942275 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [06:28<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.733199954032898     â”‚
â”‚        pixel_AUPRO        â”‚     0.883690595626831     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.23it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.23it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.24it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.24it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.25it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.25it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.25it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.25it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.25it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.25it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.25it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.25it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.25it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.25it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.25it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.25it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.25it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.25it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.26it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.26it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.26it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.26it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:11,  1.26it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:11,  1.26it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.26it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.26it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.26it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.26it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.26it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.26it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:07,  1.26it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:07,  1.26it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.26it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.26it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.26it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.26it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.26it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.26it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.26it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.26it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.26it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.26it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.26it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.26it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.26it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.30it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.03it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.86it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.79it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.84it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.90it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.93it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.96it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:53<00:00,  0.10it/s, pixel_AUPRO=0.870]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:53<00:00,  0.10it/s, pixel_AUPRO=0.870]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:26<00:00,  0.09it/s, pixel_AUPRO=0.870]INFO:anomalib.callbacks.timer:Training took 327.89 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:36<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 383.0699577331543 seconds
Throughput (batch_size=32) : 0.5220978465226437 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [06:21<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7976000308990479     â”‚
â”‚        pixel_AUPRO        â”‚    0.8699078559875488     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.96it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.96it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.23it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.23it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.20it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.20it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:20,  1.20it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:20,  1.20it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.19it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.19it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.19it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.19it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.20it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.20it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.20it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.20it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.21it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.21it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:09<00:14,  1.21it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:09<00:14,  1.21it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:14,  1.21it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:14,  1.21it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.22it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.22it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.22it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.22it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.22it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.22it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:13<00:10,  1.23it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:13<00:10,  1.23it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.23it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.23it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.24it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.24it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.24it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.24it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.24it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.24it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.24it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.24it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.25it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.25it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.25it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.25it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.25it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.25it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.25it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.25it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.25it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.25it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.25it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.25it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.25it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.25it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.29it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.03it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.82it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.78it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.85it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.90it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.93it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.96it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:58<00:00,  0.10it/s, pixel_AUPRO=0.874]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:58<00:00,  0.10it/s, pixel_AUPRO=0.874]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:30<00:00,  0.09it/s, pixel_AUPRO=0.874]INFO:anomalib.callbacks.timer:Training took 331.35 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 390.75928235054016 seconds
Throughput (batch_size=32) : 0.5118240539212198 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [06:29<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8048999905586243     â”‚
â”‚        pixel_AUPRO        â”‚    0.8740521669387817     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.25it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.25it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.34it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.04it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.90it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.84it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.90it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.95it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.98it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.01it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:55<00:00,  0.10it/s, pixel_AUPRO=0.874]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:55<00:00,  0.10it/s, pixel_AUPRO=0.874]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:28<00:00,  0.09it/s, pixel_AUPRO=0.874]INFO:anomalib.callbacks.timer:Training took 329.45 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 387.09007930755615 seconds
Throughput (batch_size=32) : 0.5166756026343244 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [06:25<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9451999664306641     â”‚
â”‚        pixel_AUPRO        â”‚    0.8743008971214294     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.97it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.97it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.26it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.26it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.25it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.25it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.26it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.26it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.26it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.26it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.26it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.26it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.26it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.28it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.28it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.28it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.28it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.28it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.28it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.28it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.28it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.28it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.22it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.95it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.86it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.92it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.98it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.03it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.07it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:54<00:00,  0.10it/s, pixel_AUPRO=0.873]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:54<00:00,  0.10it/s, pixel_AUPRO=0.873]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:26<00:00,  0.09it/s, pixel_AUPRO=0.873]INFO:anomalib.callbacks.timer:Training took 327.11 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:28<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:36<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 382.9816589355469 seconds
Throughput (batch_size=32) : 0.5222182194204203 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [06:21<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9314000606536865     â”‚
â”‚        pixel_AUPRO        â”‚    0.8732349872589111     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.94it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.94it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.22it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.22it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.24it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.24it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.29it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.29it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.29it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.29it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.29it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.29it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.30it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:07,  0.76it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.73it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:05,  0.73it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:04,  0.75it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.76it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:07<00:01,  0.77it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  0.78it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:01<00:00,  0.10it/s, pixel_AUPRO=0.887]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:01<00:00,  0.10it/s, pixel_AUPRO=0.887]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:33<00:00,  0.09it/s, pixel_AUPRO=0.887]INFO:anomalib.callbacks.timer:Training took 334.80 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:39,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:32,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:26,  0.15it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:19,  0.15it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:32<00:13,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:38<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:41<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 393.3114061355591 seconds
Throughput (batch_size=32) : 0.5085029238411352 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [06:31<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9469000101089478     â”‚
â”‚        pixel_AUPRO        â”‚    0.8872100710868835     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:04<02:18,  0.20it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:04<02:18,  0.20it/s]Epoch 0:   7%|â–‹         | 2/29 [00:06<01:27,  0.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:06<01:27,  0.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:08<01:16,  0.34it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:08<01:16,  0.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:10<01:04,  0.39it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:10<01:04,  0.39it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:12<01:02,  0.39it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:12<01:02,  0.39it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:14<00:55,  0.42it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:14<00:55,  0.42it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:15<00:49,  0.44it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:15<00:49,  0.44it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:18<00:48,  0.43it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:18<00:48,  0.43it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:19<00:44,  0.45it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:19<00:44,  0.45it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:21<00:40,  0.47it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:21<00:40,  0.47it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:23<00:38,  0.46it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:23<00:38,  0.46it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:25<00:35,  0.48it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:25<00:35,  0.48it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:26<00:32,  0.49it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:26<00:32,  0.49it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:29<00:31,  0.48it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:29<00:31,  0.48it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:30<00:28,  0.49it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:30<00:28,  0.49it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:33<00:26,  0.48it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:33<00:26,  0.48it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:34<00:24,  0.49it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:34<00:24,  0.49it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:36<00:22,  0.50it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:36<00:22,  0.50it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:38<00:20,  0.49it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:38<00:20,  0.49it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:39<00:17,  0.50it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:39<00:17,  0.50it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:41<00:15,  0.51it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:41<00:15,  0.51it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:43<00:13,  0.50it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:43<00:13,  0.50it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:45<00:11,  0.51it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:45<00:11,  0.51it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:46<00:09,  0.51it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:46<00:09,  0.51it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:49<00:07,  0.51it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:49<00:07,  0.51it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:50<00:05,  0.52it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:50<00:05,  0.52it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:51<00:03,  0.52it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:51<00:03,  0.52it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:54<00:01,  0.51it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:54<00:01,  0.51it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:54<00:00,  0.53it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:54<00:00,  0.53it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.22it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:08,  0.56it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:05<00:07,  0.54it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:08<00:06,  0.50it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:09<00:03,  0.55it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:10<00:01,  0.58it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  0.63it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:45<00:00,  0.13it/s, pixel_AUPRO=0.748]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [03:45<00:00,  0.13it/s, pixel_AUPRO=0.748]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:11<00:00,  0.12it/s, pixel_AUPRO=0.748]INFO:anomalib.callbacks.timer:Training took 252.35 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:22,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:22<00:16,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 301.199903011322 seconds
Throughput (batch_size=32) : 0.6673308921764309 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:59<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7416831254959106     â”‚
â”‚        pixel_AUPRO        â”‚    0.8520910143852234     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.33it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.33it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.34it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.33it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.33it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.31it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.31it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.30it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.30it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.27it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.27it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.27it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.30it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.30it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.31it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.31it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.34it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.22it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.99it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.89it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.95it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:04<00:01,  1.02it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.06it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.10it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:02<00:00,  0.12it/s, pixel_AUPRO=0.843]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:02<00:00,  0.12it/s, pixel_AUPRO=0.843]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:28<00:00,  0.11it/s, pixel_AUPRO=0.843]INFO:anomalib.callbacks.timer:Training took 269.34 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:35,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:28,  0.18it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:16<00:22,  0.18it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:21<00:16,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:27<00:10,  0.18it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:32<00:05,  0.18it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:34<00:00,  0.20it/s]INFO:anomalib.callbacks.timer:Testing took 296.90439200401306 seconds
Throughput (batch_size=32) : 0.6769856068592047 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:55<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7940593957901001     â”‚
â”‚        pixel_AUPRO        â”‚    0.8428129553794861     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.99it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.99it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.28it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.28it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.25it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.25it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.26it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.28it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.28it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.29it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.29it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.29it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.29it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.29it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.30it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.30it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.30it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.30it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.30it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.31it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.31it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.31it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.31it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.31it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.31it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.32it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.32it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.32it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.32it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.32it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.32it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.32it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.32it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.32it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.32it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:03,  1.32it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:03,  1.32it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.32it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.32it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.33it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.33it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.33it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.36it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.16it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.96it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.87it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.94it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.99it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.04it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.09it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:04<00:00,  0.12it/s, pixel_AUPRO=0.840]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:04<00:00,  0.12it/s, pixel_AUPRO=0.840]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:31<00:00,  0.11it/s, pixel_AUPRO=0.840]INFO:anomalib.callbacks.timer:Training took 272.08 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:35,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:22,  0.18it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 297.0523669719696 seconds
Throughput (batch_size=32) : 0.6766483702820207 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:55<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7935643792152405     â”‚
â”‚        pixel_AUPRO        â”‚    0.8400952816009521     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.23it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.29it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.29it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.29it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.29it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.30it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.30it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.31it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.31it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:15,  1.32it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.32it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.32it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.33it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.33it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.33it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.33it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.34it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.34it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.34it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.34it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.34it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.34it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.34it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.34it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.22it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.99it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.89it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.97it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:04<00:01,  1.03it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.08it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.12it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:05<00:00,  0.12it/s, pixel_AUPRO=0.839]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:05<00:00,  0.12it/s, pixel_AUPRO=0.839]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:32<00:00,  0.11it/s, pixel_AUPRO=0.839]INFO:anomalib.callbacks.timer:Training took 273.68 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:05<00:35,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:28,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:16<00:22,  0.18it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:22<00:16,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:28<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 299.3364851474762 seconds
Throughput (batch_size=32) : 0.6714851345333728 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:57<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9125742316246033     â”‚
â”‚        pixel_AUPRO        â”‚    0.8389060497283936     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.02it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.36it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.36it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.36it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.36it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.36it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.36it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.36it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.36it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.36it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.37it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.37it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.37it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.37it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.37it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.37it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.37it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.41it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.43it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:01<00:04,  1.04it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.92it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.99it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:04<00:01,  1.05it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.10it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.15it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:08<00:00,  0.12it/s, pixel_AUPRO=0.852]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:08<00:00,  0.12it/s, pixel_AUPRO=0.852]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:35<00:00,  0.11it/s, pixel_AUPRO=0.852]INFO:anomalib.callbacks.timer:Training took 276.17 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:22,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:22<00:16,  0.18it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:34<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:36<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 299.3302478790283 seconds
Throughput (batch_size=32) : 0.6714991265474526 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:57<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9205940365791321     â”‚
â”‚        pixel_AUPRO        â”‚    0.8520534038543701     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.00it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.00it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.29it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.29it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.31it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.30it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.31it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.31it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.31it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.31it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.32it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.32it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.32it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.32it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.32it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.32it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:06,  1.33it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.33it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.33it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.33it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.33it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.33it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.33it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.33it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.33it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.37it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.91it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.81it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.78it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.82it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.85it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.88it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.89it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:09<00:00,  0.12it/s, pixel_AUPRO=0.875]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:09<00:00,  0.12it/s, pixel_AUPRO=0.875]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:35<00:00,  0.11it/s, pixel_AUPRO=0.875]INFO:anomalib.callbacks.timer:Training took 276.31 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 299.16731452941895 seconds
Throughput (batch_size=32) : 0.6718648403023801 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:57<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9619802236557007     â”‚
â”‚        pixel_AUPRO        â”‚    0.8754422068595886     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:02<01:11,  0.39it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:02<01:11,  0.39it/s]Epoch 0:   7%|â–‹         | 2/29 [00:04<01:04,  0.42it/s]Epoch 0:   7%|â–‹         | 2/29 [00:04<01:04,  0.42it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:06<00:55,  0.47it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:06<00:55,  0.47it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:07<00:49,  0.51it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:07<00:49,  0.51it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:10<00:49,  0.48it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:10<00:49,  0.48it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:11<00:45,  0.50it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:11<00:45,  0.50it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:13<00:41,  0.53it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:13<00:41,  0.53it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:15<00:41,  0.51it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:15<00:41,  0.51it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:17<00:38,  0.52it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:17<00:38,  0.52it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:18<00:35,  0.53it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:18<00:35,  0.53it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:21<00:34,  0.52it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:21<00:34,  0.52it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:22<00:31,  0.53it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:22<00:31,  0.53it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:25<00:31,  0.51it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:25<00:31,  0.51it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:27<00:29,  0.52it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:27<00:29,  0.52it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:28<00:26,  0.52it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:28<00:26,  0.52it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:31<00:25,  0.51it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:31<00:25,  0.51it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:32<00:22,  0.52it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:32<00:22,  0.52it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:34<00:20,  0.53it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:34<00:20,  0.53it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:36<00:19,  0.52it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:36<00:19,  0.52it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:38<00:17,  0.52it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:38<00:17,  0.52it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:40<00:15,  0.52it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:40<00:15,  0.52it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:42<00:13,  0.52it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:42<00:13,  0.52it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:43<00:11,  0.53it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:43<00:11,  0.53it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:45<00:09,  0.52it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:45<00:09,  0.52it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:47<00:07,  0.53it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:47<00:07,  0.53it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:48<00:05,  0.53it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:48<00:05,  0.53it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:51<00:03,  0.53it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:51<00:03,  0.53it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:52<00:01,  0.53it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:52<00:01,  0.53it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:53<00:00,  0.55it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:53<00:00,  0.55it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.96it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:07,  0.67it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:06<00:08,  0.49it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:07<00:05,  0.53it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:08<00:03,  0.57it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:10<00:01,  0.55it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  0.59it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:42<00:00,  0.08it/s, pixel_AUPRO=0.691]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:42<00:00,  0.08it/s, pixel_AUPRO=0.691]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [06:16<00:00,  0.08it/s, pixel_AUPRO=0.691]INFO:anomalib.callbacks.timer:Training took 377.43 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:38,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:38<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:40<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 583.1242134571075 seconds
Throughput (batch_size=32) : 0.34469499870079534 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:41<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8994058966636658     â”‚
â”‚        pixel_AUPRO        â”‚     0.827556312084198     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:30,  0.93it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:30,  0.93it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.24it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.24it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.23it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.23it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.23it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.23it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.24it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.24it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.25it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.25it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.26it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.26it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.26it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.26it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.28it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.28it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.28it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.28it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.28it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.93it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.84it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.77it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.84it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.89it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.92it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.94it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:33<00:00,  0.06it/s, pixel_AUPRO=0.844]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:33<00:00,  0.06it/s, pixel_AUPRO=0.844]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:07<00:00,  0.06it/s, pixel_AUPRO=0.844]INFO:anomalib.callbacks.timer:Training took 488.27 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:32,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:25,  0.15it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:26<00:19,  0.15it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:33<00:13,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:39<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:42<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 571.0579450130463 seconds
Throughput (batch_size=32) : 0.35197829179210177 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:29<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9443564414978027     â”‚
â”‚        pixel_AUPRO        â”‚    0.8441746830940247     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.00it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  1.00it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.19it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.19it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:22,  1.15it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:22,  1.15it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:22,  1.13it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:22,  1.13it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:21,  1.14it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:21,  1.14it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.16it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:05<00:19,  1.16it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.18it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.18it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.20it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.20it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.21it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.21it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.22it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.22it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.22it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.22it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.23it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.23it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.24it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.24it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.24it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.24it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.25it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.25it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.25it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.25it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.25it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.25it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.26it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.26it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:07,  1.26it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:07,  1.26it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.27it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.27it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.27it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.27it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.27it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.27it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.27it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.27it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.27it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.27it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.28it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.28it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.28it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.28it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.28it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.28it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.28it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.28it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.32it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.32it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.99it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.88it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.82it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.88it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.92it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.95it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.97it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:42<00:00,  0.06it/s, pixel_AUPRO=0.841]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:42<00:00,  0.06it/s, pixel_AUPRO=0.841]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:16<00:00,  0.06it/s, pixel_AUPRO=0.841]INFO:anomalib.callbacks.timer:Training took 497.32 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:37,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:30<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:36<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 565.3226962089539 seconds
Throughput (batch_size=32) : 0.35554914272486 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:23<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9465345740318298     â”‚
â”‚        pixel_AUPRO        â”‚    0.8415138721466064     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.22it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.22it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.25it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.25it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.26it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.26it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.26it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.26it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.26it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.27it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.27it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.27it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.28it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.28it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.28it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.28it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.28it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.28it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.28it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.28it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.28it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.28it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.28it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.28it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.28it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.28it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.28it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.32it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.32it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.98it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.83it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.78it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.84it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.88it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.91it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.94it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:36<00:00,  0.06it/s, pixel_AUPRO=0.837]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:36<00:00,  0.06it/s, pixel_AUPRO=0.837]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:11<00:00,  0.06it/s, pixel_AUPRO=0.837]INFO:anomalib.callbacks.timer:Training took 492.22 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:38,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:32,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:31<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:36<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 583.5867626667023 seconds
Throughput (batch_size=32) : 0.3444217944244136 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:42<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9968316555023193     â”‚
â”‚        pixel_AUPRO        â”‚    0.8365511894226074     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  0.98it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.29it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.29it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.30it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.30it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.23it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.23it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.24it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.24it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.25it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.25it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.25it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.25it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.25it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.26it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:15,  1.26it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.26it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.26it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.27it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.27it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.28it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.15it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.94it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.85it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.91it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.97it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:05<00:00,  1.02it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.04it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:39<00:00,  0.06it/s, pixel_AUPRO=0.847]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:39<00:00,  0.06it/s, pixel_AUPRO=0.847]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:12<00:00,  0.06it/s, pixel_AUPRO=0.847]INFO:anomalib.callbacks.timer:Training took 493.26 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:30,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 581.2780375480652 seconds
Throughput (batch_size=32) : 0.3457897718755279 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:39<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9965345859527588     â”‚
â”‚        pixel_AUPRO        â”‚    0.8467438817024231     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.24it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.24it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.25it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.25it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:19,  1.25it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.26it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:15,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.27it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.29it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.29it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.33it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:08,  0.70it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.73it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:05,  0.73it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:04,  0.74it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.74it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:08<00:01,  0.74it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:09<00:00,  0.75it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:41<00:00,  0.06it/s, pixel_AUPRO=0.884]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:41<00:00,  0.06it/s, pixel_AUPRO=0.884]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:15<00:00,  0.06it/s, pixel_AUPRO=0.884]INFO:anomalib.callbacks.timer:Training took 496.44 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:07<00:42,  0.14it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:34,  0.14it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:20<00:27,  0.15it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:27<00:20,  0.15it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:34<00:13,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:40<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:43<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 587.3927974700928 seconds
Throughput (batch_size=32) : 0.34219009982027226 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:45<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9972277283668518     â”‚
â”‚        pixel_AUPRO        â”‚    0.8841233849525452     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
14        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pipe_fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:04<01:03,  0.22it/s]Epoch 0:   7%|â–‹         | 1/15 [00:04<01:03,  0.22it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:06<00:44,  0.29it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:06<00:44,  0.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:08<00:33,  0.36it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:08<00:33,  0.36it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:09<00:26,  0.41it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:09<00:26,  0.41it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:11<00:23,  0.43it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:11<00:23,  0.43it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:12<00:19,  0.46it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:12<00:19,  0.46it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:14<00:16,  0.49it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:14<00:16,  0.49it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:15<00:13,  0.52it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:15<00:13,  0.52it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:17<00:11,  0.51it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:17<00:11,  0.51it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:18<00:09,  0.53it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:18<00:09,  0.53it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:19<00:07,  0.55it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:19<00:07,  0.55it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:22<00:05,  0.54it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:22<00:05,  0.54it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:23<00:03,  0.55it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:23<00:03,  0.55it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:24<00:01,  0.57it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:24<00:01,  0.57it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:24<00:00,  0.61it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:24<00:00,  0.61it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.89it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:03<00:05,  0.59it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:06<00:04,  0.46it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:07<00:01,  0.51it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:08<00:00,  0.57it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:04<00:00,  0.05it/s, pixel_AUPRO=0.917]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:04<00:00,  0.05it/s, pixel_AUPRO=0.917]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:41<00:00,  0.04it/s, pixel_AUPRO=0.917]INFO:anomalib.callbacks.timer:Training took 342.76 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 422.2114369869232 seconds
Throughput (batch_size=32) : 0.35527223296096033 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:00<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.770799994468689     â”‚
â”‚        pixel_AUPRO        â”‚    0.9344801902770996     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pipe_fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.98it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.98it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.26it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.26it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.28it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.28it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.29it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.29it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.30it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.30it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.30it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.30it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.30it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.30it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.31it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.31it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.31it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.31it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.31it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.31it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.31it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.31it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.31it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.31it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.90it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.84it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.80it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.85it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.87it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:55<00:00,  0.04it/s, pixel_AUPRO=0.933]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:55<00:00,  0.04it/s, pixel_AUPRO=0.933]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:32<00:00,  0.04it/s, pixel_AUPRO=0.933]INFO:anomalib.callbacks.timer:Training took 393.60 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 421.3299877643585 seconds
Throughput (batch_size=32) : 0.3560154851448457 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:59<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8040000796318054     â”‚
â”‚        pixel_AUPRO        â”‚    0.9327687621116638     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pipe_fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.02it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.02it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.30it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.30it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.32it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.32it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.33it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.33it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.34it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.34it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.35it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.35it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.35it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.35it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.35it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.35it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.35it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.35it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.35it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.35it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.35it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.35it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.35it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.44it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.44it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.91it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.83it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.79it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.83it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.86it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:00<00:00,  0.04it/s, pixel_AUPRO=0.931]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:00<00:00,  0.04it/s, pixel_AUPRO=0.931]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:37<00:00,  0.04it/s, pixel_AUPRO=0.931]INFO:anomalib.callbacks.timer:Training took 398.66 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 426.969135761261 seconds
Throughput (batch_size=32) : 0.3513134497006646 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:05<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7977999448776245     â”‚
â”‚        pixel_AUPRO        â”‚    0.9307581186294556     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pipe_fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.29it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.23it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.23it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.21it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.21it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.22it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.22it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.24it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.24it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.25it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.25it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.26it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.27it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.27it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.28it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.28it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.29it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.29it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.30it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.91it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.86it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.81it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.86it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.89it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:03<00:00,  0.04it/s, pixel_AUPRO=0.930]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:03<00:00,  0.04it/s, pixel_AUPRO=0.930]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:40<00:00,  0.04it/s, pixel_AUPRO=0.930]INFO:anomalib.callbacks.timer:Training took 401.85 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:30<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 431.15574383735657 seconds
Throughput (batch_size=32) : 0.3479021261898902 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:09<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9793999791145325     â”‚
â”‚        pixel_AUPRO        â”‚    0.9299197793006897     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pipe_fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.31it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.31it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.33it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.33it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:02<00:08,  1.34it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:02<00:08,  1.34it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.35it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.35it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.34it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.35it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.35it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.34it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.34it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.34it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.34it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.34it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.34it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.34it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.34it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.34it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.34it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.34it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.43it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.43it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.00it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.90it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.83it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.89it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.92it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:06<00:00,  0.04it/s, pixel_AUPRO=0.928]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:06<00:00,  0.04it/s, pixel_AUPRO=0.928]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:43<00:00,  0.04it/s, pixel_AUPRO=0.928]INFO:anomalib.callbacks.timer:Training took 404.53 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:19,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 427.5529742240906 seconds
Throughput (batch_size=32) : 0.35083371896129406 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:06<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9811999797821045     â”‚
â”‚        pixel_AUPRO        â”‚    0.9282838106155396     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pipe_fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.97it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.97it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.24it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.24it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.27it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.27it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.28it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.28it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.27it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.27it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.27it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.27it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.28it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.28it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.28it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.28it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.28it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.28it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.28it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.28it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.28it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.28it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.37it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:06,  0.65it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  0.67it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:02,  0.68it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.68it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  0.69it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:08<00:00,  0.04it/s, pixel_AUPRO=0.938]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:08<00:00,  0.04it/s, pixel_AUPRO=0.938]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:45<00:00,  0.04it/s, pixel_AUPRO=0.938]INFO:anomalib.callbacks.timer:Training took 406.46 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:27,  0.14it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:20,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:13,  0.15it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 425.0561144351959 seconds
Throughput (batch_size=32) : 0.3528945823995881 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:03<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9909999370574951     â”‚
â”‚        pixel_AUPRO        â”‚     0.938185453414917     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad bottle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:07,  0.77it/s]Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:07,  0.77it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.96it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.96it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.97it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.97it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.98it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.98it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.99it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.99it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.99it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.99it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.07it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.07it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:02,  0.90it/s][A
Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:02<00:01,  0.92it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  0.94it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:49<00:00,  0.14it/s, pixel_AUPRO=0.939]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:49<00:00,  0.14it/s, pixel_AUPRO=0.939]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:14<00:00,  0.09it/s, pixel_AUPRO=0.939]INFO:anomalib.callbacks.timer:Training took 74.78 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:07<00:15,  0.13it/s]Testing DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:15<00:07,  0.13it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:20<00:00,  0.15it/s]INFO:anomalib.callbacks.timer:Testing took 63.17794108390808 seconds
Throughput (batch_size=32) : 1.3137496818670584 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:01<00:00,  0.05it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚            1.0            â”‚
â”‚        pixel_AUPRO        â”‚    0.9408778548240662     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad cable with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:10,  0.56it/s]Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:10,  0.56it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:08,  0.62it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:08,  0.62it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.62it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.62it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.62it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.62it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:08<00:03,  0.62it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:08<00:03,  0.62it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:09<00:01,  0.62it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:09<00:01,  0.62it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  0.63it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  0.63it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.85it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  0.67it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:03,  0.66it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:06<00:01,  0.64it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  0.68it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:10<00:00,  0.05it/s, pixel_AUPRO=0.911]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:10<00:00,  0.05it/s, pixel_AUPRO=0.911]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:37<00:00,  0.04it/s, pixel_AUPRO=0.911]INFO:anomalib.callbacks.timer:Training took 158.03 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:08<00:34,  0.12it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17<00:26,  0.11it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:25<00:17,  0.12it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:34<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:40<00:00,  0.12it/s]INFO:anomalib.callbacks.timer:Testing took 216.44806265830994 seconds
Throughput (batch_size=32) : 0.693006895778012 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:34<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9630809426307678     â”‚
â”‚        pixel_AUPRO        â”‚    0.9154481887817383     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad capsule with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:10,  0.57it/s]Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:10,  0.57it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:07,  0.65it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:07,  0.65it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.65it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.65it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.65it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.65it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:07<00:03,  0.65it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:07<00:03,  0.65it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:09<00:01,  0.66it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:09<00:01,  0.66it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:10<00:00,  0.67it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:10<00:00,  0.67it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.87it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.76it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:02,  0.70it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.67it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  0.72it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:15<00:00,  0.05it/s, pixel_AUPRO=0.938]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:15<00:00,  0.05it/s, pixel_AUPRO=0.938]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:40<00:00,  0.04it/s, pixel_AUPRO=0.938]INFO:anomalib.callbacks.timer:Training took 161.49 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:08<00:33,  0.12it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:16<00:25,  0.12it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:24<00:16,  0.12it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:32<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:35<00:00,  0.14it/s]INFO:anomalib.callbacks.timer:Testing took 159.85212779045105 seconds
Throughput (batch_size=32) : 0.8257631714044983 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:38<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9848424792289734     â”‚
â”‚        pixel_AUPRO        â”‚     0.938332736492157     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad carpet with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/9 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/9 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  11%|â–ˆ         | 1/9 [00:01<00:13,  0.59it/s]Epoch 0:  11%|â–ˆ         | 1/9 [00:01<00:13,  0.59it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 2/9 [00:02<00:10,  0.67it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 2/9 [00:02<00:10,  0.67it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:04<00:08,  0.67it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:04<00:08,  0.67it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:05<00:07,  0.68it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:05<00:07,  0.68it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:07<00:05,  0.68it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:07<00:05,  0.68it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:08<00:04,  0.68it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:08<00:04,  0.68it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:10<00:02,  0.68it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:10<00:02,  0.68it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:11<00:01,  0.68it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:11<00:01,  0.68it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:12<00:00,  0.70it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:12<00:00,  0.70it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  0.72it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  0.72it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  0.68it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  0.70it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:24<00:00,  0.11it/s, pixel_AUPRO=0.946]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:24<00:00,  0.11it/s, pixel_AUPRO=0.946]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:56<00:00,  0.08it/s, pixel_AUPRO=0.946]INFO:anomalib.callbacks.timer:Training took 117.66 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:08<00:25,  0.12it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:17<00:17,  0.12it/s]Testing DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:25<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:32<00:00,  0.12it/s]INFO:anomalib.callbacks.timer:Testing took 122.07498359680176 seconds
Throughput (batch_size=32) : 0.9584273251793849 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:00<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9823434352874756     â”‚
â”‚        pixel_AUPRO        â”‚    0.9466915130615234     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad grid with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/9 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/9 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  11%|â–ˆ         | 1/9 [00:01<00:08,  0.92it/s]Epoch 0:  11%|â–ˆ         | 1/9 [00:01<00:08,  0.92it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:06,  1.13it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:06,  1.13it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:02<00:05,  1.14it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:02<00:05,  1.14it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:03<00:04,  1.13it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:03<00:04,  1.13it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:04<00:03,  1.13it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:04<00:03,  1.13it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:05<00:02,  1.12it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:05<00:02,  1.12it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:06<00:01,  1.12it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:06<00:01,  1.12it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:07<00:00,  1.12it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:07<00:00,  1.12it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.22it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.22it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:02,  0.76it/s][A
Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:02<00:01,  0.78it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  0.80it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:22<00:00,  0.11it/s, pixel_AUPRO=0.906]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:22<00:00,  0.11it/s, pixel_AUPRO=0.906]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:53<00:00,  0.08it/s, pixel_AUPRO=0.906]INFO:anomalib.callbacks.timer:Training took 114.48 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:07<00:15,  0.13it/s]Testing DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:16<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:20<00:00,  0.14it/s]INFO:anomalib.callbacks.timer:Testing took 124.00775074958801 seconds
Throughput (batch_size=32) : 0.6289929422033255 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:02<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9841269850730896     â”‚
â”‚        pixel_AUPRO        â”‚    0.9061993360519409     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad hazelnut with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/13 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   8%|â–Š         | 1/13 [00:01<00:20,  0.58it/s]Epoch 0:   8%|â–Š         | 1/13 [00:01<00:20,  0.58it/s]Epoch 0:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  0.66it/s]Epoch 0:  15%|â–ˆâ–Œ        | 2/13 [00:03<00:16,  0.66it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  0.67it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:04<00:14,  0.67it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  0.67it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:05<00:13,  0.67it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  0.68it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:07<00:11,  0.68it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  0.68it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:08<00:10,  0.68it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  0.68it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:10<00:08,  0.68it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  0.68it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:11<00:07,  0.68it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  0.68it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:13<00:05,  0.68it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  0.68it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:14<00:04,  0.68it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  0.68it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:16<00:02,  0.68it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  0.68it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:17<00:01,  0.68it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  0.72it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  0.72it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  0.62it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  0.63it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  0.64it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  0.65it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [01:55<00:00,  0.11it/s, pixel_AUPRO=0.943]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [01:55<00:00,  0.11it/s, pixel_AUPRO=0.943]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [02:36<00:00,  0.08it/s, pixel_AUPRO=0.943]INFO:anomalib.callbacks.timer:Training took 157.36 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:08<00:26,  0.11it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:17<00:17,  0.12it/s]Testing DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:25<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  0.14it/s]INFO:anomalib.callbacks.timer:Testing took 141.03981161117554 seconds
Throughput (batch_size=32) : 0.779921631654278 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:19<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9957143068313599     â”‚
â”‚        pixel_AUPRO        â”‚    0.9484254121780396     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad leather with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/8 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:10,  0.65it/s]Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:10,  0.65it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:02<00:07,  0.75it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:02<00:07,  0.75it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:03<00:06,  0.75it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:03<00:06,  0.75it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:05<00:05,  0.76it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:05<00:05,  0.76it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:07<00:04,  0.65it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:07<00:04,  0.65it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  0.63it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  0.63it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:12<00:01,  0.55it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:12<00:01,  0.55it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  0.59it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  0.59it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  0.81it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  0.52it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  0.57it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  0.60it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:38<00:00,  0.08it/s, pixel_AUPRO=0.969]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:38<00:00,  0.08it/s, pixel_AUPRO=0.969]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [02:06<00:00,  0.06it/s, pixel_AUPRO=0.969]INFO:anomalib.callbacks.timer:Training took 128.45 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:08<00:25,  0.12it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:17<00:17,  0.12it/s]Testing DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:25<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:32<00:00,  0.12it/s]INFO:anomalib.callbacks.timer:Testing took 130.18676662445068 seconds
Throughput (batch_size=32) : 0.9524777611053385 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:08<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9993206262588501     â”‚
â”‚        pixel_AUPRO        â”‚    0.9692615866661072     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad metal_nut with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.04it/s]Epoch 0:  14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.04it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:01<00:03,  1.32it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:01<00:03,  1.32it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:02<00:02,  1.34it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:02<00:02,  1.34it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:02<00:02,  1.35it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:02<00:02,  1.35it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:03<00:01,  1.35it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:03<00:01,  1.35it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:04<00:00,  1.35it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:04<00:00,  1.35it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.38it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  0.86it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  0.89it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  0.91it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  0.91it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:36<00:00,  0.07it/s, pixel_AUPRO=0.938]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:36<00:00,  0.07it/s, pixel_AUPRO=0.938]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:01<00:00,  0.06it/s, pixel_AUPRO=0.938]INFO:anomalib.callbacks.timer:Training took 122.47 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:07<00:22,  0.14it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:14<00:14,  0.14it/s]Testing DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:21<00:07,  0.14it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:25<00:00,  0.15it/s]INFO:anomalib.callbacks.timer:Testing took 134.7484850883484 seconds
Throughput (batch_size=32) : 0.8534418767275921 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:13<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9970674514770508     â”‚
â”‚        pixel_AUPRO        â”‚    0.9386566877365112     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad pill with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/9 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/9 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  11%|â–ˆ         | 1/9 [00:01<00:09,  0.84it/s]Epoch 0:  11%|â–ˆ         | 1/9 [00:01<00:09,  0.84it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:06,  1.02it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:06,  1.02it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:02<00:05,  1.03it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:02<00:05,  1.03it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:03<00:04,  1.04it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:03<00:04,  1.04it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:04<00:03,  1.03it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:04<00:03,  1.03it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:05<00:02,  1.03it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:05<00:02,  1.03it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:06<00:01,  1.03it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:06<00:01,  1.03it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:07<00:00,  1.03it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:07<00:00,  1.03it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  1.11it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  1.11it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/6 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s][A
Validation DataLoader 0:  17%|â–ˆâ–‹        | 1/6 [00:01<00:06,  0.75it/s][A
Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:02<00:05,  0.77it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:03<00:03,  0.78it/s][A
Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:05<00:02,  0.79it/s][A
Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:06<00:01,  0.79it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:07<00:00,  0.80it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [04:32<00:00,  0.03it/s, pixel_AUPRO=0.952]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [04:32<00:00,  0.03it/s, pixel_AUPRO=0.952]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [05:04<00:00,  0.03it/s, pixel_AUPRO=0.952]INFO:anomalib.callbacks.timer:Training took 305.29 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/6 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]Testing DataLoader 0:  17%|â–ˆâ–‹        | 1/6 [00:07<00:37,  0.13it/s]Testing DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:15<00:30,  0.13it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:22<00:22,  0.13it/s]Testing DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:29<00:14,  0.13it/s]Testing DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:37<00:07,  0.13it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:39<00:00,  0.15it/s]INFO:anomalib.callbacks.timer:Testing took 342.5816345214844 seconds
Throughput (batch_size=32) : 0.48747505170049305 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [05:41<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9252591729164124     â”‚
â”‚        pixel_AUPRO        â”‚    0.9517629146575928     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad screw with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/10 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  10%|â–ˆ         | 1/10 [00:01<00:09,  0.90it/s]Epoch 0:  10%|â–ˆ         | 1/10 [00:01<00:09,  0.90it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 2/10 [00:01<00:07,  1.12it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 2/10 [00:01<00:07,  1.12it/s]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:02<00:06,  1.13it/s]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:02<00:06,  1.13it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:03<00:05,  1.14it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:03<00:05,  1.14it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:04<00:04,  1.14it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:04<00:04,  1.14it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:05<00:03,  1.15it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:05<00:03,  1.15it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:06<00:02,  1.15it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:06<00:02,  1.15it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:06<00:01,  1.15it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:06<00:01,  1.15it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:07<00:00,  1.15it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:07<00:00,  1.15it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.15it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.15it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:06,  0.65it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  0.67it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:02,  0.68it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.68it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  0.68it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:47<00:00,  0.06it/s, pixel_AUPRO=0.962]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:47<00:00,  0.06it/s, pixel_AUPRO=0.962]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [03:23<00:00,  0.05it/s, pixel_AUPRO=0.962]INFO:anomalib.callbacks.timer:Training took 204.23 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:07<00:30,  0.13it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15<00:23,  0.13it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:23<00:15,  0.13it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:30<00:07,  0.13it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:38<00:00,  0.13it/s]INFO:anomalib.callbacks.timer:Testing took 206.71199488639832 seconds
Throughput (batch_size=32) : 0.774023781677161 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:25<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9815536737442017     â”‚
â”‚        pixel_AUPRO        â”‚     0.961922287940979     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad tile with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/8 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:09,  0.75it/s]Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:09,  0.75it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:02<00:06,  0.90it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:02<00:06,  0.90it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:03<00:05,  0.91it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:03<00:05,  0.91it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:04<00:04,  0.90it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:04<00:04,  0.90it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:05<00:03,  0.90it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:05<00:03,  0.90it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:06<00:02,  0.90it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:06<00:02,  0.90it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:07<00:01,  0.89it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:07<00:01,  0.89it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  0.99it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  0.99it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  0.83it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  0.86it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  0.86it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  0.87it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:04<00:00,  0.12it/s, pixel_AUPRO=0.812]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:04<00:00,  0.12it/s, pixel_AUPRO=0.812]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:29<00:00,  0.09it/s, pixel_AUPRO=0.812]INFO:anomalib.callbacks.timer:Training took 90.70 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:07<00:23,  0.13it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:16<00:16,  0.12it/s]Testing DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:24<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:30<00:00,  0.13it/s]INFO:anomalib.callbacks.timer:Testing took 111.25294542312622 seconds
Throughput (batch_size=32) : 1.0516575498744425 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:49<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9902597665786743     â”‚
â”‚        pixel_AUPRO        â”‚    0.8135790228843689     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad toothbrush with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  0.58it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  0.58it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  0.70it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  0.70it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/2 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  0.94it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  0.98it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:26<00:00,  0.07it/s, pixel_AUPRO=0.913]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:26<00:00,  0.07it/s, pixel_AUPRO=0.913]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:33<00:00,  0.06it/s, pixel_AUPRO=0.913]INFO:anomalib.callbacks.timer:Training took 34.25 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  0.13it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 29.59206509590149 seconds
Throughput (batch_size=32) : 1.419299392046046 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:27<00:00,  0.07it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9555554986000061     â”‚
â”‚        pixel_AUPRO        â”‚    0.9146050810813904     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad transistor with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:10,  0.55it/s]Epoch 0:  14%|â–ˆâ–        | 1/7 [00:01<00:10,  0.55it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:08,  0.61it/s]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:08,  0.61it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.60it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.60it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.61it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  0.61it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:08<00:03,  0.61it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:08<00:03,  0.61it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:09<00:01,  0.61it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:09<00:01,  0.61it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:10<00:00,  0.65it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:10<00:00,  0.65it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  0.88it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  0.76it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  0.71it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  0.77it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:45<00:00,  0.16it/s, pixel_AUPRO=0.950]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:45<00:00,  0.16it/s, pixel_AUPRO=0.950]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:09<00:00,  0.10it/s, pixel_AUPRO=0.950]INFO:anomalib.callbacks.timer:Training took 70.68 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Testing DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:08<00:25,  0.12it/s]Testing DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:16<00:16,  0.12it/s]Testing DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:24<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:26<00:00,  0.15it/s]INFO:anomalib.callbacks.timer:Testing took 62.10370397567749 seconds
Throughput (batch_size=32) : 1.610209916612451 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:00<00:00,  0.07it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9937500953674316     â”‚
â”‚        pixel_AUPRO        â”‚    0.9496708512306213     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad wood with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/8 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:12,  0.57it/s]Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:12,  0.57it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:09,  0.64it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:09,  0.64it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:04<00:07,  0.64it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:04<00:07,  0.64it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:06<00:06,  0.64it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:06<00:06,  0.64it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:07<00:04,  0.64it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:07<00:04,  0.64it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  0.64it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  0.64it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:10<00:01,  0.64it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:10<00:01,  0.64it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:11<00:00,  0.67it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:11<00:00,  0.67it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:02,  0.79it/s][A
Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:02<00:01,  0.69it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  0.74it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:27<00:00,  0.09it/s, pixel_AUPRO=0.875]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:27<00:00,  0.09it/s, pixel_AUPRO=0.875]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:56<00:00,  0.07it/s, pixel_AUPRO=0.875]INFO:anomalib.callbacks.timer:Training took 116.82 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:08<00:16,  0.12it/s]Testing DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:16<00:08,  0.12it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  0.14it/s]INFO:anomalib.callbacks.timer:Testing took 123.45051765441895 seconds
Throughput (batch_size=32) : 0.6399325130506828 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:01<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9859648942947388     â”‚
â”‚        pixel_AUPRO        â”‚    0.8775368928909302     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.mvtec:Found the dataset.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset mvtec_ad zipper with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/8 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:07,  0.91it/s]Epoch 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:07,  0.91it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:05,  1.13it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:05,  1.13it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:04,  1.15it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:04,  1.15it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:03<00:03,  1.17it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:03<00:03,  1.17it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:04<00:02,  1.17it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:04<00:02,  1.17it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:05<00:01,  1.18it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:05<00:01,  1.18it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:05<00:00,  1.18it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:05<00:00,  1.18it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.81it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.84it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.85it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.86it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.86it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [03:13<00:00,  0.04it/s, pixel_AUPRO=0.940]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [03:13<00:00,  0.04it/s, pixel_AUPRO=0.940]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [03:42<00:00,  0.04it/s, pixel_AUPRO=0.940]INFO:anomalib.callbacks.timer:Training took 223.78 seconds
INFO:src.anomalib.data.image.mvtec:Found the dataset.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:07<00:31,  0.13it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15<00:23,  0.13it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:23<00:15,  0.13it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:30<00:07,  0.13it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36<00:00,  0.14it/s]INFO:anomalib.callbacks.timer:Testing took 240.7464804649353 seconds
Throughput (batch_size=32) : 0.627215815194412 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:59<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9438024759292603     â”‚
â”‚        pixel_AUPRO        â”‚    0.9403207302093506     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa candle with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.03it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.03it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.33it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.33it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.30it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.30it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.30it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.31it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.31it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.32it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.32it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.33it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.33it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:09,  1.33it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.33it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.33it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.33it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.34it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.34it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.34it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.34it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.34it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.34it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.39it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.39it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:09,  0.64it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:07,  0.66it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:06,  0.66it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:04,  0.67it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:07<00:02,  0.67it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:08<00:01,  0.67it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:10<00:00,  0.68it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:10<00:00,  0.07it/s, pixel_AUPRO=0.954]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:10<00:00,  0.07it/s, pixel_AUPRO=0.954]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:48<00:00,  0.06it/s, pixel_AUPRO=0.954]INFO:anomalib.callbacks.timer:Training took 469.69 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:41,  0.14it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:34,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:20<00:26,  0.15it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:26<00:19,  0.15it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:33<00:13,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:39<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:42<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 488.2636282444 seconds
Throughput (batch_size=32) : 0.4096147827334993 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [08:06<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9480999708175659     â”‚
â”‚        pixel_AUPRO        â”‚     0.953997015953064     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa capsules with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/17 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.98it/s]Epoch 0:   6%|â–Œ         | 1/17 [00:01<00:16,  0.98it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.26it/s]Epoch 0:  12%|â–ˆâ–        | 2/17 [00:01<00:11,  1.26it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.26it/s]Epoch 0:  18%|â–ˆâ–Š        | 3/17 [00:02<00:11,  1.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.20it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:03<00:10,  1.20it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:04<00:10,  1.17it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:04<00:10,  1.17it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:05<00:09,  1.16it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:05<00:09,  1.16it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:06<00:08,  1.14it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:06<00:08,  1.14it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:07<00:07,  1.14it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:07<00:07,  1.14it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:07<00:07,  1.14it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:07<00:07,  1.14it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:08<00:06,  1.15it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:08<00:06,  1.15it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:09<00:05,  1.16it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:09<00:05,  1.16it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:10<00:04,  1.17it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:10<00:04,  1.17it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:11<00:03,  1.18it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:11<00:03,  1.18it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:11<00:02,  1.19it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:11<00:02,  1.19it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:12<00:01,  1.19it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:12<00:01,  1.19it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:13<00:00,  1.20it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:13<00:00,  1.20it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:14<00:00,  1.21it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:14<00:00,  1.21it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.88it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.83it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.79it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:04<00:01,  0.82it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  0.85it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:26<00:00,  0.20it/s, pixel_AUPRO=0.685]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:26<00:00,  0.20it/s, pixel_AUPRO=0.685]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:54<00:00,  0.15it/s, pixel_AUPRO=0.685]INFO:anomalib.callbacks.timer:Training took 115.08 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:19,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:12,  0.15it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:32<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 136.38775515556335 seconds
Throughput (batch_size=32) : 1.1731258412274959 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:14<00:00,  0.04it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.6948333978652954     â”‚
â”‚        pixel_AUPRO        â”‚    0.6998372077941895     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa cashew with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:   7%|â–‹         | 1/15 [00:01<00:14,  0.95it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.19it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.19it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.21it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.21it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:09,  1.21it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:09,  1.21it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.22it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:04<00:08,  1.22it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.22it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.22it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.22it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.22it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.23it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.23it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.23it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.23it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.23it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:08<00:04,  1.23it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.23it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.23it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.23it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.23it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.24it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.24it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.24it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.24it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.32it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.32it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:06,  0.63it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:03<00:04,  0.65it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:03,  0.65it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:06<00:01,  0.66it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  0.66it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:23<00:00,  0.10it/s, pixel_AUPRO=0.894]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:23<00:00,  0.10it/s, pixel_AUPRO=0.894]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:01<00:00,  0.08it/s, pixel_AUPRO=0.894]INFO:anomalib.callbacks.timer:Training took 182.81 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:07<00:28,  0.14it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14<00:21,  0.14it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:20<00:13,  0.14it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:28<00:07,  0.14it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:33<00:00,  0.15it/s]INFO:anomalib.callbacks.timer:Testing took 192.18696093559265 seconds
Throughput (batch_size=32) : 0.7804899940650464 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:10<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.960800051689148     â”‚
â”‚        pixel_AUPRO        â”‚    0.8944316506385803     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa chewinggum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.03it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.03it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.31it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.31it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.33it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.33it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:02<00:08,  1.35it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:02<00:08,  1.35it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.35it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.35it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.35it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.35it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.35it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:05,  1.35it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.36it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:05<00:05,  1.36it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.36it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:06<00:04,  1.36it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.36it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.36it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.37it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:02,  1.37it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.37it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:08<00:02,  1.37it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.37it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.46it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.46it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:05,  0.69it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  0.71it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:02,  0.69it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.70it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  0.71it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:58<00:00,  0.05it/s, pixel_AUPRO=0.799]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:58<00:00,  0.05it/s, pixel_AUPRO=0.799]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:33<00:00,  0.05it/s, pixel_AUPRO=0.799]INFO:anomalib.callbacks.timer:Training took 333.97 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:27,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:19,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:13,  0.15it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:30<00:00,  0.16it/s]INFO:anomalib.callbacks.timer:Testing took 410.29099130630493 seconds
Throughput (batch_size=32) : 0.3655941835876594 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:48<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9945999383926392     â”‚
â”‚        pixel_AUPRO        â”‚    0.7988475561141968     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:10,  1.29it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.31it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.31it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.29it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.25it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:07,  1.26it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.27it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.27it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.28it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.28it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.28it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.28it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.29it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.29it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.29it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.29it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.30it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.30it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.30it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:09<00:01,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:10<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  0.88it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  0.80it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  0.75it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.79it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  0.82it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:47<00:00,  0.07it/s, pixel_AUPRO=0.833]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:47<00:00,  0.07it/s, pixel_AUPRO=0.833]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [04:14<00:00,  0.06it/s, pixel_AUPRO=0.833]INFO:anomalib.callbacks.timer:Training took 255.50 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  0.16it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:19,  0.16it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:12,  0.16it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 264.3990972042084 seconds
Throughput (batch_size=32) : 0.567324176164443 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:22<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9054000377655029     â”‚
â”‚        pixel_AUPRO        â”‚    0.8332613110542297     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.03it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:27,  1.03it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.35it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.37it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.37it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.38it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.38it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:15,  1.38it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:15,  1.38it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.38it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.38it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.38it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.38it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.38it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.38it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:07<00:13,  1.38it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:07<00:13,  1.38it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.38it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.38it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.38it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.38it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.39it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.39it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.38it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:07,  1.38it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.37it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.37it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.37it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.37it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.37it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.37it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.42it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.42it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.88it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.78it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:05,  0.74it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:03,  0.78it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.81it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:07<00:01,  0.83it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  0.85it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:21<00:00,  0.09it/s, pixel_AUPRO=0.923]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:21<00:00,  0.09it/s, pixel_AUPRO=0.923]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:49<00:00,  0.08it/s, pixel_AUPRO=0.923]INFO:anomalib.callbacks.timer:Training took 349.99 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:38,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:30<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:37<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:39<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 359.2856569290161 seconds
Throughput (batch_size=32) : 0.5566601286271606 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:57<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.8901999592781067     â”‚
â”‚        pixel_AUPRO        â”‚     0.922606885433197     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa macaroni2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:26,  1.05it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:26,  1.04it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.32it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.34it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:02<00:18,  1.35it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:17,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:16,  1.36it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.37it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:16,  1.37it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.37it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:05<00:15,  1.37it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.37it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:14,  1.37it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:08<00:12,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:11,  1.37it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.38it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:10,  1.38it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:10<00:10,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:11<00:09,  1.38it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:13<00:07,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.37it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:15<00:05,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:18<00:02,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.38it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.43it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:07,  0.86it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.83it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:05,  0.79it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.83it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.85it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.86it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.88it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:23<00:00,  0.11it/s, pixel_AUPRO=0.821]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:23<00:00,  0.11it/s, pixel_AUPRO=0.821]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:51<00:00,  0.10it/s, pixel_AUPRO=0.821]INFO:anomalib.callbacks.timer:Training took 292.07 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.17it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:11<00:29,  0.17it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:17<00:23,  0.17it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:23<00:17,  0.17it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:29<00:11,  0.17it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:35<00:05,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:37<00:00,  0.19it/s]INFO:anomalib.callbacks.timer:Testing took 227.94274187088013 seconds
Throughput (batch_size=32) : 0.8774133291477713 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [03:46<00:00,  0.03it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.7254500389099121     â”‚
â”‚        pixel_AUPRO        â”‚    0.8205596208572388     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb1 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.96it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.96it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:22,  1.21it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.24it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:21,  1.24it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.24it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:20,  1.24it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.24it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.24it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.24it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.24it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.24it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.24it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.24it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.24it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.24it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.24it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.24it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.24it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.25it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.25it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.25it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.25it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.25it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.25it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.25it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:11,  1.25it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:11,  1.26it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:11,  1.26it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.26it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.26it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.26it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.26it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.26it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.26it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:07,  1.26it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:07,  1.26it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.26it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:07,  1.26it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.26it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.26it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.26it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.26it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.26it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.26it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.26it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.26it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.26it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.26it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.26it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.30it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:07,  0.77it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.76it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:05,  0.74it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:03,  0.76it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.77it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:07<00:01,  0.78it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  0.79it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:25<00:00,  0.11it/s, pixel_AUPRO=0.871]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:25<00:00,  0.11it/s, pixel_AUPRO=0.871]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:56<00:00,  0.10it/s, pixel_AUPRO=0.871]INFO:anomalib.callbacks.timer:Training took 297.83 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:39,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:32,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:25,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:19,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:32<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:38<00:06,  0.16it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:40<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 347.9066936969757 seconds
Throughput (batch_size=32) : 0.5748667778556701 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [05:46<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.919499933719635     â”‚
â”‚        pixel_AUPRO        â”‚    0.8712525367736816     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb2 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  1.00it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:28,  1.00it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.26it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.26it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.27it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.28it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:17,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.29it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.30it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.30it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.30it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:12,  1.30it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.30it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.30it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.30it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.30it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.30it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.30it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.30it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.30it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.30it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.30it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.30it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.30it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:15<00:06,  1.30it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.30it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.30it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.30it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:17<00:04,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:18<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:20<00:01,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:21<00:00,  1.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:21<00:00,  1.34it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:07,  0.77it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.77it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:05,  0.72it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:04,  0.74it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.76it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:07<00:01,  0.77it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:09<00:00,  0.78it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:55<00:00,  0.10it/s, pixel_AUPRO=0.886]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:55<00:00,  0.10it/s, pixel_AUPRO=0.886]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [05:27<00:00,  0.09it/s, pixel_AUPRO=0.886]INFO:anomalib.callbacks.timer:Training took 328.07 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:40,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:33,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:26,  0.15it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:25<00:19,  0.15it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:32<00:13,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:39<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:41<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 384.5029010772705 seconds
Throughput (batch_size=32) : 0.5201521222327724 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [06:23<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9487000107765198     â”‚
â”‚        pixel_AUPRO        â”‚    0.8863176703453064     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:26,  1.04it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:00<00:26,  1.04it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.33it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:20,  1.33it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:19,  1.31it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.28it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:03<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.28it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:17,  1.28it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:16,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.29it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:06<00:15,  1.29it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:07<00:14,  1.30it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.31it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:13,  1.31it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:12,  1.31it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.32it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:09<00:12,  1.32it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:10<00:11,  1.32it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:11<00:10,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.33it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:09,  1.33it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.33it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:12<00:08,  1.33it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.34it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:13<00:08,  1.34it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.34it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:14<00:07,  1.34it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:14<00:06,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:15<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:16<00:05,  1.35it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:16<00:04,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:17<00:03,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:18<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:19<00:02,  1.36it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:19<00:01,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:20<00:00,  1.37it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:20<00:00,  1.40it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:06,  0.93it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:05,  0.86it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  0.82it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:04<00:03,  0.86it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:05<00:02,  0.89it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:06<00:01,  0.91it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  0.92it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:05<00:00,  0.12it/s, pixel_AUPRO=0.862]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:05<00:00,  0.12it/s, pixel_AUPRO=0.862]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [04:31<00:00,  0.11it/s, pixel_AUPRO=0.862]INFO:anomalib.callbacks.timer:Training took 271.90 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:36,  0.16it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:12<00:31,  0.16it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:18<00:24,  0.16it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:24<00:18,  0.16it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:30<00:12,  0.16it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:36<00:06,  0.17it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:38<00:00,  0.18it/s]INFO:anomalib.callbacks.timer:Testing took 299.46771931648254 seconds
Throughput (batch_size=32) : 0.6711908731223876 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [04:57<00:00,  0.02it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9442574381828308     â”‚
â”‚        pixel_AUPRO        â”‚     0.861862301826477     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   3%|â–Ž         | 1/29 [00:01<00:29,  0.95it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.24it/s]Epoch 0:   7%|â–‹         | 2/29 [00:01<00:21,  1.24it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  10%|â–ˆ         | 3/29 [00:02<00:20,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  14%|â–ˆâ–        | 4/29 [00:03<00:19,  1.26it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.24it/s]Epoch 0:  17%|â–ˆâ–‹        | 5/29 [00:04<00:19,  1.24it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.23it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 6/29 [00:04<00:18,  1.23it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.22it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 7/29 [00:05<00:18,  1.22it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.21it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:06<00:17,  1.21it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.22it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:07<00:16,  1.22it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.22it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:08<00:15,  1.22it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.22it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:08<00:14,  1.22it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.23it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:09<00:13,  1.23it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.23it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:10<00:13,  1.23it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.23it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:11<00:12,  1.23it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.23it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:12<00:11,  1.23it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.23it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:12<00:10,  1.23it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.24it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:13<00:09,  1.24it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.24it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:14<00:08,  1.24it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.24it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:15<00:08,  1.24it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.25it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:16<00:07,  1.25it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.25it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:16<00:06,  1.25it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.25it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:17<00:05,  1.25it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.25it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:18<00:04,  1.25it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.25it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:19<00:03,  1.25it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.25it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:19<00:03,  1.25it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.26it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:20<00:02,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.26it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:21<00:01,  1.26it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.26it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:22<00:00,  1.26it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.29it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:22<00:00,  1.29it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:01<00:08,  0.71it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:02<00:06,  0.73it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:04<00:05,  0.72it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:05<00:04,  0.73it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:06<00:02,  0.73it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:08<00:01,  0.74it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:09<00:00,  0.74it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:30<00:00,  0.06it/s, pixel_AUPRO=0.866]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [07:30<00:00,  0.06it/s, pixel_AUPRO=0.866]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:02<00:00,  0.06it/s, pixel_AUPRO=0.866]INFO:anomalib.callbacks.timer:Training took 483.78 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]Testing DataLoader 0:  14%|â–ˆâ–        | 1/7 [00:06<00:39,  0.15it/s]Testing DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:13<00:33,  0.15it/s]Testing DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:19<00:25,  0.15it/s]Testing DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:26<00:19,  0.15it/s]Testing DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:32<00:13,  0.15it/s]Testing DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:39<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:41<00:00,  0.17it/s]INFO:anomalib.callbacks.timer:Testing took 579.5957984924316 seconds
Throughput (batch_size=32) : 0.3467934041668604 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:38<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚    0.9978218078613281     â”‚
â”‚        pixel_AUPRO        â”‚    0.8656601309776306     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | SPALWinNNModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pipe_fryum with model spalwinnn
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/15 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.02it/s]Epoch 0:   7%|â–‹         | 1/15 [00:00<00:13,  1.02it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.30it/s]Epoch 0:  13%|â–ˆâ–Ž        | 2/15 [00:01<00:09,  1.30it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.32it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 3/15 [00:02<00:09,  1.32it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.33it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 4/15 [00:03<00:08,  1.33it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.33it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:03<00:07,  1.33it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.30it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:04<00:06,  1.30it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.29it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:05<00:06,  1.29it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.28it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:06<00:05,  1.28it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.27it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:07<00:04,  1.27it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.25it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:07<00:03,  1.25it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:08<00:03,  1.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:09<00:02,  1.26it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:10<00:01,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.27it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:11<00:00,  1.27it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.spalwinnn.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.spalwinnn.lightning_model:Generating memory bank

Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:06,  0.66it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  0.68it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:02,  0.69it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:05<00:01,  0.69it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  0.69it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:55<00:00,  0.04it/s, pixel_AUPRO=0.939]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [05:55<00:00,  0.04it/s, pixel_AUPRO=0.939]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [06:33<00:00,  0.04it/s, pixel_AUPRO=0.939]INFO:anomalib.callbacks.timer:Training took 394.15 seconds
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.

Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]Testing DataLoader 0:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:27,  0.15it/s]Testing DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13<00:20,  0.15it/s]Testing DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:20<00:13,  0.15it/s]Testing DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:06,  0.15it/s]Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:32<00:00,  0.15it/s]INFO:anomalib.callbacks.timer:Testing took 421.1498465538025 seconds
Throughput (batch_size=32) : 0.35616776600401134 FPS
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:59<00:00,  0.01it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ        Test metric        â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚        image_AUROC        â”‚     0.990399956703186     â”‚
â”‚        pixel_AUPRO        â”‚    0.9390435218811035     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | PadimModel               | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model padim
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/114 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/114 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   1%|          | 1/114 [00:00<00:54,  2.06it/s]Epoch 0:   1%|          | 1/114 [00:00<00:54,  2.06it/s]Epoch 0:   2%|â–         | 2/114 [00:00<00:27,  4.03it/s]Epoch 0:   2%|â–         | 2/114 [00:00<00:27,  4.03it/s]Epoch 0:   3%|â–Ž         | 3/114 [00:00<00:22,  4.89it/s]Epoch 0:   3%|â–Ž         | 3/114 [00:00<00:22,  4.89it/s]Epoch 0:   4%|â–Ž         | 4/114 [00:00<00:22,  4.97it/s]Epoch 0:   4%|â–Ž         | 4/114 [00:00<00:22,  4.97it/s]Epoch 0:   4%|â–         | 5/114 [00:01<00:21,  5.00it/s]Epoch 0:   4%|â–         | 5/114 [00:01<00:21,  5.00it/s]Epoch 0:   5%|â–Œ         | 6/114 [00:01<00:21,  5.02it/s]Epoch 0:   5%|â–Œ         | 6/114 [00:01<00:21,  5.02it/s]Epoch 0:   6%|â–Œ         | 7/114 [00:01<00:21,  5.04it/s]Epoch 0:   6%|â–Œ         | 7/114 [00:01<00:21,  5.04it/s]Epoch 0:   7%|â–‹         | 8/114 [00:01<00:20,  5.06it/s]Epoch 0:   7%|â–‹         | 8/114 [00:01<00:20,  5.06it/s]Epoch 0:   8%|â–Š         | 9/114 [00:01<00:20,  5.07it/s]Epoch 0:   8%|â–Š         | 9/114 [00:01<00:20,  5.07it/s]Epoch 0:   9%|â–‰         | 10/114 [00:01<00:20,  5.11it/s]Epoch 0:   9%|â–‰         | 10/114 [00:01<00:20,  5.11it/s]Epoch 0:  10%|â–‰         | 11/114 [00:02<00:20,  5.14it/s]Epoch 0:  10%|â–‰         | 11/114 [00:02<00:20,  5.14it/s]Epoch 0:  11%|â–ˆ         | 12/114 [00:02<00:19,  5.16it/s]Epoch 0:  11%|â–ˆ         | 12/114 [00:02<00:19,  5.16it/s]Epoch 0:  11%|â–ˆâ–        | 13/114 [00:02<00:19,  5.19it/s]Epoch 0:  11%|â–ˆâ–        | 13/114 [00:02<00:19,  5.19it/s]Epoch 0:  12%|â–ˆâ–        | 14/114 [00:02<00:19,  5.21it/s]Epoch 0:  12%|â–ˆâ–        | 14/114 [00:02<00:19,  5.21it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/114 [00:02<00:18,  5.23it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/114 [00:02<00:18,  5.23it/s]Epoch 0:  14%|â–ˆâ–        | 16/114 [00:03<00:18,  5.25it/s]Epoch 0:  14%|â–ˆâ–        | 16/114 [00:03<00:18,  5.25it/s]Epoch 0:  15%|â–ˆâ–        | 17/114 [00:03<00:18,  5.27it/s]Epoch 0:  15%|â–ˆâ–        | 17/114 [00:03<00:18,  5.26it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/114 [00:03<00:18,  5.27it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/114 [00:03<00:18,  5.27it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/114 [00:03<00:18,  5.26it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/114 [00:03<00:18,  5.26it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/114 [00:03<00:17,  5.26it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/114 [00:03<00:17,  5.26it/s]Epoch 0:  18%|â–ˆâ–Š        | 21/114 [00:03<00:17,  5.26it/s]Epoch 0:  18%|â–ˆâ–Š        | 21/114 [00:03<00:17,  5.26it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/114 [00:04<00:17,  5.26it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/114 [00:04<00:17,  5.26it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/114 [00:04<00:17,  5.27it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/114 [00:04<00:17,  5.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/114 [00:04<00:17,  5.27it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/114 [00:04<00:17,  5.27it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/114 [00:04<00:16,  5.27it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/114 [00:04<00:16,  5.27it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/114 [00:04<00:16,  5.27it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/114 [00:04<00:16,  5.27it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 27/114 [00:05<00:16,  5.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 27/114 [00:05<00:16,  5.26it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/114 [00:05<00:16,  5.26it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/114 [00:05<00:16,  5.26it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 29/114 [00:05<00:16,  5.25it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 29/114 [00:05<00:16,  5.25it/s]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 30/114 [00:05<00:15,  5.25it/s]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 30/114 [00:05<00:15,  5.25it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/114 [00:05<00:15,  5.24it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/114 [00:05<00:15,  5.24it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/114 [00:06<00:15,  5.24it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/114 [00:06<00:15,  5.24it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/114 [00:06<00:15,  5.25it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/114 [00:06<00:15,  5.25it/s]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 34/114 [00:06<00:15,  5.24it/s]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 34/114 [00:06<00:15,  5.24it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/114 [00:06<00:15,  5.24it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/114 [00:06<00:15,  5.24it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/114 [00:06<00:14,  5.24it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/114 [00:06<00:14,  5.24it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 37/114 [00:07<00:14,  5.24it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 37/114 [00:07<00:14,  5.24it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/114 [00:07<00:14,  5.24it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/114 [00:07<00:14,  5.24it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 39/114 [00:07<00:14,  5.23it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 39/114 [00:07<00:14,  5.23it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/114 [00:07<00:14,  5.24it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/114 [00:07<00:14,  5.24it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 41/114 [00:07<00:13,  5.24it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 41/114 [00:07<00:13,  5.24it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/114 [00:08<00:13,  5.24it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/114 [00:08<00:13,  5.24it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/114 [00:08<00:13,  5.24it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/114 [00:08<00:13,  5.24it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 44/114 [00:08<00:13,  5.24it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 44/114 [00:08<00:13,  5.24it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 45/114 [00:08<00:13,  5.24it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 45/114 [00:08<00:13,  5.24it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/114 [00:08<00:12,  5.23it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/114 [00:08<00:12,  5.23it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 47/114 [00:08<00:12,  5.24it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 47/114 [00:08<00:12,  5.24it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/114 [00:09<00:12,  5.24it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/114 [00:09<00:12,  5.23it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/114 [00:09<00:12,  5.23it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/114 [00:09<00:12,  5.23it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/114 [00:09<00:12,  5.23it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/114 [00:09<00:12,  5.23it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 51/114 [00:09<00:12,  5.24it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 51/114 [00:09<00:12,  5.24it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/114 [00:09<00:11,  5.24it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/114 [00:09<00:11,  5.24it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/114 [00:10<00:11,  5.24it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/114 [00:10<00:11,  5.24it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 54/114 [00:10<00:11,  5.23it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 54/114 [00:10<00:11,  5.23it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/114 [00:10<00:11,  5.23it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/114 [00:10<00:11,  5.23it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/114 [00:10<00:11,  5.23it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/114 [00:10<00:11,  5.23it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/114 [00:10<00:10,  5.23it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/114 [00:10<00:10,  5.23it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 58/114 [00:11<00:10,  5.23it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 58/114 [00:11<00:10,  5.23it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/114 [00:11<00:10,  5.23it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/114 [00:11<00:10,  5.23it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/114 [00:11<00:10,  5.23it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/114 [00:11<00:10,  5.23it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 61/114 [00:11<00:10,  5.23it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 61/114 [00:11<00:10,  5.23it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/114 [00:11<00:09,  5.23it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/114 [00:11<00:09,  5.23it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/114 [00:12<00:09,  5.23it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/114 [00:12<00:09,  5.23it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 64/114 [00:12<00:09,  5.23it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 64/114 [00:12<00:09,  5.23it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 65/114 [00:12<00:09,  5.24it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 65/114 [00:12<00:09,  5.24it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/114 [00:12<00:09,  5.24it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/114 [00:12<00:09,  5.24it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/114 [00:12<00:08,  5.24it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/114 [00:12<00:08,  5.24it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 68/114 [00:12<00:08,  5.24it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 68/114 [00:12<00:08,  5.24it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/114 [00:13<00:08,  5.24it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/114 [00:13<00:08,  5.24it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/114 [00:13<00:08,  5.24it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/114 [00:13<00:08,  5.24it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 71/114 [00:13<00:08,  5.24it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 71/114 [00:13<00:08,  5.24it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/114 [00:13<00:08,  5.24it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/114 [00:13<00:08,  5.24it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/114 [00:13<00:07,  5.24it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/114 [00:13<00:07,  5.24it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 74/114 [00:14<00:07,  5.25it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 74/114 [00:14<00:07,  5.25it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 75/114 [00:14<00:07,  5.25it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 75/114 [00:14<00:07,  5.25it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/114 [00:14<00:07,  5.25it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/114 [00:14<00:07,  5.25it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/114 [00:14<00:07,  5.25it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/114 [00:14<00:07,  5.25it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 78/114 [00:14<00:06,  5.25it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 78/114 [00:14<00:06,  5.25it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/114 [00:15<00:06,  5.25it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/114 [00:15<00:06,  5.25it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/114 [00:15<00:06,  5.25it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/114 [00:15<00:06,  5.25it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 81/114 [00:15<00:06,  5.25it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 81/114 [00:15<00:06,  5.25it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 82/114 [00:15<00:06,  5.26it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 82/114 [00:15<00:06,  5.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/114 [00:15<00:05,  5.26it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/114 [00:15<00:05,  5.26it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 84/114 [00:15<00:05,  5.26it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 84/114 [00:15<00:05,  5.26it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 85/114 [00:16<00:05,  5.26it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 85/114 [00:16<00:05,  5.26it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/114 [00:16<00:05,  5.26it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/114 [00:16<00:05,  5.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/114 [00:16<00:05,  5.26it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/114 [00:16<00:05,  5.26it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 88/114 [00:16<00:04,  5.26it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 88/114 [00:16<00:04,  5.26it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 89/114 [00:16<00:04,  5.27it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 89/114 [00:16<00:04,  5.26it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/114 [00:17<00:04,  5.26it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/114 [00:17<00:04,  5.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 91/114 [00:17<00:04,  5.26it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 91/114 [00:17<00:04,  5.26it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 92/114 [00:17<00:04,  5.27it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 92/114 [00:17<00:04,  5.27it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/114 [00:17<00:03,  5.27it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/114 [00:17<00:03,  5.27it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 94/114 [00:17<00:03,  5.26it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 94/114 [00:17<00:03,  5.26it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 95/114 [00:18<00:03,  5.26it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 95/114 [00:18<00:03,  5.26it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/114 [00:18<00:03,  5.26it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/114 [00:18<00:03,  5.26it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/114 [00:18<00:03,  5.27it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/114 [00:18<00:03,  5.27it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 98/114 [00:18<00:03,  5.27it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 98/114 [00:18<00:03,  5.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 99/114 [00:18<00:02,  5.27it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 99/114 [00:18<00:02,  5.27it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/114 [00:18<00:02,  5.28it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/114 [00:18<00:02,  5.28it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 101/114 [00:19<00:02,  5.28it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 101/114 [00:19<00:02,  5.28it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 102/114 [00:19<00:02,  5.28it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 102/114 [00:19<00:02,  5.28it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/114 [00:19<00:02,  5.29it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/114 [00:19<00:02,  5.29it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 104/114 [00:19<00:01,  5.29it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 104/114 [00:19<00:01,  5.29it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 105/114 [00:19<00:01,  5.29it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 105/114 [00:19<00:01,  5.29it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 106/114 [00:20<00:01,  5.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 106/114 [00:20<00:01,  5.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/114 [00:20<00:01,  5.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/114 [00:20<00:01,  5.30it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 108/114 [00:20<00:01,  5.30it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 108/114 [00:20<00:01,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 109/114 [00:20<00:00,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 109/114 [00:20<00:00,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/114 [00:20<00:00,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/114 [00:20<00:00,  5.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 111/114 [00:20<00:00,  5.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 111/114 [00:20<00:00,  5.30it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 112/114 [00:21<00:00,  5.30it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 112/114 [00:21<00:00,  5.30it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 113/114 [00:21<00:00,  5.31it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 113/114 [00:21<00:00,  5.31it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:21<00:00,  5.34it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:21<00:00,  5.34it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.padim.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.padim.lightning_model:Fitting a Gaussian to the embedding collected from the training set.

Validation:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   4%|â–         | 1/26 [00:00<00:02, 11.22it/s][A
Validation DataLoader 0:   8%|â–Š         | 2/26 [00:00<00:01, 18.27it/s][A
Validation DataLoader 0:  12%|â–ˆâ–        | 3/26 [00:00<00:02,  8.47it/s][A
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 4/26 [00:00<00:03,  5.77it/s][A
Validation DataLoader 0:  19%|â–ˆâ–‰        | 5/26 [00:01<00:04,  4.86it/s][A
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 6/26 [00:01<00:04,  4.33it/s][A
Validation DataLoader 0:  27%|â–ˆâ–ˆâ–‹       | 7/26 [00:01<00:04,  4.04it/s][A
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 8/26 [00:02<00:04,  3.84it/s][A
Validation DataLoader 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 9/26 [00:02<00:04,  3.75it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 10/26 [00:02<00:04,  3.66it/s][A
Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/26 [00:03<00:04,  3.58it/s][A
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/26 [00:03<00:04,  3.50it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 13/26 [00:03<00:03,  3.51it/s][A
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/26 [00:03<00:03,  3.60it/s][A
Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 15/26 [00:04<00:02,  3.68it/s][A
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/26 [00:04<00:02,  3.76it/s][A
Validation DataLoader 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 17/26 [00:04<00:02,  3.84it/s][A
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 18/26 [00:04<00:02,  3.91it/s][A
Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 19/26 [00:04<00:01,  3.97it/s][A
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 20/26 [00:04<00:01,  4.03it/s][A
Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 21/26 [00:05<00:01,  4.08it/s][A
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/26 [00:05<00:00,  4.13it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 23/26 [00:05<00:00,  4.17it/s][A
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 24/26 [00:05<00:00,  4.22it/s][A
Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 25/26 [00:05<00:00,  4.26it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:05<00:00,  4.35it/s][Aâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:161 in <module>    â”‚
â”‚                                                                              â”‚
â”‚   158 â”‚   â”‚   print("Image AUROC: {}, Pixel AUPRO: {}".format(image_AUROC, p â”‚
â”‚   159                                                                        â”‚
â”‚   160 if __name__ == '__main__':                                             â”‚
â”‚ â± 161 â”‚   main()                                                             â”‚
â”‚   162 â”‚   torch.cuda.empty_cache()                                           â”‚
â”‚   163                                                                        â”‚
â”‚   164                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:137 in main        â”‚
â”‚                                                                              â”‚
â”‚   134 â”‚                                                                      â”‚
â”‚   135 â”‚   # start training                                                   â”‚
â”‚   136 â”‚   engine = Engine(accelerator=args.gpu_type,task=TaskType.SEGMENTATI â”‚
â”‚ â± 137 â”‚   engine.fit(model=model, datamodule=datamodule)                     â”‚
â”‚   138 â”‚                                                                      â”‚
â”‚   139 â”‚   # load best model from checkpoint before evaluating                â”‚
â”‚   140 â”‚   test_results = engine.test(                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/engine/engine.p â”‚
â”‚ y:549 in fit                                                                 â”‚
â”‚                                                                              â”‚
â”‚    546 â”‚   â”‚   â”‚   # if the model is zero-shot or few-shot, we only need to  â”‚
â”‚    547 â”‚   â”‚   â”‚   self.trainer.validate(model, val_dataloaders, datamodule= â”‚
â”‚    548 â”‚   â”‚   else:                                                         â”‚
â”‚ â±  549 â”‚   â”‚   â”‚   self.trainer.fit(model, train_dataloaders, val_dataloader â”‚
â”‚    550 â”‚                                                                     â”‚
â”‚    551 â”‚   def validate(                                                     â”‚
â”‚    552 â”‚   â”‚   self,                                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:538 in fit              â”‚
â”‚                                                                              â”‚
â”‚    535 â”‚   â”‚   self.state.fn = TrainerFn.FITTING                             â”‚
â”‚    536 â”‚   â”‚   self.state.status = TrainerStatus.RUNNING                     â”‚
â”‚    537 â”‚   â”‚   self.training = True                                          â”‚
â”‚ â±  538 â”‚   â”‚   call._call_and_handle_interrupt(                              â”‚
â”‚    539 â”‚   â”‚   â”‚   self, self._fit_impl, model, train_dataloaders, val_datal â”‚
â”‚    540 â”‚   â”‚   )                                                             â”‚
â”‚    541                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/call.py:47 in                      â”‚
â”‚ _call_and_handle_interrupt                                                   â”‚
â”‚                                                                              â”‚
â”‚    44 â”‚   try:                                                               â”‚
â”‚    45 â”‚   â”‚   if trainer.strategy.launcher is not None:                      â”‚
â”‚    46 â”‚   â”‚   â”‚   return trainer.strategy.launcher.launch(trainer_fn, *args, â”‚
â”‚ â±  47 â”‚   â”‚   return trainer_fn(*args, **kwargs)                             â”‚
â”‚    48 â”‚                                                                      â”‚
â”‚    49 â”‚   except _TunerExitException:                                        â”‚
â”‚    50 â”‚   â”‚   _call_teardown_hook(trainer)                                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:574 in _fit_impl        â”‚
â”‚                                                                              â”‚
â”‚    571 â”‚   â”‚   â”‚   model_provided=True,                                      â”‚
â”‚    572 â”‚   â”‚   â”‚   model_connected=self.lightning_module is not None,        â”‚
â”‚    573 â”‚   â”‚   )                                                             â”‚
â”‚ â±  574 â”‚   â”‚   self._run(model, ckpt_path=ckpt_path)                         â”‚
â”‚    575 â”‚   â”‚                                                                 â”‚
â”‚    576 â”‚   â”‚   assert self.state.stopped                                     â”‚
â”‚    577 â”‚   â”‚   self.training = False                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:981 in _run             â”‚
â”‚                                                                              â”‚
â”‚    978 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    979 â”‚   â”‚   # RUN THE TRAINER                                             â”‚
â”‚    980 â”‚   â”‚   # ----------------------------                                â”‚
â”‚ â±  981 â”‚   â”‚   results = self._run_stage()                                   â”‚
â”‚    982 â”‚   â”‚                                                                 â”‚
â”‚    983 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    984 â”‚   â”‚   # POST-Training CLEAN UP                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:1025 in _run_stage      â”‚
â”‚                                                                              â”‚
â”‚   1022 â”‚   â”‚   â”‚   with isolate_rng():                                       â”‚
â”‚   1023 â”‚   â”‚   â”‚   â”‚   self._run_sanity_check()                              â”‚
â”‚   1024 â”‚   â”‚   â”‚   with torch.autograd.set_detect_anomaly(self._detect_anoma â”‚
â”‚ â± 1025 â”‚   â”‚   â”‚   â”‚   self.fit_loop.run()                                   â”‚
â”‚   1026 â”‚   â”‚   â”‚   return None                                               â”‚
â”‚   1027 â”‚   â”‚   raise RuntimeError(f"Unexpected state {self.state}")          â”‚
â”‚   1028                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:205 in run               â”‚
â”‚                                                                              â”‚
â”‚   202 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   203 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   204 â”‚   â”‚   â”‚   â”‚   self.on_advance_start()                                â”‚
â”‚ â± 205 â”‚   â”‚   â”‚   â”‚   self.advance()                                         â”‚
â”‚   206 â”‚   â”‚   â”‚   â”‚   self.on_advance_end()                                  â”‚
â”‚   207 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   208 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:363 in advance           â”‚
â”‚                                                                              â”‚
â”‚   360 â”‚   â”‚   â”‚   )                                                          â”‚
â”‚   361 â”‚   â”‚   with self.trainer.profiler.profile("run_training_epoch"):      â”‚
â”‚   362 â”‚   â”‚   â”‚   assert self._data_fetcher is not None                      â”‚
â”‚ â± 363 â”‚   â”‚   â”‚   self.epoch_loop.run(self._data_fetcher)                    â”‚
â”‚   364 â”‚                                                                      â”‚
â”‚   365 â”‚   def on_advance_end(self) -> None:                                  â”‚
â”‚   366 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:141 in run    â”‚
â”‚                                                                              â”‚
â”‚   138 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   139 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self.advance(data_fetcher)                             â”‚
â”‚ â± 141 â”‚   â”‚   â”‚   â”‚   self.on_advance_end(data_fetcher)                      â”‚
â”‚   142 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   143 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚   144 â”‚   â”‚   â”‚   â”‚   break                                                  â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:295 in        â”‚
â”‚ on_advance_end                                                               â”‚
â”‚                                                                              â”‚
â”‚   292 â”‚   â”‚   â”‚   â”‚   # clear gradients to not leave any unused memory durin â”‚
â”‚   293 â”‚   â”‚   â”‚   â”‚   call._call_lightning_module_hook(self.trainer, "on_val â”‚
â”‚   294 â”‚   â”‚   â”‚                                                              â”‚
â”‚ â± 295 â”‚   â”‚   â”‚   self.val_loop.run()                                        â”‚
â”‚   296 â”‚   â”‚   â”‚   self.trainer.training = True                               â”‚
â”‚   297 â”‚   â”‚   â”‚   self.trainer._logger_connector._first_loop_iter = first_lo â”‚
â”‚   298                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/utilities.py:178 in _decorator       â”‚
â”‚                                                                              â”‚
â”‚   175 â”‚   â”‚   else:                                                          â”‚
â”‚   176 â”‚   â”‚   â”‚   context_manager = torch.no_grad                            â”‚
â”‚   177 â”‚   â”‚   with context_manager():                                        â”‚
â”‚ â± 178 â”‚   â”‚   â”‚   return loop_run(self, *args, **kwargs)                     â”‚
â”‚   179 â”‚                                                                      â”‚
â”‚   180 â”‚   return _decorator                                                  â”‚
â”‚   181                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:142 in run        â”‚
â”‚                                                                              â”‚
â”‚   139 â”‚   â”‚   â”‚   finally:                                                   â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   141 â”‚   â”‚   self._store_dataloader_outputs()                               â”‚
â”‚ â± 142 â”‚   â”‚   return self.on_run_end()                                       â”‚
â”‚   143 â”‚                                                                      â”‚
â”‚   144 â”‚   def setup_data(self) -> None:                                      â”‚
â”‚   145 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:254 in on_run_end â”‚
â”‚                                                                              â”‚
â”‚   251 â”‚   â”‚   self.trainer._logger_connector._evaluation_epoch_end()         â”‚
â”‚   252 â”‚   â”‚                                                                  â”‚
â”‚   253 â”‚   â”‚   # hook                                                         â”‚
â”‚ â± 254 â”‚   â”‚   self._on_evaluation_epoch_end()                                â”‚
â”‚   255 â”‚   â”‚                                                                  â”‚
â”‚   256 â”‚   â”‚   logged_outputs, self._logged_outputs = self._logged_outputs, [ â”‚
â”‚   257 â”‚   â”‚   # include any logged outputs on epoch_end                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:336 in            â”‚
â”‚ _on_evaluation_epoch_end                                                     â”‚
â”‚                                                                              â”‚
â”‚   333 â”‚   â”‚   call._call_callback_hooks(trainer, hook_name)                  â”‚
â”‚   334 â”‚   â”‚   call._call_lightning_module_hook(trainer, hook_name)           â”‚
â”‚   335 â”‚   â”‚                                                                  â”‚
â”‚ â± 336 â”‚   â”‚   trainer._logger_connector.on_epoch_end()                       â”‚
â”‚   337 â”‚                                                                      â”‚
â”‚   338 â”‚   def _store_dataloader_outputs(self) -> None:                       â”‚
â”‚   339 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:195 in on_epoch_end                                            â”‚
â”‚                                                                              â”‚
â”‚   192 â”‚                                                                      â”‚
â”‚   193 â”‚   def on_epoch_end(self) -> None:                                    â”‚
â”‚   194 â”‚   â”‚   assert self._first_loop_iter is None                           â”‚
â”‚ â± 195 â”‚   â”‚   metrics = self.metrics                                         â”‚
â”‚   196 â”‚   â”‚   self._progress_bar_metrics.update(metrics["pbar"])             â”‚
â”‚   197 â”‚   â”‚   self._callback_metrics.update(metrics["callback"])             â”‚
â”‚   198 â”‚   â”‚   self._logged_metrics.update(metrics["log"])                    â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:234 in metrics                                                 â”‚
â”‚                                                                              â”‚
â”‚   231 â”‚   â”‚   """This function returns either batch or epoch metrics."""     â”‚
â”‚   232 â”‚   â”‚   on_step = self._first_loop_iter is not None                    â”‚
â”‚   233 â”‚   â”‚   assert self.trainer._results is not None                       â”‚
â”‚ â± 234 â”‚   â”‚   return self.trainer._results.metrics(on_step)                  â”‚
â”‚   235 â”‚                                                                      â”‚
â”‚   236 â”‚   @property                                                          â”‚
â”‚   237 â”‚   def callback_metrics(self) -> _OUT_DICT:                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:473 in metrics                                                           â”‚
â”‚                                                                              â”‚
â”‚   470 â”‚   â”‚                                                                  â”‚
â”‚   471 â”‚   â”‚   for _, result_metric in self.valid_items():                    â”‚
â”‚   472 â”‚   â”‚   â”‚   # extract forward_cache or computed from the _ResultMetric â”‚
â”‚ â± 473 â”‚   â”‚   â”‚   value = self._get_cache(result_metric, on_step)            â”‚
â”‚   474 â”‚   â”‚   â”‚   if not isinstance(value, Tensor):                          â”‚
â”‚   475 â”‚   â”‚   â”‚   â”‚   continue                                               â”‚
â”‚   476                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:437 in _get_cache                                                        â”‚
â”‚                                                                              â”‚
â”‚   434 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   " devices.",                                   â”‚
â”‚   435 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   category=PossibleUserWarning,                  â”‚
â”‚   436 â”‚   â”‚   â”‚   â”‚   â”‚   )                                                  â”‚
â”‚ â± 437 â”‚   â”‚   â”‚   â”‚   result_metric.compute()                                â”‚
â”‚   438 â”‚   â”‚   â”‚   â”‚   result_metric.meta.sync.should = should                â”‚
â”‚   439 â”‚   â”‚   â”‚                                                              â”‚
â”‚   440 â”‚   â”‚   â”‚   cache = result_metric._computed                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:288 in wrapped_func                                                      â”‚
â”‚                                                                              â”‚
â”‚   285 â”‚   â”‚   â”‚   # return cached value                                      â”‚
â”‚   286 â”‚   â”‚   â”‚   if self._computed is not None:                             â”‚
â”‚   287 â”‚   â”‚   â”‚   â”‚   return self._computed                                  â”‚
â”‚ â± 288 â”‚   â”‚   â”‚   self._computed = compute(*args, **kwargs)                  â”‚
â”‚   289 â”‚   â”‚   â”‚   return self._computed                                      â”‚
â”‚   290 â”‚   â”‚                                                                  â”‚
â”‚   291 â”‚   â”‚   return wrapped_func                                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:253 in compute                                                           â”‚
â”‚                                                                              â”‚
â”‚   250 â”‚   â”‚   â”‚   â”‚   cumulated_batch_size = self.meta.sync(self.cumulated_b â”‚
â”‚   251 â”‚   â”‚   â”‚   â”‚   return value / cumulated_batch_size                    â”‚
â”‚   252 â”‚   â”‚   â”‚   return value                                               â”‚
â”‚ â± 253 â”‚   â”‚   return self.value.compute()                                    â”‚
â”‚   254 â”‚                                                                      â”‚
â”‚   255 â”‚   @override                                                          â”‚
â”‚   256 â”‚   def reset(self) -> None:                                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/metric.py:700 in wrapped_func                   â”‚
â”‚                                                                              â”‚
â”‚    697 â”‚   â”‚   â”‚   â”‚   should_sync=self._to_sync,                            â”‚
â”‚    698 â”‚   â”‚   â”‚   â”‚   should_unsync=self._should_unsync,                    â”‚
â”‚    699 â”‚   â”‚   â”‚   ):                                                        â”‚
â”‚ â±  700 â”‚   â”‚   â”‚   â”‚   value = _squeeze_if_scalar(compute(*args, **kwargs))  â”‚
â”‚    701 â”‚   â”‚   â”‚   â”‚   # clone tensor to avoid in-place operations after com â”‚
â”‚    702 â”‚   â”‚   â”‚   â”‚   value = apply_to_collection(value, Tensor, lambda x:  â”‚
â”‚    703                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:241 in compute                                                             â”‚
â”‚                                                                              â”‚
â”‚   238 â”‚   â”‚   Returns:                                                       â”‚
â”‚   239 â”‚   â”‚   â”‚   Tensor: Value of the AUPRO metric                          â”‚
â”‚   240 â”‚   â”‚   """                                                            â”‚
â”‚ â± 241 â”‚   â”‚   fpr, tpr = self._compute()                                     â”‚
â”‚   242 â”‚   â”‚                                                                  â”‚
â”‚   243 â”‚   â”‚   aupro = auc(fpr, tpr, reorder=True)                            â”‚
â”‚   244 â”‚   â”‚   return aupro / fpr[-1]  # normalize the area                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:229 in _compute                                                            â”‚
â”‚                                                                              â”‚
â”‚   226 â”‚   â”‚   Returns:                                                       â”‚
â”‚   227 â”‚   â”‚   â”‚   tuple[torch.Tensor, torch.Tensor]: tuple containing final  â”‚
â”‚   228 â”‚   â”‚   """                                                            â”‚
â”‚ â± 229 â”‚   â”‚   cca = self.perform_cca().flatten()                             â”‚
â”‚   230 â”‚   â”‚   target = dim_zero_cat(self.target).flatten()                   â”‚
â”‚   231 â”‚   â”‚   preds = dim_zero_cat(self.preds).flatten()                     â”‚
â”‚   232                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:108 in perform_cca                                                         â”‚
â”‚                                                                              â”‚
â”‚   105 â”‚   â”‚   Returns:                                                       â”‚
â”‚   106 â”‚   â”‚   â”‚   Tensor: Components labeled from 0 to N.                    â”‚
â”‚   107 â”‚   â”‚   """                                                            â”‚
â”‚ â± 108 â”‚   â”‚   target = dim_zero_cat(self.target)                             â”‚
â”‚   109 â”‚   â”‚                                                                  â”‚
â”‚   110 â”‚   â”‚   # check and prepare target for labeling via kornia             â”‚
â”‚   111 â”‚   â”‚   if target.min() < 0 or target.max() > 1:                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/utilities/data.py:36 in dim_zero_cat            â”‚
â”‚                                                                              â”‚
â”‚    33 â”‚   x = [y.unsqueeze(0) if y.numel() == 1 and y.ndim == 0 else y for y â”‚
â”‚    34 â”‚   if not x:  # empty list                                            â”‚
â”‚    35 â”‚   â”‚   raise ValueError("No samples to concatenate")                  â”‚
â”‚ â±  36 â”‚   return torch.cat(x, dim=0)                                         â”‚
â”‚    37                                                                        â”‚
â”‚    38                                                                        â”‚
â”‚    39 def dim_zero_sum(x: Tensor) -> Tensor:                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:32<00:00,  3.46it/s]

                                                                        [A/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | PadimModel               | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model padim
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/113 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/113 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   1%|          | 1/113 [00:00<00:54,  2.05it/s]Epoch 0:   1%|          | 1/113 [00:00<00:54,  2.05it/s]Epoch 0:   2%|â–         | 2/113 [00:00<00:27,  4.00it/s]Epoch 0:   2%|â–         | 2/113 [00:00<00:27,  4.00it/s]Epoch 0:   3%|â–Ž         | 3/113 [00:00<00:23,  4.66it/s]Epoch 0:   3%|â–Ž         | 3/113 [00:00<00:23,  4.66it/s]Epoch 0:   4%|â–Ž         | 4/113 [00:00<00:22,  4.83it/s]Epoch 0:   4%|â–Ž         | 4/113 [00:00<00:22,  4.82it/s]Epoch 0:   4%|â–         | 5/113 [00:01<00:21,  4.91it/s]Epoch 0:   4%|â–         | 5/113 [00:01<00:21,  4.91it/s]Epoch 0:   5%|â–Œ         | 6/113 [00:01<00:21,  4.97it/s]Epoch 0:   5%|â–Œ         | 6/113 [00:01<00:21,  4.97it/s]Epoch 0:   6%|â–Œ         | 7/113 [00:01<00:21,  5.02it/s]Epoch 0:   6%|â–Œ         | 7/113 [00:01<00:21,  5.02it/s]Epoch 0:   7%|â–‹         | 8/113 [00:01<00:20,  5.06it/s]Epoch 0:   7%|â–‹         | 8/113 [00:01<00:20,  5.06it/s]Epoch 0:   8%|â–Š         | 9/113 [00:01<00:20,  5.10it/s]Epoch 0:   8%|â–Š         | 9/113 [00:01<00:20,  5.10it/s]Epoch 0:   9%|â–‰         | 10/113 [00:01<00:20,  5.13it/s]Epoch 0:   9%|â–‰         | 10/113 [00:01<00:20,  5.13it/s]Epoch 0:  10%|â–‰         | 11/113 [00:02<00:19,  5.15it/s]Epoch 0:  10%|â–‰         | 11/113 [00:02<00:19,  5.15it/s]Epoch 0:  11%|â–ˆ         | 12/113 [00:02<00:19,  5.16it/s]Epoch 0:  11%|â–ˆ         | 12/113 [00:02<00:19,  5.16it/s]Epoch 0:  12%|â–ˆâ–        | 13/113 [00:02<00:19,  5.18it/s]Epoch 0:  12%|â–ˆâ–        | 13/113 [00:02<00:19,  5.18it/s]Epoch 0:  12%|â–ˆâ–        | 14/113 [00:02<00:19,  5.19it/s]Epoch 0:  12%|â–ˆâ–        | 14/113 [00:02<00:19,  5.19it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/113 [00:02<00:18,  5.19it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/113 [00:02<00:18,  5.19it/s]Epoch 0:  14%|â–ˆâ–        | 16/113 [00:03<00:18,  5.19it/s]Epoch 0:  14%|â–ˆâ–        | 16/113 [00:03<00:18,  5.19it/s]Epoch 0:  15%|â–ˆâ–Œ        | 17/113 [00:03<00:18,  5.20it/s]Epoch 0:  15%|â–ˆâ–Œ        | 17/113 [00:03<00:18,  5.20it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/113 [00:03<00:18,  5.22it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/113 [00:03<00:18,  5.22it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/113 [00:03<00:17,  5.22it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/113 [00:03<00:17,  5.22it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/113 [00:03<00:17,  5.23it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/113 [00:03<00:17,  5.23it/s]Epoch 0:  19%|â–ˆâ–Š        | 21/113 [00:04<00:17,  5.24it/s]Epoch 0:  19%|â–ˆâ–Š        | 21/113 [00:04<00:17,  5.23it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/113 [00:04<00:17,  5.24it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/113 [00:04<00:17,  5.24it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/113 [00:04<00:17,  5.24it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/113 [00:04<00:17,  5.24it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/113 [00:04<00:16,  5.25it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/113 [00:04<00:16,  5.25it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/113 [00:04<00:16,  5.25it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/113 [00:04<00:16,  5.25it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/113 [00:04<00:16,  5.26it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/113 [00:04<00:16,  5.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 27/113 [00:05<00:16,  5.26it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 27/113 [00:05<00:16,  5.26it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/113 [00:05<00:16,  5.26it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/113 [00:05<00:16,  5.26it/s]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 29/113 [00:05<00:15,  5.26it/s]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 29/113 [00:05<00:15,  5.26it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 30/113 [00:05<00:15,  5.27it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 30/113 [00:05<00:15,  5.27it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/113 [00:05<00:15,  5.27it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/113 [00:05<00:15,  5.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/113 [00:06<00:15,  5.27it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/113 [00:06<00:15,  5.27it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/113 [00:06<00:15,  5.27it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/113 [00:06<00:15,  5.27it/s]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 34/113 [00:06<00:15,  5.26it/s]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 34/113 [00:06<00:15,  5.26it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/113 [00:06<00:14,  5.26it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/113 [00:06<00:14,  5.26it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/113 [00:06<00:14,  5.26it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/113 [00:06<00:14,  5.26it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 37/113 [00:07<00:14,  5.27it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 37/113 [00:07<00:14,  5.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/113 [00:07<00:14,  5.27it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/113 [00:07<00:14,  5.26it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 39/113 [00:07<00:14,  5.27it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 39/113 [00:07<00:14,  5.27it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/113 [00:07<00:13,  5.27it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/113 [00:07<00:13,  5.27it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 41/113 [00:07<00:13,  5.27it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 41/113 [00:07<00:13,  5.27it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/113 [00:07<00:13,  5.27it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/113 [00:07<00:13,  5.27it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/113 [00:08<00:13,  5.27it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/113 [00:08<00:13,  5.27it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 44/113 [00:08<00:13,  5.27it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 44/113 [00:08<00:13,  5.27it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 45/113 [00:08<00:12,  5.27it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 45/113 [00:08<00:12,  5.27it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/113 [00:08<00:12,  5.28it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/113 [00:08<00:12,  5.28it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/113 [00:08<00:12,  5.28it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/113 [00:08<00:12,  5.28it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/113 [00:09<00:12,  5.28it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/113 [00:09<00:12,  5.28it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/113 [00:09<00:12,  5.28it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/113 [00:09<00:12,  5.28it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/113 [00:09<00:11,  5.27it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/113 [00:09<00:11,  5.27it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 51/113 [00:09<00:11,  5.28it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 51/113 [00:09<00:11,  5.28it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/113 [00:09<00:11,  5.28it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/113 [00:09<00:11,  5.28it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/113 [00:10<00:11,  5.28it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/113 [00:10<00:11,  5.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 54/113 [00:10<00:11,  5.28it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 54/113 [00:10<00:11,  5.28it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/113 [00:10<00:10,  5.27it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/113 [00:10<00:10,  5.27it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/113 [00:10<00:10,  5.28it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/113 [00:10<00:10,  5.28it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/113 [00:10<00:10,  5.28it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/113 [00:10<00:10,  5.28it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 58/113 [00:10<00:10,  5.28it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 58/113 [00:10<00:10,  5.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/113 [00:11<00:10,  5.28it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/113 [00:11<00:10,  5.28it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/113 [00:11<00:10,  5.28it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/113 [00:11<00:10,  5.28it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 61/113 [00:11<00:09,  5.28it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 61/113 [00:11<00:09,  5.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/113 [00:11<00:09,  5.28it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/113 [00:11<00:09,  5.28it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/113 [00:11<00:09,  5.27it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/113 [00:11<00:09,  5.27it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 64/113 [00:12<00:09,  5.28it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 64/113 [00:12<00:09,  5.28it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 65/113 [00:12<00:09,  5.28it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 65/113 [00:12<00:09,  5.28it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/113 [00:12<00:08,  5.28it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/113 [00:12<00:08,  5.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/113 [00:12<00:08,  5.28it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/113 [00:12<00:08,  5.28it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 68/113 [00:12<00:08,  5.28it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 68/113 [00:12<00:08,  5.28it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/113 [00:13<00:08,  5.28it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/113 [00:13<00:08,  5.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/113 [00:13<00:08,  5.28it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/113 [00:13<00:08,  5.28it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 71/113 [00:13<00:07,  5.28it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 71/113 [00:13<00:07,  5.28it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/113 [00:13<00:07,  5.28it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/113 [00:13<00:07,  5.28it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/113 [00:13<00:07,  5.28it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/113 [00:13<00:07,  5.28it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 74/113 [00:14<00:07,  5.28it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 74/113 [00:14<00:07,  5.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 75/113 [00:14<00:07,  5.28it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 75/113 [00:14<00:07,  5.28it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/113 [00:14<00:07,  5.29it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/113 [00:14<00:07,  5.29it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/113 [00:14<00:06,  5.29it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/113 [00:14<00:06,  5.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 78/113 [00:14<00:06,  5.29it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 78/113 [00:14<00:06,  5.29it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/113 [00:14<00:06,  5.29it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/113 [00:14<00:06,  5.29it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/113 [00:15<00:06,  5.29it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/113 [00:15<00:06,  5.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 81/113 [00:15<00:06,  5.29it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 81/113 [00:15<00:06,  5.29it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 82/113 [00:15<00:05,  5.29it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 82/113 [00:15<00:05,  5.29it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/113 [00:15<00:05,  5.29it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/113 [00:15<00:05,  5.29it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 84/113 [00:15<00:05,  5.29it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 84/113 [00:15<00:05,  5.29it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 85/113 [00:16<00:05,  5.29it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 85/113 [00:16<00:05,  5.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/113 [00:16<00:05,  5.29it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/113 [00:16<00:05,  5.29it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/113 [00:16<00:04,  5.29it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/113 [00:16<00:04,  5.29it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 88/113 [00:16<00:04,  5.29it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 88/113 [00:16<00:04,  5.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 89/113 [00:16<00:04,  5.29it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 89/113 [00:16<00:04,  5.29it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/113 [00:17<00:04,  5.29it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/113 [00:17<00:04,  5.29it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 91/113 [00:17<00:04,  5.30it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 91/113 [00:17<00:04,  5.30it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 92/113 [00:17<00:03,  5.30it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 92/113 [00:17<00:03,  5.30it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/113 [00:17<00:03,  5.29it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/113 [00:17<00:03,  5.29it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 94/113 [00:17<00:03,  5.30it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 94/113 [00:17<00:03,  5.30it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 95/113 [00:17<00:03,  5.30it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 95/113 [00:17<00:03,  5.30it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/113 [00:18<00:03,  5.29it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/113 [00:18<00:03,  5.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/113 [00:18<00:03,  5.29it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/113 [00:18<00:03,  5.29it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 98/113 [00:18<00:02,  5.29it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 98/113 [00:18<00:02,  5.29it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 99/113 [00:18<00:02,  5.30it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 99/113 [00:18<00:02,  5.30it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/113 [00:18<00:02,  5.30it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/113 [00:18<00:02,  5.30it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 101/113 [00:19<00:02,  5.30it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 101/113 [00:19<00:02,  5.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 102/113 [00:19<00:02,  5.30it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 102/113 [00:19<00:02,  5.30it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/113 [00:19<00:01,  5.30it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/113 [00:19<00:01,  5.30it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 104/113 [00:19<00:01,  5.30it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 104/113 [00:19<00:01,  5.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 105/113 [00:19<00:01,  5.30it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 105/113 [00:19<00:01,  5.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 106/113 [00:20<00:01,  5.30it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 106/113 [00:20<00:01,  5.30it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/113 [00:20<00:01,  5.30it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/113 [00:20<00:01,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 108/113 [00:20<00:00,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 108/113 [00:20<00:00,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 109/113 [00:20<00:00,  5.30it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 109/113 [00:20<00:00,  5.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/113 [00:20<00:00,  5.30it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/113 [00:20<00:00,  5.30it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 111/113 [00:20<00:00,  5.30it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 111/113 [00:20<00:00,  5.30it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 112/113 [00:21<00:00,  5.30it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 112/113 [00:21<00:00,  5.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:21<00:00,  5.30it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:21<00:00,  5.30it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.padim.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.padim.lightning_model:Fitting a Gaussian to the embedding collected from the training set.

Validation:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   4%|â–         | 1/26 [00:00<00:02, 10.88it/s][A
Validation DataLoader 0:   8%|â–Š         | 2/26 [00:00<00:01, 17.30it/s][A
Validation DataLoader 0:  12%|â–ˆâ–        | 3/26 [00:00<00:03,  7.63it/s][A
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 4/26 [00:00<00:04,  5.32it/s][A
Validation DataLoader 0:  19%|â–ˆâ–‰        | 5/26 [00:01<00:04,  4.49it/s][A
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 6/26 [00:01<00:04,  4.08it/s][A
Validation DataLoader 0:  27%|â–ˆâ–ˆâ–‹       | 7/26 [00:01<00:04,  3.82it/s][A
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 8/26 [00:02<00:04,  3.66it/s][A
Validation DataLoader 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 9/26 [00:02<00:04,  3.54it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 10/26 [00:02<00:04,  3.40it/s][A
Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/26 [00:03<00:04,  3.36it/s][A
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/26 [00:03<00:04,  3.31it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 13/26 [00:03<00:03,  3.34it/s][A
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/26 [00:04<00:03,  3.42it/s][A
Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 15/26 [00:04<00:03,  3.49it/s][A
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/26 [00:04<00:02,  3.56it/s][A
Validation DataLoader 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 17/26 [00:04<00:02,  3.62it/s][A
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 18/26 [00:04<00:02,  3.67it/s][A
Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 19/26 [00:05<00:01,  3.72it/s][A
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 20/26 [00:05<00:01,  3.77it/s][A
Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 21/26 [00:05<00:01,  3.82it/s][A
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/26 [00:05<00:01,  3.86it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 23/26 [00:05<00:00,  3.90it/s][A
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 24/26 [00:06<00:00,  3.94it/s][A
Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 25/26 [00:06<00:00,  3.98it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:06<00:00,  4.11it/s][Aâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:161 in <module>    â”‚
â”‚                                                                              â”‚
â”‚   158 â”‚   â”‚   print("Image AUROC: {}, Pixel AUPRO: {}".format(image_AUROC, p â”‚
â”‚   159                                                                        â”‚
â”‚   160 if __name__ == '__main__':                                             â”‚
â”‚ â± 161 â”‚   main()                                                             â”‚
â”‚   162 â”‚   torch.cuda.empty_cache()                                           â”‚
â”‚   163                                                                        â”‚
â”‚   164                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:137 in main        â”‚
â”‚                                                                              â”‚
â”‚   134 â”‚                                                                      â”‚
â”‚   135 â”‚   # start training                                                   â”‚
â”‚   136 â”‚   engine = Engine(accelerator=args.gpu_type,task=TaskType.SEGMENTATI â”‚
â”‚ â± 137 â”‚   engine.fit(model=model, datamodule=datamodule)                     â”‚
â”‚   138 â”‚                                                                      â”‚
â”‚   139 â”‚   # load best model from checkpoint before evaluating                â”‚
â”‚   140 â”‚   test_results = engine.test(                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/engine/engine.p â”‚
â”‚ y:549 in fit                                                                 â”‚
â”‚                                                                              â”‚
â”‚    546 â”‚   â”‚   â”‚   # if the model is zero-shot or few-shot, we only need to  â”‚
â”‚    547 â”‚   â”‚   â”‚   self.trainer.validate(model, val_dataloaders, datamodule= â”‚
â”‚    548 â”‚   â”‚   else:                                                         â”‚
â”‚ â±  549 â”‚   â”‚   â”‚   self.trainer.fit(model, train_dataloaders, val_dataloader â”‚
â”‚    550 â”‚                                                                     â”‚
â”‚    551 â”‚   def validate(                                                     â”‚
â”‚    552 â”‚   â”‚   self,                                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:538 in fit              â”‚
â”‚                                                                              â”‚
â”‚    535 â”‚   â”‚   self.state.fn = TrainerFn.FITTING                             â”‚
â”‚    536 â”‚   â”‚   self.state.status = TrainerStatus.RUNNING                     â”‚
â”‚    537 â”‚   â”‚   self.training = True                                          â”‚
â”‚ â±  538 â”‚   â”‚   call._call_and_handle_interrupt(                              â”‚
â”‚    539 â”‚   â”‚   â”‚   self, self._fit_impl, model, train_dataloaders, val_datal â”‚
â”‚    540 â”‚   â”‚   )                                                             â”‚
â”‚    541                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/call.py:47 in                      â”‚
â”‚ _call_and_handle_interrupt                                                   â”‚
â”‚                                                                              â”‚
â”‚    44 â”‚   try:                                                               â”‚
â”‚    45 â”‚   â”‚   if trainer.strategy.launcher is not None:                      â”‚
â”‚    46 â”‚   â”‚   â”‚   return trainer.strategy.launcher.launch(trainer_fn, *args, â”‚
â”‚ â±  47 â”‚   â”‚   return trainer_fn(*args, **kwargs)                             â”‚
â”‚    48 â”‚                                                                      â”‚
â”‚    49 â”‚   except _TunerExitException:                                        â”‚
â”‚    50 â”‚   â”‚   _call_teardown_hook(trainer)                                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:574 in _fit_impl        â”‚
â”‚                                                                              â”‚
â”‚    571 â”‚   â”‚   â”‚   model_provided=True,                                      â”‚
â”‚    572 â”‚   â”‚   â”‚   model_connected=self.lightning_module is not None,        â”‚
â”‚    573 â”‚   â”‚   )                                                             â”‚
â”‚ â±  574 â”‚   â”‚   self._run(model, ckpt_path=ckpt_path)                         â”‚
â”‚    575 â”‚   â”‚                                                                 â”‚
â”‚    576 â”‚   â”‚   assert self.state.stopped                                     â”‚
â”‚    577 â”‚   â”‚   self.training = False                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:981 in _run             â”‚
â”‚                                                                              â”‚
â”‚    978 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    979 â”‚   â”‚   # RUN THE TRAINER                                             â”‚
â”‚    980 â”‚   â”‚   # ----------------------------                                â”‚
â”‚ â±  981 â”‚   â”‚   results = self._run_stage()                                   â”‚
â”‚    982 â”‚   â”‚                                                                 â”‚
â”‚    983 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    984 â”‚   â”‚   # POST-Training CLEAN UP                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:1025 in _run_stage      â”‚
â”‚                                                                              â”‚
â”‚   1022 â”‚   â”‚   â”‚   with isolate_rng():                                       â”‚
â”‚   1023 â”‚   â”‚   â”‚   â”‚   self._run_sanity_check()                              â”‚
â”‚   1024 â”‚   â”‚   â”‚   with torch.autograd.set_detect_anomaly(self._detect_anoma â”‚
â”‚ â± 1025 â”‚   â”‚   â”‚   â”‚   self.fit_loop.run()                                   â”‚
â”‚   1026 â”‚   â”‚   â”‚   return None                                               â”‚
â”‚   1027 â”‚   â”‚   raise RuntimeError(f"Unexpected state {self.state}")          â”‚
â”‚   1028                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:205 in run               â”‚
â”‚                                                                              â”‚
â”‚   202 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   203 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   204 â”‚   â”‚   â”‚   â”‚   self.on_advance_start()                                â”‚
â”‚ â± 205 â”‚   â”‚   â”‚   â”‚   self.advance()                                         â”‚
â”‚   206 â”‚   â”‚   â”‚   â”‚   self.on_advance_end()                                  â”‚
â”‚   207 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   208 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:363 in advance           â”‚
â”‚                                                                              â”‚
â”‚   360 â”‚   â”‚   â”‚   )                                                          â”‚
â”‚   361 â”‚   â”‚   with self.trainer.profiler.profile("run_training_epoch"):      â”‚
â”‚   362 â”‚   â”‚   â”‚   assert self._data_fetcher is not None                      â”‚
â”‚ â± 363 â”‚   â”‚   â”‚   self.epoch_loop.run(self._data_fetcher)                    â”‚
â”‚   364 â”‚                                                                      â”‚
â”‚   365 â”‚   def on_advance_end(self) -> None:                                  â”‚
â”‚   366 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:141 in run    â”‚
â”‚                                                                              â”‚
â”‚   138 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   139 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self.advance(data_fetcher)                             â”‚
â”‚ â± 141 â”‚   â”‚   â”‚   â”‚   self.on_advance_end(data_fetcher)                      â”‚
â”‚   142 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   143 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚   144 â”‚   â”‚   â”‚   â”‚   break                                                  â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:295 in        â”‚
â”‚ on_advance_end                                                               â”‚
â”‚                                                                              â”‚
â”‚   292 â”‚   â”‚   â”‚   â”‚   # clear gradients to not leave any unused memory durin â”‚
â”‚   293 â”‚   â”‚   â”‚   â”‚   call._call_lightning_module_hook(self.trainer, "on_val â”‚
â”‚   294 â”‚   â”‚   â”‚                                                              â”‚
â”‚ â± 295 â”‚   â”‚   â”‚   self.val_loop.run()                                        â”‚
â”‚   296 â”‚   â”‚   â”‚   self.trainer.training = True                               â”‚
â”‚   297 â”‚   â”‚   â”‚   self.trainer._logger_connector._first_loop_iter = first_lo â”‚
â”‚   298                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/utilities.py:178 in _decorator       â”‚
â”‚                                                                              â”‚
â”‚   175 â”‚   â”‚   else:                                                          â”‚
â”‚   176 â”‚   â”‚   â”‚   context_manager = torch.no_grad                            â”‚
â”‚   177 â”‚   â”‚   with context_manager():                                        â”‚
â”‚ â± 178 â”‚   â”‚   â”‚   return loop_run(self, *args, **kwargs)                     â”‚
â”‚   179 â”‚                                                                      â”‚
â”‚   180 â”‚   return _decorator                                                  â”‚
â”‚   181                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:142 in run        â”‚
â”‚                                                                              â”‚
â”‚   139 â”‚   â”‚   â”‚   finally:                                                   â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   141 â”‚   â”‚   self._store_dataloader_outputs()                               â”‚
â”‚ â± 142 â”‚   â”‚   return self.on_run_end()                                       â”‚
â”‚   143 â”‚                                                                      â”‚
â”‚   144 â”‚   def setup_data(self) -> None:                                      â”‚
â”‚   145 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:254 in on_run_end â”‚
â”‚                                                                              â”‚
â”‚   251 â”‚   â”‚   self.trainer._logger_connector._evaluation_epoch_end()         â”‚
â”‚   252 â”‚   â”‚                                                                  â”‚
â”‚   253 â”‚   â”‚   # hook                                                         â”‚
â”‚ â± 254 â”‚   â”‚   self._on_evaluation_epoch_end()                                â”‚
â”‚   255 â”‚   â”‚                                                                  â”‚
â”‚   256 â”‚   â”‚   logged_outputs, self._logged_outputs = self._logged_outputs, [ â”‚
â”‚   257 â”‚   â”‚   # include any logged outputs on epoch_end                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:336 in            â”‚
â”‚ _on_evaluation_epoch_end                                                     â”‚
â”‚                                                                              â”‚
â”‚   333 â”‚   â”‚   call._call_callback_hooks(trainer, hook_name)                  â”‚
â”‚   334 â”‚   â”‚   call._call_lightning_module_hook(trainer, hook_name)           â”‚
â”‚   335 â”‚   â”‚                                                                  â”‚
â”‚ â± 336 â”‚   â”‚   trainer._logger_connector.on_epoch_end()                       â”‚
â”‚   337 â”‚                                                                      â”‚
â”‚   338 â”‚   def _store_dataloader_outputs(self) -> None:                       â”‚
â”‚   339 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:195 in on_epoch_end                                            â”‚
â”‚                                                                              â”‚
â”‚   192 â”‚                                                                      â”‚
â”‚   193 â”‚   def on_epoch_end(self) -> None:                                    â”‚
â”‚   194 â”‚   â”‚   assert self._first_loop_iter is None                           â”‚
â”‚ â± 195 â”‚   â”‚   metrics = self.metrics                                         â”‚
â”‚   196 â”‚   â”‚   self._progress_bar_metrics.update(metrics["pbar"])             â”‚
â”‚   197 â”‚   â”‚   self._callback_metrics.update(metrics["callback"])             â”‚
â”‚   198 â”‚   â”‚   self._logged_metrics.update(metrics["log"])                    â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:234 in metrics                                                 â”‚
â”‚                                                                              â”‚
â”‚   231 â”‚   â”‚   """This function returns either batch or epoch metrics."""     â”‚
â”‚   232 â”‚   â”‚   on_step = self._first_loop_iter is not None                    â”‚
â”‚   233 â”‚   â”‚   assert self.trainer._results is not None                       â”‚
â”‚ â± 234 â”‚   â”‚   return self.trainer._results.metrics(on_step)                  â”‚
â”‚   235 â”‚                                                                      â”‚
â”‚   236 â”‚   @property                                                          â”‚
â”‚   237 â”‚   def callback_metrics(self) -> _OUT_DICT:                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:473 in metrics                                                           â”‚
â”‚                                                                              â”‚
â”‚   470 â”‚   â”‚                                                                  â”‚
â”‚   471 â”‚   â”‚   for _, result_metric in self.valid_items():                    â”‚
â”‚   472 â”‚   â”‚   â”‚   # extract forward_cache or computed from the _ResultMetric â”‚
â”‚ â± 473 â”‚   â”‚   â”‚   value = self._get_cache(result_metric, on_step)            â”‚
â”‚   474 â”‚   â”‚   â”‚   if not isinstance(value, Tensor):                          â”‚
â”‚   475 â”‚   â”‚   â”‚   â”‚   continue                                               â”‚
â”‚   476                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:437 in _get_cache                                                        â”‚
â”‚                                                                              â”‚
â”‚   434 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   " devices.",                                   â”‚
â”‚   435 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   category=PossibleUserWarning,                  â”‚
â”‚   436 â”‚   â”‚   â”‚   â”‚   â”‚   )                                                  â”‚
â”‚ â± 437 â”‚   â”‚   â”‚   â”‚   result_metric.compute()                                â”‚
â”‚   438 â”‚   â”‚   â”‚   â”‚   result_metric.meta.sync.should = should                â”‚
â”‚   439 â”‚   â”‚   â”‚                                                              â”‚
â”‚   440 â”‚   â”‚   â”‚   cache = result_metric._computed                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:288 in wrapped_func                                                      â”‚
â”‚                                                                              â”‚
â”‚   285 â”‚   â”‚   â”‚   # return cached value                                      â”‚
â”‚   286 â”‚   â”‚   â”‚   if self._computed is not None:                             â”‚
â”‚   287 â”‚   â”‚   â”‚   â”‚   return self._computed                                  â”‚
â”‚ â± 288 â”‚   â”‚   â”‚   self._computed = compute(*args, **kwargs)                  â”‚
â”‚   289 â”‚   â”‚   â”‚   return self._computed                                      â”‚
â”‚   290 â”‚   â”‚                                                                  â”‚
â”‚   291 â”‚   â”‚   return wrapped_func                                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:253 in compute                                                           â”‚
â”‚                                                                              â”‚
â”‚   250 â”‚   â”‚   â”‚   â”‚   cumulated_batch_size = self.meta.sync(self.cumulated_b â”‚
â”‚   251 â”‚   â”‚   â”‚   â”‚   return value / cumulated_batch_size                    â”‚
â”‚   252 â”‚   â”‚   â”‚   return value                                               â”‚
â”‚ â± 253 â”‚   â”‚   return self.value.compute()                                    â”‚
â”‚   254 â”‚                                                                      â”‚
â”‚   255 â”‚   @override                                                          â”‚
â”‚   256 â”‚   def reset(self) -> None:                                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/metric.py:700 in wrapped_func                   â”‚
â”‚                                                                              â”‚
â”‚    697 â”‚   â”‚   â”‚   â”‚   should_sync=self._to_sync,                            â”‚
â”‚    698 â”‚   â”‚   â”‚   â”‚   should_unsync=self._should_unsync,                    â”‚
â”‚    699 â”‚   â”‚   â”‚   ):                                                        â”‚
â”‚ â±  700 â”‚   â”‚   â”‚   â”‚   value = _squeeze_if_scalar(compute(*args, **kwargs))  â”‚
â”‚    701 â”‚   â”‚   â”‚   â”‚   # clone tensor to avoid in-place operations after com â”‚
â”‚    702 â”‚   â”‚   â”‚   â”‚   value = apply_to_collection(value, Tensor, lambda x:  â”‚
â”‚    703                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:241 in compute                                                             â”‚
â”‚                                                                              â”‚
â”‚   238 â”‚   â”‚   Returns:                                                       â”‚
â”‚   239 â”‚   â”‚   â”‚   Tensor: Value of the AUPRO metric                          â”‚
â”‚   240 â”‚   â”‚   """                                                            â”‚
â”‚ â± 241 â”‚   â”‚   fpr, tpr = self._compute()                                     â”‚
â”‚   242 â”‚   â”‚                                                                  â”‚
â”‚   243 â”‚   â”‚   aupro = auc(fpr, tpr, reorder=True)                            â”‚
â”‚   244 â”‚   â”‚   return aupro / fpr[-1]  # normalize the area                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:229 in _compute                                                            â”‚
â”‚                                                                              â”‚
â”‚   226 â”‚   â”‚   Returns:                                                       â”‚
â”‚   227 â”‚   â”‚   â”‚   tuple[torch.Tensor, torch.Tensor]: tuple containing final  â”‚
â”‚   228 â”‚   â”‚   """                                                            â”‚
â”‚ â± 229 â”‚   â”‚   cca = self.perform_cca().flatten()                             â”‚
â”‚   230 â”‚   â”‚   target = dim_zero_cat(self.target).flatten()                   â”‚
â”‚   231 â”‚   â”‚   preds = dim_zero_cat(self.preds).flatten()                     â”‚
â”‚   232                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:108 in perform_cca                                                         â”‚
â”‚                                                                              â”‚
â”‚   105 â”‚   â”‚   Returns:                                                       â”‚
â”‚   106 â”‚   â”‚   â”‚   Tensor: Components labeled from 0 to N.                    â”‚
â”‚   107 â”‚   â”‚   """                                                            â”‚
â”‚ â± 108 â”‚   â”‚   target = dim_zero_cat(self.target)                             â”‚
â”‚   109 â”‚   â”‚                                                                  â”‚
â”‚   110 â”‚   â”‚   # check and prepare target for labeling via kornia             â”‚
â”‚   111 â”‚   â”‚   if target.min() < 0 or target.max() > 1:                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/utilities/data.py:36 in dim_zero_cat            â”‚
â”‚                                                                              â”‚
â”‚    33 â”‚   x = [y.unsqueeze(0) if y.numel() == 1 and y.ndim == 0 else y for y â”‚
â”‚    34 â”‚   if not x:  # empty list                                            â”‚
â”‚    35 â”‚   â”‚   raise ValueError("No samples to concatenate")                  â”‚
â”‚ â±  36 â”‚   return torch.cat(x, dim=0)                                         â”‚
â”‚    37                                                                        â”‚
â”‚    38                                                                        â”‚
â”‚    39 def dim_zero_sum(x: Tensor) -> Tensor:                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:34<00:00,  3.31it/s]

                                                                        [A/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | PatchcoreModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb3 with model patchcore
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/114 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/114 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   1%|          | 1/114 [00:00<00:50,  2.25it/s]Epoch 0:   1%|          | 1/114 [00:00<00:50,  2.25it/s]Epoch 0:   2%|â–         | 2/114 [00:00<00:25,  4.42it/s]Epoch 0:   2%|â–         | 2/114 [00:00<00:25,  4.42it/s]Epoch 0:   3%|â–Ž         | 3/114 [00:00<00:23,  4.71it/s]Epoch 0:   3%|â–Ž         | 3/114 [00:00<00:23,  4.71it/s]Epoch 0:   4%|â–Ž         | 4/114 [00:00<00:22,  4.80it/s]Epoch 0:   4%|â–Ž         | 4/114 [00:00<00:22,  4.80it/s]Epoch 0:   4%|â–         | 5/114 [00:01<00:22,  4.86it/s]Epoch 0:   4%|â–         | 5/114 [00:01<00:22,  4.86it/s]Epoch 0:   5%|â–Œ         | 6/114 [00:01<00:22,  4.90it/s]Epoch 0:   5%|â–Œ         | 6/114 [00:01<00:22,  4.90it/s]Epoch 0:   6%|â–Œ         | 7/114 [00:01<00:21,  4.93it/s]Epoch 0:   6%|â–Œ         | 7/114 [00:01<00:21,  4.93it/s]Epoch 0:   7%|â–‹         | 8/114 [00:01<00:21,  4.95it/s]Epoch 0:   7%|â–‹         | 8/114 [00:01<00:21,  4.95it/s]Epoch 0:   8%|â–Š         | 9/114 [00:01<00:21,  4.96it/s]Epoch 0:   8%|â–Š         | 9/114 [00:01<00:21,  4.96it/s]Epoch 0:   9%|â–‰         | 10/114 [00:02<00:20,  4.98it/s]Epoch 0:   9%|â–‰         | 10/114 [00:02<00:20,  4.98it/s]Epoch 0:  10%|â–‰         | 11/114 [00:02<00:20,  4.99it/s]Epoch 0:  10%|â–‰         | 11/114 [00:02<00:20,  4.99it/s]Epoch 0:  11%|â–ˆ         | 12/114 [00:02<00:20,  5.00it/s]Epoch 0:  11%|â–ˆ         | 12/114 [00:02<00:20,  5.00it/s]Epoch 0:  11%|â–ˆâ–        | 13/114 [00:02<00:20,  5.00it/s]Epoch 0:  11%|â–ˆâ–        | 13/114 [00:02<00:20,  5.00it/s]Epoch 0:  12%|â–ˆâ–        | 14/114 [00:02<00:19,  5.01it/s]Epoch 0:  12%|â–ˆâ–        | 14/114 [00:02<00:19,  5.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/114 [00:03<00:19,  4.98it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/114 [00:03<00:19,  4.98it/s]Epoch 0:  14%|â–ˆâ–        | 16/114 [00:03<00:19,  4.95it/s]Epoch 0:  14%|â–ˆâ–        | 16/114 [00:03<00:19,  4.95it/s]Epoch 0:  15%|â–ˆâ–        | 17/114 [00:03<00:19,  4.95it/s]Epoch 0:  15%|â–ˆâ–        | 17/114 [00:03<00:19,  4.95it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/114 [00:03<00:19,  4.94it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/114 [00:03<00:19,  4.94it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/114 [00:03<00:19,  4.94it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/114 [00:03<00:19,  4.94it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/114 [00:04<00:19,  4.93it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/114 [00:04<00:19,  4.93it/s]Epoch 0:  18%|â–ˆâ–Š        | 21/114 [00:04<00:18,  4.92it/s]Epoch 0:  18%|â–ˆâ–Š        | 21/114 [00:04<00:18,  4.92it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/114 [00:04<00:18,  4.92it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/114 [00:04<00:18,  4.92it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/114 [00:04<00:18,  4.91it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/114 [00:04<00:18,  4.91it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/114 [00:04<00:18,  4.91it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/114 [00:04<00:18,  4.91it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/114 [00:05<00:18,  4.89it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/114 [00:05<00:18,  4.89it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/114 [00:05<00:17,  4.89it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/114 [00:05<00:17,  4.89it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 27/114 [00:05<00:17,  4.90it/s]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 27/114 [00:05<00:17,  4.90it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/114 [00:05<00:17,  4.90it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/114 [00:05<00:17,  4.90it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 29/114 [00:05<00:17,  4.90it/s]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 29/114 [00:05<00:17,  4.90it/s]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 30/114 [00:06<00:17,  4.91it/s]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 30/114 [00:06<00:17,  4.91it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/114 [00:06<00:16,  4.91it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/114 [00:06<00:16,  4.91it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/114 [00:06<00:16,  4.91it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/114 [00:06<00:16,  4.91it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/114 [00:06<00:16,  4.92it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/114 [00:06<00:16,  4.92it/s]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 34/114 [00:06<00:16,  4.93it/s]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 34/114 [00:06<00:16,  4.93it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/114 [00:07<00:16,  4.94it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/114 [00:07<00:16,  4.94it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/114 [00:07<00:15,  4.94it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/114 [00:07<00:15,  4.94it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 37/114 [00:07<00:15,  4.94it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 37/114 [00:07<00:15,  4.94it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/114 [00:07<00:15,  4.94it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/114 [00:07<00:15,  4.94it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 39/114 [00:07<00:15,  4.95it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 39/114 [00:07<00:15,  4.95it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/114 [00:08<00:14,  4.95it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/114 [00:08<00:14,  4.95it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 41/114 [00:08<00:14,  4.95it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 41/114 [00:08<00:14,  4.95it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/114 [00:08<00:14,  4.95it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/114 [00:08<00:14,  4.95it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/114 [00:08<00:14,  4.96it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/114 [00:08<00:14,  4.96it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 44/114 [00:08<00:14,  4.96it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 44/114 [00:08<00:14,  4.96it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 45/114 [00:09<00:13,  4.96it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 45/114 [00:09<00:13,  4.96it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/114 [00:09<00:13,  4.96it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/114 [00:09<00:13,  4.96it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 47/114 [00:09<00:13,  4.97it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 47/114 [00:09<00:13,  4.97it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/114 [00:09<00:13,  4.97it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/114 [00:09<00:13,  4.97it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/114 [00:09<00:13,  4.97it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/114 [00:09<00:13,  4.97it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/114 [00:10<00:12,  4.98it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/114 [00:10<00:12,  4.98it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 51/114 [00:10<00:12,  4.98it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 51/114 [00:10<00:12,  4.98it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/114 [00:10<00:12,  4.98it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/114 [00:10<00:12,  4.98it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/114 [00:10<00:12,  4.98it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/114 [00:10<00:12,  4.98it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 54/114 [00:10<00:12,  4.99it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 54/114 [00:10<00:12,  4.99it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/114 [00:11<00:11,  4.99it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/114 [00:11<00:11,  4.99it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/114 [00:11<00:11,  4.99it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/114 [00:11<00:11,  4.99it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/114 [00:11<00:11,  4.99it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/114 [00:11<00:11,  4.99it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 58/114 [00:11<00:11,  5.00it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 58/114 [00:11<00:11,  5.00it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/114 [00:11<00:10,  5.01it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/114 [00:11<00:10,  5.01it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/114 [00:11<00:10,  5.01it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/114 [00:11<00:10,  5.01it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 61/114 [00:12<00:10,  5.01it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 61/114 [00:12<00:10,  5.01it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/114 [00:12<00:10,  5.01it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/114 [00:12<00:10,  5.01it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/114 [00:12<00:10,  5.02it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/114 [00:12<00:10,  5.02it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 64/114 [00:12<00:09,  5.02it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 64/114 [00:12<00:09,  5.02it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 65/114 [00:12<00:09,  5.02it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 65/114 [00:12<00:09,  5.02it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/114 [00:13<00:09,  5.02it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/114 [00:13<00:09,  5.02it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/114 [00:13<00:09,  5.02it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/114 [00:13<00:09,  5.02it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 68/114 [00:13<00:09,  5.03it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 68/114 [00:13<00:09,  5.03it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/114 [00:13<00:08,  5.03it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/114 [00:13<00:08,  5.03it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/114 [00:13<00:08,  5.03it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/114 [00:13<00:08,  5.03it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 71/114 [00:14<00:08,  5.03it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 71/114 [00:14<00:08,  5.03it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/114 [00:14<00:08,  5.03it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/114 [00:14<00:08,  5.03it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/114 [00:14<00:08,  5.03it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/114 [00:14<00:08,  5.03it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 74/114 [00:14<00:07,  5.04it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 74/114 [00:14<00:07,  5.04it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 75/114 [00:14<00:07,  5.04it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 75/114 [00:14<00:07,  5.04it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/114 [00:15<00:07,  5.04it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/114 [00:15<00:07,  5.04it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/114 [00:15<00:07,  5.04it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/114 [00:15<00:07,  5.04it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 78/114 [00:15<00:07,  5.04it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 78/114 [00:15<00:07,  5.04it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/114 [00:15<00:06,  5.04it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/114 [00:15<00:06,  5.04it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/114 [00:15<00:06,  5.05it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/114 [00:15<00:06,  5.05it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 81/114 [00:16<00:06,  5.05it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 81/114 [00:16<00:06,  5.05it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 82/114 [00:16<00:06,  5.05it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 82/114 [00:16<00:06,  5.05it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/114 [00:16<00:06,  5.05it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/114 [00:16<00:06,  5.05it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 84/114 [00:16<00:05,  5.05it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 84/114 [00:16<00:05,  5.05it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 85/114 [00:16<00:05,  5.05it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 85/114 [00:16<00:05,  5.05it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/114 [00:17<00:05,  5.05it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/114 [00:17<00:05,  5.05it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/114 [00:17<00:05,  5.05it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/114 [00:17<00:05,  5.05it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 88/114 [00:17<00:05,  5.05it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 88/114 [00:17<00:05,  5.05it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 89/114 [00:17<00:04,  5.05it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 89/114 [00:17<00:04,  5.05it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/114 [00:17<00:04,  5.05it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/114 [00:17<00:04,  5.05it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 91/114 [00:18<00:04,  5.05it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 91/114 [00:18<00:04,  5.05it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 92/114 [00:18<00:04,  5.05it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 92/114 [00:18<00:04,  5.05it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/114 [00:18<00:04,  5.05it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/114 [00:18<00:04,  5.05it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 94/114 [00:18<00:03,  5.05it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 94/114 [00:18<00:03,  5.05it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 95/114 [00:18<00:03,  5.05it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 95/114 [00:18<00:03,  5.05it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/114 [00:19<00:03,  5.05it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/114 [00:19<00:03,  5.05it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/114 [00:19<00:03,  5.05it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/114 [00:19<00:03,  5.05it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 98/114 [00:19<00:03,  5.05it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 98/114 [00:19<00:03,  5.05it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 99/114 [00:19<00:02,  5.05it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 99/114 [00:19<00:02,  5.05it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/114 [00:19<00:02,  5.05it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/114 [00:19<00:02,  5.05it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 101/114 [00:19<00:02,  5.06it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 101/114 [00:19<00:02,  5.06it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 102/114 [00:20<00:02,  5.06it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 102/114 [00:20<00:02,  5.06it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/114 [00:20<00:02,  5.06it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/114 [00:20<00:02,  5.06it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 104/114 [00:20<00:01,  5.06it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 104/114 [00:20<00:01,  5.06it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 105/114 [00:20<00:01,  5.06it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 105/114 [00:20<00:01,  5.06it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 106/114 [00:20<00:01,  5.06it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 106/114 [00:20<00:01,  5.06it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/114 [00:21<00:01,  5.06it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/114 [00:21<00:01,  5.06it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 108/114 [00:21<00:01,  5.06it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 108/114 [00:21<00:01,  5.06it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 109/114 [00:21<00:00,  5.06it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 109/114 [00:21<00:00,  5.06it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/114 [00:21<00:00,  5.06it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/114 [00:21<00:00,  5.06it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 111/114 [00:21<00:00,  5.06it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 111/114 [00:21<00:00,  5.06it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 112/114 [00:22<00:00,  5.06it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 112/114 [00:22<00:00,  5.06it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 113/114 [00:22<00:00,  5.06it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 113/114 [00:22<00:00,  5.06it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:22<00:00,  5.10it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:22<00:00,  5.10it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.patchcore.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.patchcore.lightning_model:Applying core-set subsampling to get the embedding.


Selecting Coreset Indices.:   0%|          | 0/57920 [00:00<?, ?it/s][A[A

Selecting Coreset Indices.:   0%|          | 1/57920 [00:00<4:47:31,  3.36it/s][A[A

Selecting Coreset Indices.:   0%|          | 18/57920 [00:00<16:57, 56.89it/s] [A[A

Selecting Coreset Indices.:   0%|          | 36/57920 [00:00<10:07, 95.24it/s][A[A

Selecting Coreset Indices.:   0%|          | 54/57920 [00:00<07:58, 120.96it/s][A[A

Selecting Coreset Indices.:   0%|          | 72/57920 [00:00<06:57, 138.61it/s][A[A

Selecting Coreset Indices.:   0%|          | 90/57920 [00:00<06:23, 150.75it/s][A[A

Selecting Coreset Indices.:   0%|          | 108/57920 [00:00<06:07, 157.39it/s][A[A

Selecting Coreset Indices.:   0%|          | 126/57920 [00:01<05:53, 163.62it/s][A[A

Selecting Coreset Indices.:   0%|          | 144/57920 [00:01<05:43, 168.04it/s][A[A

Selecting Coreset Indices.:   0%|          | 162/57920 [00:01<05:37, 171.14it/s][A[A

Selecting Coreset Indices.:   0%|          | 180/57920 [00:01<05:33, 173.30it/s][A[A

Selecting Coreset Indices.:   0%|          | 198/57920 [00:01<05:30, 174.82it/s][A[A

Selecting Coreset Indices.:   0%|          | 216/57920 [00:01<05:28, 175.89it/s][A[A

Selecting Coreset Indices.:   0%|          | 234/57920 [00:01<05:26, 176.64it/s][A[A

Selecting Coreset Indices.:   0%|          | 252/57920 [00:01<05:25, 177.15it/s][A[A

Selecting Coreset Indices.:   0%|          | 270/57920 [00:01<05:24, 177.53it/s][A[A

Selecting Coreset Indices.:   0%|          | 288/57920 [00:01<05:24, 177.79it/s][A[A

Selecting Coreset Indices.:   1%|          | 306/57920 [00:02<05:23, 177.96it/s][A[A

Selecting Coreset Indices.:   1%|          | 324/57920 [00:02<05:23, 178.07it/s][A[A

Selecting Coreset Indices.:   1%|          | 342/57920 [00:02<05:23, 178.17it/s][A[A

Selecting Coreset Indices.:   1%|          | 360/57920 [00:02<05:22, 178.23it/s][A[A

Selecting Coreset Indices.:   1%|          | 378/57920 [00:02<05:22, 178.27it/s][A[A

Selecting Coreset Indices.:   1%|          | 396/57920 [00:02<05:22, 178.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 414/57920 [00:02<05:22, 178.31it/s][A[A

Selecting Coreset Indices.:   1%|          | 432/57920 [00:02<05:22, 178.34it/s][A[A

Selecting Coreset Indices.:   1%|          | 450/57920 [00:02<05:22, 178.35it/s][A[A

Selecting Coreset Indices.:   1%|          | 468/57920 [00:02<05:22, 178.35it/s][A[A

Selecting Coreset Indices.:   1%|          | 486/57920 [00:03<05:21, 178.37it/s][A[A

Selecting Coreset Indices.:   1%|          | 504/57920 [00:03<05:24, 177.20it/s][A[A

Selecting Coreset Indices.:   1%|          | 522/57920 [00:03<05:23, 177.47it/s][A[A

Selecting Coreset Indices.:   1%|          | 540/57920 [00:03<05:22, 177.70it/s][A[A

Selecting Coreset Indices.:   1%|          | 558/57920 [00:03<05:22, 177.88it/s][A[A

Selecting Coreset Indices.:   1%|          | 576/57920 [00:03<05:22, 178.01it/s][A[A

Selecting Coreset Indices.:   1%|          | 594/57920 [00:03<05:21, 178.10it/s][A[A

Selecting Coreset Indices.:   1%|          | 612/57920 [00:03<05:21, 178.20it/s][A[A

Selecting Coreset Indices.:   1%|          | 630/57920 [00:03<05:21, 178.26it/s][A[A

Selecting Coreset Indices.:   1%|          | 648/57920 [00:03<05:21, 178.31it/s][A[A

Selecting Coreset Indices.:   1%|          | 666/57920 [00:04<05:21, 178.34it/s][A[A

Selecting Coreset Indices.:   1%|          | 684/57920 [00:04<05:20, 178.36it/s][A[A

Selecting Coreset Indices.:   1%|          | 702/57920 [00:04<05:20, 178.36it/s][A[A

Selecting Coreset Indices.:   1%|          | 720/57920 [00:04<05:20, 178.34it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 738/57920 [00:04<05:20, 178.34it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 756/57920 [00:04<05:20, 178.32it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 774/57920 [00:04<05:20, 178.34it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 792/57920 [00:04<05:20, 178.34it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 810/57920 [00:04<05:20, 178.35it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 828/57920 [00:04<05:20, 178.37it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 846/57920 [00:05<05:19, 178.37it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 864/57920 [00:05<05:19, 178.37it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 882/57920 [00:05<05:19, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 900/57920 [00:05<05:19, 178.39it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 918/57920 [00:05<05:19, 178.39it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 936/57920 [00:05<05:19, 178.39it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 954/57920 [00:05<05:19, 178.39it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 972/57920 [00:05<05:19, 178.39it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 990/57920 [00:05<05:19, 178.40it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1008/57920 [00:05<05:19, 178.37it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1026/57920 [00:06<05:18, 178.36it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1044/57920 [00:06<05:19, 178.24it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1062/57920 [00:06<05:19, 178.20it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1080/57920 [00:06<05:18, 178.24it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1098/57920 [00:06<05:18, 178.24it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1116/57920 [00:06<05:18, 178.25it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1134/57920 [00:06<05:18, 178.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1152/57920 [00:06<05:18, 178.25it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1170/57920 [00:06<05:18, 178.20it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1188/57920 [00:06<05:18, 178.28it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1206/57920 [00:07<05:18, 178.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1224/57920 [00:07<05:17, 178.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1242/57920 [00:07<05:17, 178.36it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1260/57920 [00:07<05:17, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1278/57920 [00:07<05:17, 178.37it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1296/57920 [00:07<05:17, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1314/57920 [00:07<05:17, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1332/57920 [00:07<05:17, 178.36it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1350/57920 [00:07<05:17, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1368/57920 [00:07<05:17, 178.36it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1386/57920 [00:08<05:16, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1404/57920 [00:08<05:16, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1422/57920 [00:08<05:16, 178.38it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1440/57920 [00:08<05:16, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1458/57920 [00:08<05:16, 178.38it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1476/57920 [00:08<05:16, 178.37it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1494/57920 [00:08<05:16, 178.37it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1512/57920 [00:08<05:16, 178.37it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1530/57920 [00:08<05:16, 178.38it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1548/57920 [00:08<05:16, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1566/57920 [00:09<05:15, 178.36it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1584/57920 [00:09<05:15, 178.37it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1602/57920 [00:09<05:15, 178.37it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1620/57920 [00:09<05:15, 178.37it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1638/57920 [00:09<05:15, 178.38it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1656/57920 [00:09<05:15, 178.38it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1674/57920 [00:09<05:15, 178.40it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1692/57920 [00:09<05:15, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1710/57920 [00:09<05:15, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1728/57920 [00:09<05:14, 178.41it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1746/57920 [00:10<05:14, 178.40it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1764/57920 [00:10<05:14, 178.38it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1782/57920 [00:10<05:14, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1800/57920 [00:10<05:14, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1818/57920 [00:10<05:14, 178.41it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1836/57920 [00:10<05:14, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1854/57920 [00:10<05:14, 178.37it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1872/57920 [00:10<05:14, 178.36it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1890/57920 [00:10<05:14, 178.38it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1908/57920 [00:11<05:14, 178.38it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1926/57920 [00:11<05:13, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1944/57920 [00:11<05:13, 178.39it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1962/57920 [00:11<05:13, 178.40it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1980/57920 [00:11<05:13, 178.42it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1998/57920 [00:11<05:13, 178.41it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2016/57920 [00:11<05:13, 178.38it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2034/57920 [00:11<05:13, 178.37it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2052/57920 [00:11<05:13, 178.39it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2070/57920 [00:11<05:13, 178.38it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2088/57920 [00:12<05:12, 178.39it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2106/57920 [00:12<05:12, 178.39it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2124/57920 [00:12<05:12, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2142/57920 [00:12<05:12, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2160/57920 [00:12<05:12, 178.41it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2178/57920 [00:12<05:12, 178.42it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2196/57920 [00:12<05:12, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2214/57920 [00:12<05:12, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2232/57920 [00:12<05:12, 178.39it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2250/57920 [00:12<05:12, 178.38it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2268/57920 [00:13<05:11, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2286/57920 [00:13<05:11, 178.41it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2304/57920 [00:13<05:11, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2322/57920 [00:13<05:11, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2340/57920 [00:13<05:11, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2358/57920 [00:13<05:11, 178.39it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2376/57920 [00:13<05:11, 178.37it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2394/57920 [00:13<05:11, 178.38it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2412/57920 [00:13<05:11, 178.39it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2430/57920 [00:13<05:11, 178.40it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2448/57920 [00:14<05:10, 178.38it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2466/57920 [00:14<05:10, 178.37it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2484/57920 [00:14<05:10, 178.37it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2502/57920 [00:14<05:11, 178.14it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2520/57920 [00:14<05:10, 178.21it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2538/57920 [00:14<05:10, 178.25it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2556/57920 [00:14<05:10, 178.31it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2574/57920 [00:14<05:12, 177.04it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2592/57920 [00:14<05:11, 177.42it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2610/57920 [00:14<05:11, 177.71it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2628/57920 [00:15<05:10, 177.92it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2646/57920 [00:15<05:10, 178.01it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2664/57920 [00:15<05:10, 178.11it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2682/57920 [00:15<05:10, 178.17it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2700/57920 [00:15<05:09, 178.23it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2718/57920 [00:15<05:09, 178.28it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2736/57920 [00:15<05:10, 177.88it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2754/57920 [00:15<05:09, 177.99it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2772/57920 [00:15<05:09, 178.09it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2790/57920 [00:15<05:09, 178.21it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2808/57920 [00:16<05:09, 178.27it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2826/57920 [00:16<05:09, 178.29it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2844/57920 [00:16<05:08, 178.34it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2862/57920 [00:16<05:08, 178.36it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 2880/57920 [00:16<05:08, 178.37it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 2898/57920 [00:16<05:08, 178.38it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 2916/57920 [00:16<05:08, 178.38it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 2934/57920 [00:16<05:08, 178.39it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 2952/57920 [00:16<05:08, 178.40it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 2970/57920 [00:16<05:08, 178.40it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 2988/57920 [00:17<05:07, 178.41it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3006/57920 [00:17<05:07, 178.40it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3024/57920 [00:17<05:07, 178.41it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3042/57920 [00:17<05:07, 178.41it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3060/57920 [00:17<05:07, 178.40it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3078/57920 [00:17<05:07, 178.39it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3096/57920 [00:17<05:07, 178.39it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3114/57920 [00:17<05:07, 178.40it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3132/57920 [00:17<05:07, 178.37it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3150/57920 [00:17<05:07, 178.37it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3168/57920 [00:18<05:06, 178.38it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3186/57920 [00:18<05:06, 178.37it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3204/57920 [00:18<05:06, 178.39it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3222/57920 [00:18<05:06, 178.40it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3240/57920 [00:18<05:06, 178.41it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3258/57920 [00:18<05:06, 178.40it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3276/57920 [00:18<05:06, 178.41it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3294/57920 [00:18<05:06, 178.39it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3312/57920 [00:18<05:06, 178.41it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3330/57920 [00:18<05:05, 178.42it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3348/57920 [00:19<05:05, 178.39it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3366/57920 [00:19<05:05, 178.37it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3384/57920 [00:19<05:05, 178.38it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3402/57920 [00:19<05:05, 178.38it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3420/57920 [00:19<05:05, 178.39it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3438/57920 [00:19<05:06, 177.74it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3456/57920 [00:19<05:06, 177.90it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3474/57920 [00:19<05:05, 178.03it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3492/57920 [00:19<05:05, 178.12it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3510/57920 [00:19<05:05, 178.21it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3528/57920 [00:20<05:05, 178.23it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3546/57920 [00:20<05:05, 178.27it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3564/57920 [00:20<05:04, 178.30it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3582/57920 [00:20<05:04, 178.31it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3600/57920 [00:20<05:04, 178.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 3618/57920 [00:20<05:04, 178.30it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3636/57920 [00:20<05:04, 178.28it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3654/57920 [00:20<05:04, 178.30it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3672/57920 [00:20<05:04, 178.32it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3690/57920 [00:20<05:04, 178.32it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3708/57920 [00:21<05:03, 178.34it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3726/57920 [00:21<05:03, 178.35it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3744/57920 [00:21<05:03, 178.35it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 3762/57920 [00:21<05:03, 178.37it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3780/57920 [00:21<05:03, 178.39it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3798/57920 [00:21<05:03, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3816/57920 [00:21<05:03, 178.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3834/57920 [00:21<05:03, 178.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3852/57920 [00:21<05:03, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3870/57920 [00:22<05:02, 178.39it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3888/57920 [00:22<05:02, 178.39it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3906/57920 [00:22<05:02, 178.40it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3924/57920 [00:22<05:02, 178.42it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3942/57920 [00:22<05:02, 178.42it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3960/57920 [00:22<05:02, 178.43it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3978/57920 [00:22<05:02, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 3996/57920 [00:22<05:02, 178.37it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4014/57920 [00:22<05:02, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4032/57920 [00:22<05:02, 178.36it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4050/57920 [00:23<05:02, 178.36it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4068/57920 [00:23<05:01, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4086/57920 [00:23<05:01, 178.39it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4104/57920 [00:23<05:01, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4122/57920 [00:23<05:01, 178.40it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4140/57920 [00:23<05:01, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4158/57920 [00:23<05:01, 178.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4176/57920 [00:23<05:01, 178.37it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4194/57920 [00:23<05:01, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4212/57920 [00:23<05:01, 178.39it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4230/57920 [00:24<05:00, 178.37it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4248/57920 [00:24<05:00, 178.38it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4266/57920 [00:24<05:00, 178.40it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4284/57920 [00:24<05:00, 178.39it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4302/57920 [00:24<05:00, 178.40it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4320/57920 [00:24<05:00, 178.39it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4338/57920 [00:24<05:00, 178.38it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4356/57920 [00:24<05:00, 178.40it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4374/57920 [00:24<05:02, 177.18it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4392/57920 [00:24<05:01, 177.55it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4410/57920 [00:25<05:00, 177.80it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4428/57920 [00:25<05:00, 177.99it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4446/57920 [00:25<05:00, 178.10it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4464/57920 [00:25<05:00, 178.18it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4482/57920 [00:25<04:59, 178.19it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4500/57920 [00:25<04:59, 178.20it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4518/57920 [00:25<04:59, 178.25it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4536/57920 [00:25<04:59, 178.28it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4554/57920 [00:25<04:59, 178.30it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4572/57920 [00:25<04:59, 178.32it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4590/57920 [00:26<05:00, 177.27it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4608/57920 [00:26<05:00, 177.58it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4626/57920 [00:26<04:59, 177.82it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4644/57920 [00:26<04:59, 177.98it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4662/57920 [00:26<04:59, 178.09it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4680/57920 [00:26<04:58, 178.16it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4698/57920 [00:26<05:01, 176.30it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4716/57920 [00:26<05:00, 176.89it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4734/57920 [00:26<04:59, 177.32it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4752/57920 [00:26<04:59, 177.64it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4770/57920 [00:27<04:58, 177.87it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4788/57920 [00:27<04:58, 178.02it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4806/57920 [00:27<04:58, 178.12it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4824/57920 [00:27<04:57, 178.18it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4842/57920 [00:27<04:57, 178.24it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4860/57920 [00:27<04:57, 178.30it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4878/57920 [00:27<04:57, 178.30it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4896/57920 [00:27<04:57, 178.32it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 4914/57920 [00:27<04:57, 178.32it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 4932/57920 [00:27<04:57, 178.34it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 4950/57920 [00:28<04:57, 178.34it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 4968/57920 [00:28<04:56, 178.36it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 4986/57920 [00:28<04:56, 178.37it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 5004/57920 [00:28<04:56, 178.37it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 5022/57920 [00:28<04:56, 178.40it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 5040/57920 [00:28<04:56, 178.39it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 5058/57920 [00:28<04:56, 178.38it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5076/57920 [00:28<04:56, 178.38it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5094/57920 [00:28<04:56, 178.36it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5112/57920 [00:28<04:56, 178.37it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5130/57920 [00:29<04:55, 178.39it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5148/57920 [00:29<04:55, 178.40it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5166/57920 [00:29<04:55, 178.40it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5184/57920 [00:29<04:55, 178.39it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5202/57920 [00:29<04:55, 178.39it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5220/57920 [00:29<04:55, 178.38it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5238/57920 [00:29<04:55, 178.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5256/57920 [00:29<04:55, 178.37it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5274/57920 [00:29<04:55, 178.38it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5292/57920 [00:29<04:55, 178.37it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5310/57920 [00:30<04:54, 178.36it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5328/57920 [00:30<04:54, 178.36it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5346/57920 [00:30<04:54, 178.36it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5364/57920 [00:30<04:54, 178.38it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5382/57920 [00:30<04:54, 178.40it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5400/57920 [00:30<04:54, 178.40it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5418/57920 [00:30<04:54, 178.40it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5436/57920 [00:30<04:54, 178.40it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5454/57920 [00:30<04:54, 178.39it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5472/57920 [00:30<04:54, 178.39it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 5490/57920 [00:31<04:53, 178.40it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5508/57920 [00:31<04:53, 178.40it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5526/57920 [00:31<04:53, 178.39it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5544/57920 [00:31<04:53, 178.39it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5562/57920 [00:31<04:53, 178.40it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5580/57920 [00:31<04:53, 178.39it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5598/57920 [00:31<04:53, 178.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5616/57920 [00:31<04:53, 178.33it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5634/57920 [00:31<04:53, 178.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5652/57920 [00:32<04:53, 178.36it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5670/57920 [00:32<04:52, 178.37it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5688/57920 [00:32<04:52, 178.38it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5706/57920 [00:32<04:53, 178.07it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5724/57920 [00:32<04:52, 178.16it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5742/57920 [00:32<04:52, 178.21it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5760/57920 [00:32<04:52, 178.27it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 5778/57920 [00:32<04:52, 178.29it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5796/57920 [00:32<04:52, 178.33it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5814/57920 [00:32<04:52, 178.35it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5832/57920 [00:33<04:52, 178.37it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5850/57920 [00:33<04:51, 178.34it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5868/57920 [00:33<04:51, 178.34it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5886/57920 [00:33<04:51, 178.37it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5904/57920 [00:33<04:51, 178.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5922/57920 [00:33<04:51, 178.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5940/57920 [00:33<04:51, 178.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5958/57920 [00:33<04:51, 178.37it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5976/57920 [00:33<04:53, 177.06it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 5994/57920 [00:33<04:52, 177.43it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 6012/57920 [00:34<04:52, 177.70it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 6030/57920 [00:34<04:51, 177.91it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 6048/57920 [00:34<04:51, 178.05it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 6066/57920 [00:34<04:51, 178.18it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6084/57920 [00:34<04:50, 178.23it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6102/57920 [00:34<04:50, 178.29it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6120/57920 [00:34<04:50, 178.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6138/57920 [00:34<04:50, 178.37it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6156/57920 [00:34<04:50, 178.39it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6174/57920 [00:34<04:50, 178.39it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6192/57920 [00:35<04:49, 178.39it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6210/57920 [00:35<04:49, 178.36it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6228/57920 [00:35<04:49, 178.38it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6246/57920 [00:35<04:49, 178.41it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6264/57920 [00:35<04:49, 178.41it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6282/57920 [00:35<04:49, 178.42it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6300/57920 [00:35<04:49, 178.43it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6318/57920 [00:35<04:49, 178.42it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6336/57920 [00:35<04:49, 178.43it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6354/57920 [00:35<04:48, 178.43it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6372/57920 [00:36<04:48, 178.43it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6390/57920 [00:36<04:48, 178.43it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6408/57920 [00:36<04:48, 178.42it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6426/57920 [00:36<04:48, 178.41it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6444/57920 [00:36<04:48, 178.42it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6462/57920 [00:36<04:48, 178.42it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6480/57920 [00:36<04:48, 178.42it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 6498/57920 [00:36<04:48, 178.41it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6516/57920 [00:36<04:48, 178.41it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6534/57920 [00:36<04:47, 178.43it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6552/57920 [00:37<04:47, 178.42it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6570/57920 [00:37<04:47, 178.41it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6588/57920 [00:37<04:47, 178.40it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6606/57920 [00:37<04:47, 178.40it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6624/57920 [00:37<04:47, 178.39it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6642/57920 [00:37<04:47, 178.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 6660/57920 [00:37<04:47, 178.38it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6678/57920 [00:37<04:47, 178.38it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6696/57920 [00:37<04:47, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6714/57920 [00:37<04:46, 178.42it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6732/57920 [00:38<04:46, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6750/57920 [00:38<04:46, 178.42it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6768/57920 [00:38<04:46, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6786/57920 [00:38<04:46, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6804/57920 [00:38<04:46, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6822/57920 [00:38<04:46, 178.39it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6840/57920 [00:38<04:46, 178.37it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6858/57920 [00:38<04:46, 178.37it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6876/57920 [00:38<04:46, 178.38it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6894/57920 [00:38<04:46, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6912/57920 [00:39<04:45, 178.42it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6930/57920 [00:39<04:45, 178.40it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6948/57920 [00:39<04:45, 178.40it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6966/57920 [00:39<04:45, 178.38it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 6984/57920 [00:39<04:45, 178.39it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7002/57920 [00:39<04:45, 178.40it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7020/57920 [00:39<04:45, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7038/57920 [00:39<04:45, 178.37it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7056/57920 [00:39<04:45, 178.36it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7074/57920 [00:39<04:45, 178.39it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7092/57920 [00:40<04:44, 178.40it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7110/57920 [00:40<04:44, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7128/57920 [00:40<04:44, 178.40it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7146/57920 [00:40<04:44, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7164/57920 [00:40<04:44, 178.40it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7182/57920 [00:40<04:44, 178.41it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7200/57920 [00:40<04:44, 178.38it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7218/57920 [00:40<04:44, 178.36it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 7236/57920 [00:40<04:44, 178.36it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7254/57920 [00:40<04:44, 178.36it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7272/57920 [00:41<04:43, 178.37it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7290/57920 [00:41<04:43, 178.38it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7308/57920 [00:41<04:43, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7326/57920 [00:41<04:43, 178.39it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7344/57920 [00:41<04:43, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7362/57920 [00:41<04:43, 178.37it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7380/57920 [00:41<04:43, 178.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7398/57920 [00:41<04:43, 178.37it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7416/57920 [00:41<04:43, 178.39it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7434/57920 [00:41<04:43, 178.39it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7452/57920 [00:42<04:42, 178.41it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7470/57920 [00:42<04:42, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7488/57920 [00:42<04:42, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7506/57920 [00:42<04:42, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7524/57920 [00:42<04:42, 178.37it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7542/57920 [00:42<04:42, 178.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7560/57920 [00:42<04:42, 178.37it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7578/57920 [00:42<04:42, 178.39it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7596/57920 [00:42<04:42, 178.39it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7614/57920 [00:43<04:42, 178.39it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7632/57920 [00:43<04:41, 178.39it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7650/57920 [00:43<04:41, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7668/57920 [00:43<04:41, 178.41it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7686/57920 [00:43<04:41, 178.43it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7704/57920 [00:43<04:41, 178.42it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7722/57920 [00:43<04:41, 178.42it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7740/57920 [00:43<04:41, 178.43it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7758/57920 [00:43<04:41, 178.43it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7776/57920 [00:43<04:41, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7794/57920 [00:44<04:40, 178.40it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 7812/57920 [00:44<04:40, 178.40it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7830/57920 [00:44<04:40, 178.39it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7848/57920 [00:44<04:40, 178.40it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7866/57920 [00:44<04:40, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7884/57920 [00:44<04:40, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7902/57920 [00:44<04:40, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7920/57920 [00:44<04:40, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7938/57920 [00:44<04:40, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 7956/57920 [00:44<04:40, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 7974/57920 [00:45<04:39, 178.43it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 7992/57920 [00:45<04:39, 178.43it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8010/57920 [00:45<04:39, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8028/57920 [00:45<04:39, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8046/57920 [00:45<04:39, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8064/57920 [00:45<04:39, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8082/57920 [00:45<04:39, 178.43it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8100/57920 [00:45<04:39, 178.43it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8118/57920 [00:45<04:39, 178.40it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8136/57920 [00:45<04:39, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8154/57920 [00:46<04:38, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8172/57920 [00:46<04:38, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8190/57920 [00:46<04:38, 178.43it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8208/57920 [00:46<04:38, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8226/57920 [00:46<04:38, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8244/57920 [00:46<04:38, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8262/57920 [00:46<04:38, 178.44it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8280/57920 [00:46<04:38, 178.43it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8298/57920 [00:46<04:38, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8316/57920 [00:46<04:37, 178.43it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8334/57920 [00:47<04:37, 178.42it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8352/57920 [00:47<04:37, 178.41it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8370/57920 [00:47<04:37, 178.39it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 8388/57920 [00:47<04:37, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8406/57920 [00:47<04:37, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8424/57920 [00:47<04:37, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8442/57920 [00:47<04:37, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8460/57920 [00:47<04:37, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8478/57920 [00:47<04:37, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8496/57920 [00:47<04:37, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8514/57920 [00:48<04:36, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8532/57920 [00:48<04:36, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8550/57920 [00:48<04:36, 178.40it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8568/57920 [00:48<04:36, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8586/57920 [00:48<04:36, 178.40it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8604/57920 [00:48<04:36, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8622/57920 [00:48<04:36, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8640/57920 [00:48<04:36, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8658/57920 [00:48<04:36, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 8676/57920 [00:48<04:36, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8694/57920 [00:49<04:35, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8712/57920 [00:49<04:35, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8730/57920 [00:49<04:35, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8748/57920 [00:49<04:35, 178.39it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8766/57920 [00:49<04:35, 178.40it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8784/57920 [00:49<04:35, 178.38it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8802/57920 [00:49<04:35, 178.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8820/57920 [00:49<04:35, 178.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8838/57920 [00:49<04:35, 178.38it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8856/57920 [00:49<04:35, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8874/57920 [00:50<04:34, 178.39it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8892/57920 [00:50<04:34, 178.39it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8910/57920 [00:50<04:34, 178.41it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8928/57920 [00:50<04:34, 178.43it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8946/57920 [00:50<04:34, 178.42it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 8964/57920 [00:50<04:34, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 8982/57920 [00:50<04:34, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9000/57920 [00:50<04:34, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9018/57920 [00:50<04:34, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9036/57920 [00:50<04:33, 178.41it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9054/57920 [00:51<04:33, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9072/57920 [00:51<04:33, 178.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9090/57920 [00:51<04:33, 178.38it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9108/57920 [00:51<04:33, 178.16it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9126/57920 [00:51<04:33, 178.24it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9144/57920 [00:51<04:33, 178.30it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9162/57920 [00:51<04:33, 178.33it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9180/57920 [00:51<04:33, 178.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9198/57920 [00:51<04:33, 178.39it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9216/57920 [00:51<04:32, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9234/57920 [00:52<04:32, 178.43it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9252/57920 [00:52<04:32, 178.43it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9270/57920 [00:52<04:32, 178.40it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9288/57920 [00:52<04:32, 178.39it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9306/57920 [00:52<04:32, 178.39it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9324/57920 [00:52<04:32, 178.40it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9342/57920 [00:52<04:32, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9360/57920 [00:52<04:32, 178.44it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9378/57920 [00:52<04:32, 178.44it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 9396/57920 [00:52<04:31, 178.43it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9414/57920 [00:53<04:31, 178.43it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9432/57920 [00:53<04:31, 178.43it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9450/57920 [00:53<04:31, 178.42it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9468/57920 [00:53<04:31, 178.43it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9486/57920 [00:53<04:31, 178.43it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9504/57920 [00:53<04:31, 178.41it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9522/57920 [00:53<04:31, 178.41it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 9540/57920 [00:53<04:31, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9558/57920 [00:53<04:31, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9576/57920 [00:54<04:30, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9594/57920 [00:54<04:30, 178.40it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9612/57920 [00:54<04:30, 178.41it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9630/57920 [00:54<04:30, 178.41it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9648/57920 [00:54<04:30, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9666/57920 [00:54<04:30, 178.40it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9684/57920 [00:54<04:30, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9702/57920 [00:54<04:30, 178.44it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9720/57920 [00:54<04:30, 178.44it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9738/57920 [00:54<04:30, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9756/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9774/57920 [00:55<04:29, 178.41it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9792/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9810/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9828/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9846/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9864/57920 [00:55<04:29, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9882/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9900/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9918/57920 [00:55<04:29, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9936/57920 [00:56<04:28, 178.41it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9954/57920 [00:56<04:28, 178.41it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9972/57920 [00:56<04:28, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 9990/57920 [00:56<04:28, 178.44it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10008/57920 [00:56<04:28, 178.45it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10026/57920 [00:56<04:28, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10044/57920 [00:56<04:28, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10062/57920 [00:56<04:28, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10080/57920 [00:56<04:28, 178.41it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10098/57920 [00:56<04:28, 178.43it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10116/57920 [00:57<04:27, 178.42it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 10134/57920 [00:57<04:27, 178.44it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10152/57920 [00:57<04:27, 178.45it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10170/57920 [00:57<04:27, 178.43it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10188/57920 [00:57<04:27, 178.43it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10206/57920 [00:57<04:27, 178.41it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10224/57920 [00:57<04:27, 178.41it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10242/57920 [00:57<04:27, 178.41it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10260/57920 [00:57<04:27, 178.41it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10278/57920 [00:57<04:27, 178.41it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10296/57920 [00:58<04:26, 178.40it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10314/57920 [00:58<04:26, 178.41it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10332/57920 [00:58<04:26, 178.43it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10350/57920 [00:58<04:26, 178.44it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10368/57920 [00:58<04:26, 178.44it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10386/57920 [00:58<04:26, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10404/57920 [00:58<04:26, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10422/57920 [00:58<04:26, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10440/57920 [00:58<04:26, 178.44it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10458/57920 [00:58<04:26, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10476/57920 [00:59<04:25, 178.43it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10494/57920 [00:59<04:25, 178.44it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10512/57920 [00:59<04:25, 178.44it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10530/57920 [00:59<04:25, 178.40it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10548/57920 [00:59<04:25, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10566/57920 [00:59<04:25, 178.43it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10584/57920 [00:59<04:25, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10602/57920 [00:59<04:25, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10620/57920 [00:59<04:25, 178.44it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10638/57920 [00:59<04:24, 178.43it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10656/57920 [01:00<04:24, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10674/57920 [01:00<04:24, 178.42it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10692/57920 [01:00<04:24, 178.40it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 10710/57920 [01:00<04:24, 178.41it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10728/57920 [01:00<04:24, 178.43it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10746/57920 [01:00<04:24, 178.43it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10764/57920 [01:00<04:24, 178.43it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10782/57920 [01:00<04:24, 178.43it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10800/57920 [01:00<04:24, 178.45it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10818/57920 [01:00<04:23, 178.45it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10836/57920 [01:01<04:23, 178.44it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 10854/57920 [01:01<04:23, 178.43it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10872/57920 [01:01<04:23, 178.42it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10890/57920 [01:01<04:23, 178.42it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10908/57920 [01:01<04:23, 178.43it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10926/57920 [01:01<04:23, 178.41it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10944/57920 [01:01<04:23, 178.42it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10962/57920 [01:01<04:23, 178.41it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10980/57920 [01:01<04:23, 178.41it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 10998/57920 [01:01<04:23, 178.40it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11016/57920 [01:02<04:22, 178.39it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11034/57920 [01:02<04:22, 178.40it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11052/57920 [01:02<04:22, 178.41it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11070/57920 [01:02<04:25, 176.76it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11088/57920 [01:02<04:24, 177.23it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11106/57920 [01:02<04:23, 177.58it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11124/57920 [01:02<04:23, 177.84it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11142/57920 [01:02<04:22, 178.01it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11160/57920 [01:02<04:22, 178.13it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11178/57920 [01:02<04:22, 178.23it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11196/57920 [01:03<04:22, 178.29it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11214/57920 [01:03<04:21, 178.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11232/57920 [01:03<04:21, 178.37it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11250/57920 [01:03<04:23, 176.85it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11268/57920 [01:03<04:23, 177.31it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 11286/57920 [01:03<04:22, 177.64it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11304/57920 [01:03<04:22, 177.88it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11322/57920 [01:03<04:21, 178.05it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11340/57920 [01:03<04:21, 178.17it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11358/57920 [01:03<04:21, 178.25it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11376/57920 [01:04<04:21, 178.30it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11394/57920 [01:04<04:20, 178.33it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11412/57920 [01:04<04:20, 178.37it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11430/57920 [01:04<04:20, 178.39it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11448/57920 [01:04<04:21, 177.42it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11466/57920 [01:04<04:21, 177.68it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11484/57920 [01:04<04:21, 177.90it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11502/57920 [01:04<04:20, 178.04it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11520/57920 [01:04<04:20, 178.14it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11538/57920 [01:05<04:20, 178.23it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11556/57920 [01:05<04:20, 178.29it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 11574/57920 [01:05<04:19, 178.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11592/57920 [01:05<04:19, 178.36it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11610/57920 [01:05<04:19, 178.38it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11628/57920 [01:05<04:19, 178.39it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11646/57920 [01:05<04:19, 178.39it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11664/57920 [01:05<04:19, 178.40it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11682/57920 [01:05<04:19, 178.40it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11700/57920 [01:05<04:19, 178.39it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11718/57920 [01:06<04:18, 178.41it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11736/57920 [01:06<04:18, 178.42it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11754/57920 [01:06<04:18, 178.41it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11772/57920 [01:06<04:18, 178.42it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11790/57920 [01:06<04:18, 178.43it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11808/57920 [01:06<04:18, 178.43it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11826/57920 [01:06<04:18, 178.41it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11844/57920 [01:06<04:18, 178.42it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 11862/57920 [01:06<04:18, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 11880/57920 [01:06<04:18, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 11898/57920 [01:07<04:17, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 11916/57920 [01:07<04:17, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 11934/57920 [01:07<04:17, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 11952/57920 [01:07<04:17, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 11970/57920 [01:07<04:17, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 11988/57920 [01:07<04:17, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12006/57920 [01:07<04:17, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12024/57920 [01:07<04:17, 178.43it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12042/57920 [01:07<04:17, 178.43it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12060/57920 [01:07<04:17, 178.41it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12078/57920 [01:08<04:16, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12096/57920 [01:08<04:16, 178.43it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12114/57920 [01:08<04:16, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12132/57920 [01:08<04:16, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12150/57920 [01:08<04:16, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12168/57920 [01:08<04:16, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12186/57920 [01:08<04:16, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12204/57920 [01:08<04:16, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12222/57920 [01:08<04:16, 178.45it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12240/57920 [01:08<04:15, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12258/57920 [01:09<04:15, 178.43it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12276/57920 [01:09<04:15, 178.45it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 12294/57920 [01:09<04:15, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12312/57920 [01:09<04:15, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12330/57920 [01:09<04:15, 178.43it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12348/57920 [01:09<04:15, 178.44it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12366/57920 [01:09<04:15, 178.43it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12384/57920 [01:09<04:15, 178.41it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12402/57920 [01:09<04:15, 178.41it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12420/57920 [01:09<04:15, 178.42it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 12438/57920 [01:10<04:14, 178.42it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12456/57920 [01:10<04:14, 178.42it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12474/57920 [01:10<04:14, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12492/57920 [01:10<04:14, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12510/57920 [01:10<04:14, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12528/57920 [01:10<04:14, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12546/57920 [01:10<04:14, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12564/57920 [01:10<04:14, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12582/57920 [01:10<04:14, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12600/57920 [01:10<04:13, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12618/57920 [01:11<04:13, 178.45it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12636/57920 [01:11<04:13, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12654/57920 [01:11<04:13, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12672/57920 [01:11<04:13, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12690/57920 [01:11<04:13, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12708/57920 [01:11<04:13, 178.42it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12726/57920 [01:11<04:13, 178.41it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12744/57920 [01:11<04:13, 178.42it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12762/57920 [01:11<04:13, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12780/57920 [01:11<04:13, 178.40it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12798/57920 [01:12<04:12, 178.41it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12816/57920 [01:12<04:12, 178.42it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12834/57920 [01:12<04:12, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12852/57920 [01:12<04:12, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12870/57920 [01:12<04:12, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12888/57920 [01:12<04:12, 178.42it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12906/57920 [01:12<04:12, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12924/57920 [01:12<04:12, 178.44it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12942/57920 [01:12<04:12, 178.45it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12960/57920 [01:12<04:11, 178.43it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12978/57920 [01:13<04:11, 178.40it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 12996/57920 [01:13<04:11, 178.39it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 13014/57920 [01:13<04:11, 178.40it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–Ž       | 13032/57920 [01:13<04:11, 178.39it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13050/57920 [01:13<04:11, 178.39it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13068/57920 [01:13<04:11, 178.40it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13086/57920 [01:13<04:11, 178.42it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13104/57920 [01:13<04:11, 178.42it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13122/57920 [01:13<04:11, 178.41it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13140/57920 [01:13<04:10, 178.41it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13158/57920 [01:14<04:10, 178.40it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13176/57920 [01:14<04:10, 178.42it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13194/57920 [01:14<04:10, 178.42it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13212/57920 [01:14<04:10, 178.20it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13230/57920 [01:14<04:10, 178.24it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13248/57920 [01:14<04:10, 178.30it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13266/57920 [01:14<04:10, 178.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13284/57920 [01:14<04:10, 178.38it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13302/57920 [01:14<04:10, 178.39it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13320/57920 [01:14<04:09, 178.42it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13338/57920 [01:15<04:09, 178.42it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13356/57920 [01:15<04:09, 178.41it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13374/57920 [01:15<04:09, 178.42it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13392/57920 [01:15<04:09, 178.43it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13410/57920 [01:15<04:09, 178.41it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13428/57920 [01:15<04:09, 178.24it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13446/57920 [01:15<04:09, 178.27it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13464/57920 [01:15<04:09, 178.31it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13482/57920 [01:15<04:09, 178.34it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13500/57920 [01:16<04:09, 178.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13518/57920 [01:16<04:08, 178.39it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13536/57920 [01:16<04:08, 178.40it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13554/57920 [01:16<04:08, 178.40it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13572/57920 [01:16<04:08, 178.40it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13590/57920 [01:16<04:08, 178.39it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 13608/57920 [01:16<04:08, 178.40it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13626/57920 [01:16<04:08, 178.41it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13644/57920 [01:16<04:08, 178.42it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13662/57920 [01:16<04:08, 178.04it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13680/57920 [01:17<04:08, 178.12it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13698/57920 [01:17<04:08, 178.22it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13716/57920 [01:17<04:07, 178.28it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13734/57920 [01:17<04:07, 178.33it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 13752/57920 [01:17<04:07, 178.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13770/57920 [01:17<04:07, 178.37it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13788/57920 [01:17<04:07, 178.40it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13806/57920 [01:17<04:07, 178.42it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13824/57920 [01:17<04:07, 178.43it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13842/57920 [01:17<04:07, 178.42it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13860/57920 [01:18<04:06, 178.42it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13878/57920 [01:18<04:06, 178.43it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13896/57920 [01:18<04:06, 178.42it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13914/57920 [01:18<04:06, 178.41it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13932/57920 [01:18<04:06, 178.40it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13950/57920 [01:18<04:06, 178.41it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13968/57920 [01:18<04:06, 178.39it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 13986/57920 [01:18<04:06, 178.39it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14004/57920 [01:18<04:06, 178.40it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14022/57920 [01:18<04:06, 178.42it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14040/57920 [01:19<04:05, 178.44it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14058/57920 [01:19<04:05, 178.44it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14076/57920 [01:19<04:05, 178.45it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14094/57920 [01:19<04:05, 178.45it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14112/57920 [01:19<04:05, 178.45it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14130/57920 [01:19<04:05, 178.45it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14148/57920 [01:19<04:05, 178.43it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14166/57920 [01:19<04:05, 178.43it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 14184/57920 [01:19<04:05, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14202/57920 [01:19<04:05, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14220/57920 [01:20<04:04, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14238/57920 [01:20<04:04, 178.39it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14256/57920 [01:20<04:04, 178.40it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14274/57920 [01:20<04:04, 178.41it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14292/57920 [01:20<04:04, 178.42it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14310/57920 [01:20<04:04, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14328/57920 [01:20<04:04, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14346/57920 [01:20<04:04, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14364/57920 [01:20<04:04, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14382/57920 [01:20<04:03, 178.45it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14400/57920 [01:21<04:03, 178.46it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14418/57920 [01:21<04:03, 178.46it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14436/57920 [01:21<04:03, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14454/57920 [01:21<04:03, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 14472/57920 [01:21<04:03, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14490/57920 [01:21<04:03, 178.42it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14508/57920 [01:21<04:03, 178.40it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14526/57920 [01:21<04:03, 178.40it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14544/57920 [01:21<04:03, 178.41it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14562/57920 [01:21<04:03, 178.42it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14580/57920 [01:22<04:02, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14598/57920 [01:22<04:02, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14616/57920 [01:22<04:02, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14634/57920 [01:22<04:02, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14652/57920 [01:22<04:02, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14670/57920 [01:22<04:02, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14688/57920 [01:22<04:02, 178.43it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14706/57920 [01:22<04:02, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14724/57920 [01:22<04:02, 178.44it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14742/57920 [01:22<04:01, 178.45it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 14760/57920 [01:23<04:01, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14778/57920 [01:23<04:01, 178.43it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14796/57920 [01:23<04:01, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14814/57920 [01:23<04:01, 178.43it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14832/57920 [01:23<04:01, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14850/57920 [01:23<04:01, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14868/57920 [01:23<04:01, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14886/57920 [01:23<04:01, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14904/57920 [01:23<04:01, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14922/57920 [01:23<04:00, 178.46it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14940/57920 [01:24<04:00, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14958/57920 [01:24<04:00, 178.43it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14976/57920 [01:24<04:00, 178.42it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 14994/57920 [01:24<04:00, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15012/57920 [01:24<04:00, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15030/57920 [01:24<04:00, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15048/57920 [01:24<04:00, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15066/57920 [01:24<04:00, 178.43it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15084/57920 [01:24<04:00, 178.42it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15102/57920 [01:24<03:59, 178.42it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15120/57920 [01:25<03:59, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15138/57920 [01:25<03:59, 178.46it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15156/57920 [01:25<03:59, 178.46it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15174/57920 [01:25<03:59, 178.43it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 15192/57920 [01:25<03:59, 178.43it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15210/57920 [01:25<03:59, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15228/57920 [01:25<03:59, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15246/57920 [01:25<03:59, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15264/57920 [01:25<03:59, 178.46it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15282/57920 [01:25<03:58, 178.45it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15300/57920 [01:26<03:58, 178.43it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15318/57920 [01:26<03:58, 178.44it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 15336/57920 [01:26<03:58, 178.44it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15354/57920 [01:26<03:58, 178.46it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15372/57920 [01:26<03:58, 178.44it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15390/57920 [01:26<03:58, 178.45it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15408/57920 [01:26<03:58, 178.43it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15426/57920 [01:26<03:58, 178.44it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15444/57920 [01:26<03:58, 178.44it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15462/57920 [01:27<03:57, 178.45it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15480/57920 [01:27<03:57, 178.45it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15498/57920 [01:27<03:58, 177.53it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15516/57920 [01:27<03:58, 177.76it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15534/57920 [01:27<03:58, 177.96it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15552/57920 [01:27<03:57, 178.09it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15570/57920 [01:27<03:57, 178.20it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15588/57920 [01:27<03:57, 178.27it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15606/57920 [01:27<03:57, 178.32it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15624/57920 [01:27<03:57, 178.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15642/57920 [01:28<03:57, 178.38it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15660/57920 [01:28<03:56, 178.40it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15678/57920 [01:28<03:56, 178.42it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15696/57920 [01:28<03:56, 178.42it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15714/57920 [01:28<03:56, 178.43it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15732/57920 [01:28<03:56, 178.44it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15750/57920 [01:28<03:56, 178.43it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15768/57920 [01:28<03:56, 178.39it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15786/57920 [01:28<03:56, 178.39it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15804/57920 [01:28<03:56, 178.38it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15822/57920 [01:29<03:55, 178.41it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15840/57920 [01:29<03:55, 178.42it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15858/57920 [01:29<03:55, 178.42it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15876/57920 [01:29<03:55, 178.43it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15894/57920 [01:29<03:55, 178.42it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 15912/57920 [01:29<03:55, 178.44it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 15930/57920 [01:29<03:55, 178.44it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 15948/57920 [01:29<03:55, 178.45it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 15966/57920 [01:29<03:55, 178.45it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 15984/57920 [01:29<03:54, 178.46it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16002/57920 [01:30<03:54, 178.46it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16020/57920 [01:30<03:54, 178.44it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16038/57920 [01:30<03:56, 177.05it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16056/57920 [01:30<03:55, 177.43it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16074/57920 [01:30<03:55, 177.74it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16092/57920 [01:30<03:55, 177.93it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16110/57920 [01:30<03:54, 178.07it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16128/57920 [01:30<03:54, 178.16it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16146/57920 [01:30<03:54, 178.22it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16164/57920 [01:30<03:54, 178.29it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16182/57920 [01:31<03:54, 178.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16200/57920 [01:31<03:53, 178.38it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16218/57920 [01:31<03:53, 178.41it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16236/57920 [01:31<03:53, 178.42it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16254/57920 [01:31<03:53, 178.41it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16272/57920 [01:31<03:53, 178.41it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16290/57920 [01:31<03:53, 178.42it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16308/57920 [01:31<03:53, 178.43it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16326/57920 [01:31<03:53, 178.39it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16344/57920 [01:31<03:53, 178.37it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16362/57920 [01:32<03:52, 178.38it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16380/57920 [01:32<03:52, 178.40it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16398/57920 [01:32<03:52, 178.40it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16416/57920 [01:32<03:52, 178.41it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16434/57920 [01:32<03:52, 178.43it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16452/57920 [01:32<03:52, 178.45it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16470/57920 [01:32<03:52, 178.45it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16488/57920 [01:32<03:52, 178.44it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 16506/57920 [01:32<03:52, 178.43it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16524/57920 [01:32<03:52, 178.43it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16542/57920 [01:33<03:51, 178.43it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16560/57920 [01:33<03:51, 178.44it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16578/57920 [01:33<03:51, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16596/57920 [01:33<03:51, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16614/57920 [01:33<03:51, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16632/57920 [01:33<03:51, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 16650/57920 [01:33<03:51, 178.44it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16668/57920 [01:33<03:51, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16686/57920 [01:33<03:51, 178.42it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16704/57920 [01:33<03:50, 178.43it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16722/57920 [01:34<03:50, 178.44it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16740/57920 [01:34<03:50, 178.41it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16758/57920 [01:34<03:50, 178.42it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16776/57920 [01:34<03:50, 178.42it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16794/57920 [01:34<03:50, 178.44it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16812/57920 [01:34<03:50, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16830/57920 [01:34<03:50, 178.46it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16848/57920 [01:34<03:50, 178.46it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16866/57920 [01:34<03:50, 178.46it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16884/57920 [01:34<03:49, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16902/57920 [01:35<03:49, 178.41it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16920/57920 [01:35<03:49, 178.44it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16938/57920 [01:35<03:49, 178.43it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16956/57920 [01:35<03:49, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16974/57920 [01:35<03:49, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 16992/57920 [01:35<03:49, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 17010/57920 [01:35<03:49, 178.45it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 17028/57920 [01:35<03:49, 178.44it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 17046/57920 [01:35<03:49, 178.43it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 17064/57920 [01:35<03:48, 178.44it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 17082/57920 [01:36<03:48, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17100/57920 [01:36<03:48, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17118/57920 [01:36<03:48, 178.45it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17136/57920 [01:36<03:48, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17154/57920 [01:36<03:48, 178.45it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17172/57920 [01:36<03:48, 178.43it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17190/57920 [01:36<03:48, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17208/57920 [01:36<03:48, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17226/57920 [01:36<03:48, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17244/57920 [01:36<03:47, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17262/57920 [01:37<03:47, 178.43it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17280/57920 [01:37<03:47, 178.43it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17298/57920 [01:37<03:47, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17316/57920 [01:37<03:47, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17334/57920 [01:37<03:47, 178.43it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17352/57920 [01:37<03:47, 178.41it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 17370/57920 [01:37<03:47, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17388/57920 [01:37<03:47, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17406/57920 [01:37<03:47, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17424/57920 [01:38<03:46, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17442/57920 [01:38<03:46, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17460/57920 [01:38<03:46, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17478/57920 [01:38<03:46, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17496/57920 [01:38<03:46, 178.42it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17514/57920 [01:38<03:46, 178.43it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17532/57920 [01:38<03:46, 178.43it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17550/57920 [01:38<03:46, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17568/57920 [01:38<03:46, 178.43it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17586/57920 [01:38<03:46, 178.45it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17604/57920 [01:39<03:45, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17622/57920 [01:39<03:45, 178.44it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17640/57920 [01:39<03:45, 178.45it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 17658/57920 [01:39<03:45, 178.47it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17676/57920 [01:39<03:45, 178.46it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17694/57920 [01:39<03:45, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17712/57920 [01:39<03:45, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17730/57920 [01:39<03:45, 178.46it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17748/57920 [01:39<03:45, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17766/57920 [01:39<03:45, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17784/57920 [01:40<03:44, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17802/57920 [01:40<03:44, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17820/57920 [01:40<03:44, 178.41it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17838/57920 [01:40<03:44, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17856/57920 [01:40<03:44, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17874/57920 [01:40<03:44, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17892/57920 [01:40<03:44, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17910/57920 [01:40<03:44, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17928/57920 [01:40<03:44, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17946/57920 [01:40<03:44, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17964/57920 [01:41<03:43, 178.43it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 17982/57920 [01:41<03:43, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 18000/57920 [01:41<03:43, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 18018/57920 [01:41<03:43, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 18036/57920 [01:41<03:43, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 18054/57920 [01:41<03:43, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 18072/57920 [01:41<03:43, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 18090/57920 [01:41<03:43, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18108/57920 [01:41<03:43, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18126/57920 [01:41<03:43, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18144/57920 [01:42<03:42, 178.46it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18162/57920 [01:42<03:42, 178.46it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18180/57920 [01:42<03:42, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18198/57920 [01:42<03:42, 178.45it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18216/57920 [01:42<03:42, 178.44it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 18234/57920 [01:42<03:42, 178.45it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18252/57920 [01:42<03:42, 178.45it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18270/57920 [01:42<03:42, 178.44it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18288/57920 [01:42<03:42, 178.45it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18306/57920 [01:42<03:42, 178.44it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18324/57920 [01:43<03:41, 178.44it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18342/57920 [01:43<03:41, 178.43it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18360/57920 [01:43<03:41, 178.45it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18378/57920 [01:43<03:41, 178.43it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18396/57920 [01:43<03:41, 178.42it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18414/57920 [01:43<03:41, 178.41it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18432/57920 [01:43<03:41, 178.40it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18450/57920 [01:43<03:41, 178.43it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18468/57920 [01:43<03:41, 178.43it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18486/57920 [01:43<03:41, 178.43it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18504/57920 [01:44<03:40, 178.42it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18522/57920 [01:44<03:40, 178.41it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18540/57920 [01:44<03:40, 178.40it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18558/57920 [01:44<03:40, 178.39it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18576/57920 [01:44<03:40, 178.41it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18594/57920 [01:44<03:40, 178.42it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18612/57920 [01:44<03:40, 178.41it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18630/57920 [01:44<03:40, 178.42it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18648/57920 [01:44<03:40, 178.43it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18666/57920 [01:44<03:39, 178.43it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18684/57920 [01:45<03:39, 178.45it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18702/57920 [01:45<03:39, 178.45it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18720/57920 [01:45<03:39, 178.46it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18738/57920 [01:45<03:39, 178.46it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18756/57920 [01:45<03:39, 178.44it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18774/57920 [01:45<03:39, 178.44it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18792/57920 [01:45<03:39, 178.45it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 18810/57920 [01:45<03:39, 178.45it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18828/57920 [01:45<03:39, 178.44it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18846/57920 [01:45<03:41, 176.76it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18864/57920 [01:46<03:40, 177.24it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18882/57920 [01:46<03:39, 177.57it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18900/57920 [01:46<03:39, 177.82it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18918/57920 [01:46<03:39, 177.99it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18936/57920 [01:46<03:38, 178.14it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18954/57920 [01:46<03:38, 178.23it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18972/57920 [01:46<03:38, 178.31it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18990/57920 [01:46<03:38, 178.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19008/57920 [01:46<03:38, 178.37it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19026/57920 [01:46<03:38, 178.39it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19044/57920 [01:47<03:37, 178.42it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19062/57920 [01:47<03:37, 178.43it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19080/57920 [01:47<03:37, 178.43it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19098/57920 [01:47<03:37, 178.41it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19116/57920 [01:47<03:37, 178.41it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19134/57920 [01:47<03:37, 178.42it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19152/57920 [01:47<03:37, 178.43it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19170/57920 [01:47<03:37, 178.43it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19188/57920 [01:47<03:37, 178.40it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19206/57920 [01:47<03:37, 178.39it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19224/57920 [01:48<03:36, 178.38it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19242/57920 [01:48<03:36, 178.38it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19260/57920 [01:48<03:36, 178.39it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19278/57920 [01:48<03:36, 178.40it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19296/57920 [01:48<03:36, 178.42it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19314/57920 [01:48<03:36, 178.42it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19332/57920 [01:48<03:36, 178.41it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19350/57920 [01:48<03:36, 178.43it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19368/57920 [01:48<03:36, 178.44it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19386/57920 [01:49<03:35, 178.43it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19404/57920 [01:49<03:35, 178.44it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19422/57920 [01:49<03:35, 178.46it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19440/57920 [01:49<03:35, 178.45it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19458/57920 [01:49<03:35, 178.44it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19476/57920 [01:49<03:35, 178.44it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19494/57920 [01:49<03:35, 178.44it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19512/57920 [01:49<03:36, 177.02it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 19530/57920 [01:49<03:36, 177.39it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19548/57920 [01:49<03:35, 177.69it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19566/57920 [01:50<03:35, 177.92it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19584/57920 [01:50<03:35, 178.08it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19602/57920 [01:50<03:35, 178.19it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19620/57920 [01:50<03:34, 178.27it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19638/57920 [01:50<03:34, 178.31it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19656/57920 [01:50<03:34, 178.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19674/57920 [01:50<03:34, 178.39it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19692/57920 [01:50<03:34, 178.42it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19710/57920 [01:50<03:34, 178.42it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19728/57920 [01:50<03:34, 178.43it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19746/57920 [01:51<03:33, 178.42it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19764/57920 [01:51<03:33, 178.44it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19782/57920 [01:51<03:33, 178.45it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19800/57920 [01:51<03:33, 178.46it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19818/57920 [01:51<03:33, 178.45it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19836/57920 [01:51<03:33, 178.43it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19854/57920 [01:51<03:33, 178.44it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19872/57920 [01:51<03:33, 178.45it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19890/57920 [01:51<03:33, 178.45it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19908/57920 [01:51<03:33, 178.45it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19926/57920 [01:52<03:32, 178.44it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19944/57920 [01:52<03:32, 178.43it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19962/57920 [01:52<03:32, 178.43it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 19980/57920 [01:52<03:32, 178.44it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 19998/57920 [01:52<03:32, 178.44it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20016/57920 [01:52<03:32, 178.44it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20034/57920 [01:52<03:32, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20052/57920 [01:52<03:32, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20070/57920 [01:52<03:32, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20088/57920 [01:52<03:32, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20106/57920 [01:53<03:31, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20124/57920 [01:53<03:31, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20142/57920 [01:53<03:31, 178.46it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20160/57920 [01:53<03:31, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20178/57920 [01:53<03:31, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20196/57920 [01:53<03:31, 178.44it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20214/57920 [01:53<03:31, 178.44it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20232/57920 [01:53<03:31, 178.46it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20250/57920 [01:53<03:31, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 20268/57920 [01:53<03:30, 178.45it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20286/57920 [01:54<03:30, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20304/57920 [01:54<03:30, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20322/57920 [01:54<03:30, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20340/57920 [01:54<03:30, 178.41it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20358/57920 [01:54<03:30, 178.42it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20376/57920 [01:54<03:30, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20394/57920 [01:54<03:30, 178.42it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20412/57920 [01:54<03:30, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20430/57920 [01:54<03:30, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20448/57920 [01:54<03:29, 178.44it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20466/57920 [01:55<03:29, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20484/57920 [01:55<03:29, 178.42it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20502/57920 [01:55<03:29, 178.41it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20520/57920 [01:55<03:29, 178.41it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20538/57920 [01:55<03:29, 178.43it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 20556/57920 [01:55<03:29, 178.43it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20574/57920 [01:55<03:29, 178.42it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20592/57920 [01:55<03:29, 178.43it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20610/57920 [01:55<03:29, 178.42it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20628/57920 [01:55<03:29, 178.43it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20646/57920 [01:56<03:28, 178.43it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20664/57920 [01:56<03:28, 178.43it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20682/57920 [01:56<03:28, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20700/57920 [01:56<03:28, 178.42it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20718/57920 [01:56<03:28, 178.42it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20736/57920 [01:56<03:28, 178.43it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20754/57920 [01:56<03:28, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20772/57920 [01:56<03:28, 178.46it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20790/57920 [01:56<03:28, 178.46it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20808/57920 [01:56<03:27, 178.46it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20826/57920 [01:57<03:27, 178.45it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20844/57920 [01:57<03:27, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20862/57920 [01:57<03:27, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20880/57920 [01:57<03:27, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20898/57920 [01:57<03:27, 178.43it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20916/57920 [01:57<03:27, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20934/57920 [01:57<03:27, 178.45it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20952/57920 [01:57<03:27, 178.45it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20970/57920 [01:57<03:27, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20988/57920 [01:57<03:26, 178.45it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21006/57920 [01:58<03:26, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21024/57920 [01:58<03:26, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21042/57920 [01:58<03:26, 178.46it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21060/57920 [01:58<03:26, 178.46it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21078/57920 [01:58<03:26, 178.45it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21096/57920 [01:58<03:26, 178.44it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21114/57920 [01:58<03:26, 178.42it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 21132/57920 [01:58<03:26, 178.42it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21150/57920 [01:58<03:26, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21168/57920 [01:58<03:25, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21186/57920 [01:59<03:25, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21204/57920 [01:59<03:25, 178.46it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21222/57920 [01:59<03:25, 178.45it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21240/57920 [01:59<03:25, 178.46it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21258/57920 [01:59<03:25, 178.45it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21276/57920 [01:59<03:25, 178.45it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21294/57920 [01:59<03:25, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21312/57920 [01:59<03:25, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21330/57920 [01:59<03:25, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21348/57920 [02:00<03:24, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21366/57920 [02:00<03:24, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21384/57920 [02:00<03:24, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21402/57920 [02:00<03:24, 178.42it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21420/57920 [02:00<03:24, 178.42it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21438/57920 [02:00<03:24, 178.42it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21456/57920 [02:00<03:24, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21474/57920 [02:00<03:24, 178.42it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21492/57920 [02:00<03:24, 178.41it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21510/57920 [02:00<03:24, 178.41it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21528/57920 [02:01<03:23, 178.41it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21546/57920 [02:01<03:23, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21564/57920 [02:01<03:23, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21582/57920 [02:01<03:23, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21600/57920 [02:01<03:23, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21618/57920 [02:01<03:23, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21636/57920 [02:01<03:23, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21654/57920 [02:01<03:23, 178.43it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21672/57920 [02:01<03:23, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21690/57920 [02:01<03:23, 178.44it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21708/57920 [02:02<03:22, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21726/57920 [02:02<03:22, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21744/57920 [02:02<03:22, 178.41it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21762/57920 [02:02<03:22, 178.43it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21780/57920 [02:02<03:22, 178.43it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21798/57920 [02:02<03:22, 178.45it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21816/57920 [02:02<03:22, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21834/57920 [02:02<03:22, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21852/57920 [02:02<03:22, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21870/57920 [02:02<03:22, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21888/57920 [02:03<03:21, 178.45it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21906/57920 [02:03<03:21, 178.46it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21924/57920 [02:03<03:21, 178.47it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21942/57920 [02:03<03:21, 178.46it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21960/57920 [02:03<03:21, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21978/57920 [02:03<03:21, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21996/57920 [02:03<03:21, 178.45it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22014/57920 [02:03<03:21, 178.45it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22032/57920 [02:03<03:21, 178.46it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22050/57920 [02:03<03:21, 178.43it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22068/57920 [02:04<03:20, 178.44it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22086/57920 [02:04<03:20, 178.45it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22104/57920 [02:04<03:20, 178.45it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22122/57920 [02:04<03:20, 178.46it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22140/57920 [02:04<03:21, 177.85it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22158/57920 [02:04<03:20, 177.99it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22176/57920 [02:04<03:20, 178.12it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22194/57920 [02:04<03:20, 178.21it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22212/57920 [02:04<03:20, 178.28it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22230/57920 [02:04<03:20, 178.33it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22248/57920 [02:05<03:20, 178.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22266/57920 [02:05<03:19, 178.38it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 22284/57920 [02:05<03:19, 178.41it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22302/57920 [02:05<03:19, 178.42it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22320/57920 [02:05<03:19, 178.42it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22338/57920 [02:05<03:19, 178.41it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22356/57920 [02:05<03:19, 178.44it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22374/57920 [02:05<03:19, 178.43it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22392/57920 [02:05<03:19, 178.42it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22410/57920 [02:05<03:19, 178.42it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22428/57920 [02:06<03:18, 178.43it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22446/57920 [02:06<03:18, 178.43it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22464/57920 [02:06<03:18, 178.42it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22482/57920 [02:06<03:18, 178.42it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22500/57920 [02:06<03:18, 178.42it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22518/57920 [02:06<03:18, 178.41it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22536/57920 [02:06<03:20, 176.65it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22554/57920 [02:06<03:19, 177.17it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22572/57920 [02:06<03:19, 177.53it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22590/57920 [02:06<03:18, 177.79it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22608/57920 [02:07<03:18, 177.98it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22626/57920 [02:07<03:18, 178.09it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22644/57920 [02:07<03:17, 178.20it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22662/57920 [02:07<03:17, 178.26it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22680/57920 [02:07<03:17, 178.32it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22698/57920 [02:07<03:17, 178.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22716/57920 [02:07<03:17, 178.37it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22734/57920 [02:07<03:17, 178.40it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22752/57920 [02:07<03:17, 178.41it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22770/57920 [02:07<03:17, 178.43it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22788/57920 [02:08<03:16, 178.45it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22806/57920 [02:08<03:16, 178.45it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22824/57920 [02:08<03:16, 178.43it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22842/57920 [02:08<03:16, 178.45it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22860/57920 [02:08<03:16, 178.47it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22878/57920 [02:08<03:16, 178.45it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 22896/57920 [02:08<03:16, 178.45it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 22914/57920 [02:08<03:16, 178.44it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 22932/57920 [02:08<03:17, 177.31it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 22950/57920 [02:08<03:16, 177.62it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 22968/57920 [02:09<03:16, 177.84it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 22986/57920 [02:09<03:16, 178.00it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23004/57920 [02:09<03:16, 178.13it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23022/57920 [02:09<03:15, 178.22it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23040/57920 [02:09<03:15, 178.28it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23058/57920 [02:09<03:15, 178.31it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23076/57920 [02:09<03:15, 178.34it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23094/57920 [02:09<03:15, 178.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23112/57920 [02:09<03:15, 178.39it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23130/57920 [02:09<03:14, 178.42it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23148/57920 [02:10<03:14, 178.42it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 23166/57920 [02:10<03:14, 178.40it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23184/57920 [02:10<03:14, 178.41it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23202/57920 [02:10<03:14, 178.41it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23220/57920 [02:10<03:14, 178.42it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23238/57920 [02:10<03:14, 178.42it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23256/57920 [02:10<03:14, 178.44it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23274/57920 [02:10<03:14, 178.45it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23292/57920 [02:10<03:14, 178.44it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23310/57920 [02:11<03:13, 178.44it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23328/57920 [02:11<03:14, 178.02it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23346/57920 [02:11<03:14, 178.10it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23364/57920 [02:11<03:13, 178.19it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23382/57920 [02:11<03:13, 178.25it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23400/57920 [02:11<03:13, 178.31it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23418/57920 [02:11<03:13, 178.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23436/57920 [02:11<03:13, 178.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23454/57920 [02:11<03:13, 178.41it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23472/57920 [02:11<03:13, 178.43it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23490/57920 [02:12<03:12, 178.43it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23508/57920 [02:12<03:12, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23526/57920 [02:12<03:12, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23544/57920 [02:12<03:12, 178.45it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23562/57920 [02:12<03:12, 178.46it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23580/57920 [02:12<03:12, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23598/57920 [02:12<03:12, 178.42it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23616/57920 [02:12<03:12, 178.42it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23634/57920 [02:12<03:12, 178.42it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23652/57920 [02:12<03:12, 178.45it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23670/57920 [02:13<03:11, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23688/57920 [02:13<03:11, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23706/57920 [02:13<03:11, 178.43it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23724/57920 [02:13<03:11, 178.42it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23742/57920 [02:13<03:11, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23760/57920 [02:13<03:11, 178.45it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23778/57920 [02:13<03:11, 178.42it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23796/57920 [02:13<03:11, 178.43it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23814/57920 [02:13<03:11, 178.42it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23832/57920 [02:13<03:11, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23850/57920 [02:14<03:10, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23868/57920 [02:14<03:10, 178.43it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23886/57920 [02:14<03:10, 178.45it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23904/57920 [02:14<03:10, 178.46it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23922/57920 [02:14<03:10, 178.46it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23940/57920 [02:14<03:10, 178.45it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23958/57920 [02:14<03:10, 178.45it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23976/57920 [02:14<03:10, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23994/57920 [02:14<03:10, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24012/57920 [02:14<03:10, 178.44it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24030/57920 [02:15<03:09, 178.43it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24048/57920 [02:15<03:09, 178.43it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24066/57920 [02:15<03:09, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24084/57920 [02:15<03:09, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24102/57920 [02:15<03:09, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24120/57920 [02:15<03:09, 178.43it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24138/57920 [02:15<03:09, 178.43it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24156/57920 [02:15<03:09, 178.43it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24174/57920 [02:15<03:09, 178.43it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24192/57920 [02:15<03:09, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24210/57920 [02:16<03:08, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24228/57920 [02:16<03:08, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24246/57920 [02:16<03:08, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24264/57920 [02:16<03:08, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24282/57920 [02:16<03:08, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24300/57920 [02:16<03:08, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24318/57920 [02:16<03:08, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24336/57920 [02:16<03:08, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24354/57920 [02:16<03:08, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24372/57920 [02:16<03:07, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24390/57920 [02:17<03:07, 178.47it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24408/57920 [02:17<03:07, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24426/57920 [02:17<03:07, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24444/57920 [02:17<03:07, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24462/57920 [02:17<03:07, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24480/57920 [02:17<03:07, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24498/57920 [02:17<03:07, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24516/57920 [02:17<03:07, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24534/57920 [02:17<03:07, 178.45it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24552/57920 [02:17<03:06, 178.46it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24570/57920 [02:18<03:06, 178.43it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24588/57920 [02:18<03:06, 178.44it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24606/57920 [02:18<03:06, 178.45it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24624/57920 [02:18<03:06, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24642/57920 [02:18<03:06, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24660/57920 [02:18<03:06, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24678/57920 [02:18<03:06, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24696/57920 [02:18<03:06, 178.45it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24714/57920 [02:18<03:06, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24732/57920 [02:18<03:05, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24750/57920 [02:19<03:05, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24768/57920 [02:19<03:05, 178.42it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24786/57920 [02:19<03:05, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24804/57920 [02:19<03:05, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24822/57920 [02:19<03:05, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24840/57920 [02:19<03:05, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24858/57920 [02:19<03:05, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24876/57920 [02:19<03:05, 178.42it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24894/57920 [02:19<03:05, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24912/57920 [02:19<03:04, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24930/57920 [02:20<03:04, 178.45it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24948/57920 [02:20<03:04, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24966/57920 [02:20<03:04, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24984/57920 [02:20<03:04, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25002/57920 [02:20<03:04, 178.46it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25020/57920 [02:20<03:04, 178.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25038/57920 [02:20<03:04, 178.37it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25056/57920 [02:20<03:04, 178.39it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25074/57920 [02:20<03:04, 178.40it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25092/57920 [02:20<03:03, 178.43it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25110/57920 [02:21<03:03, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25128/57920 [02:21<03:03, 178.44it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25146/57920 [02:21<03:03, 178.46it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25164/57920 [02:21<03:03, 178.47it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25182/57920 [02:21<03:03, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25200/57920 [02:21<03:03, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25218/57920 [02:21<03:03, 178.43it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25236/57920 [02:21<03:03, 178.42it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25254/57920 [02:21<03:03, 178.43it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25272/57920 [02:21<03:02, 178.42it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25290/57920 [02:22<03:02, 178.42it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25308/57920 [02:22<03:02, 178.42it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 25326/57920 [02:22<03:02, 178.43it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25344/57920 [02:22<03:02, 178.42it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25362/57920 [02:22<03:02, 178.43it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25380/57920 [02:22<03:02, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25398/57920 [02:22<03:02, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25416/57920 [02:22<03:02, 178.43it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25434/57920 [02:22<03:02, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25452/57920 [02:23<03:01, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25470/57920 [02:23<03:01, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25488/57920 [02:23<03:01, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25506/57920 [02:23<03:01, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25524/57920 [02:23<03:01, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25542/57920 [02:23<03:01, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25560/57920 [02:23<03:01, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25578/57920 [02:23<03:01, 178.44it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25596/57920 [02:23<03:01, 178.46it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25614/57920 [02:23<03:01, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25632/57920 [02:24<03:00, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25650/57920 [02:24<03:00, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25668/57920 [02:24<03:00, 178.46it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25686/57920 [02:24<03:00, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25704/57920 [02:24<03:00, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25722/57920 [02:24<03:00, 178.45it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25740/57920 [02:24<03:00, 178.46it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25758/57920 [02:24<03:00, 178.46it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25776/57920 [02:24<03:00, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25794/57920 [02:24<03:00, 178.47it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25812/57920 [02:25<02:59, 178.47it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25830/57920 [02:25<02:59, 178.47it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25848/57920 [02:25<02:59, 178.47it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25866/57920 [02:25<02:59, 178.46it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25884/57920 [02:25<02:59, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25902/57920 [02:25<02:59, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25920/57920 [02:25<02:59, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25938/57920 [02:25<02:59, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25956/57920 [02:25<02:59, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25974/57920 [02:25<02:59, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25992/57920 [02:26<02:58, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26010/57920 [02:26<02:58, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26028/57920 [02:26<02:58, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26046/57920 [02:26<02:58, 178.46it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26064/57920 [02:26<02:58, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26082/57920 [02:26<02:58, 178.46it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26100/57920 [02:26<02:58, 178.46it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26118/57920 [02:26<02:58, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26136/57920 [02:26<02:58, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26154/57920 [02:26<02:58, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26172/57920 [02:27<02:57, 178.46it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26190/57920 [02:27<02:57, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26208/57920 [02:27<02:57, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26226/57920 [02:27<02:57, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26244/57920 [02:27<02:57, 178.45it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26262/57920 [02:27<02:57, 178.44it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26280/57920 [02:27<02:57, 178.42it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26298/57920 [02:27<02:57, 178.43it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26316/57920 [02:27<02:57, 178.42it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26334/57920 [02:27<02:57, 178.43it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26352/57920 [02:28<02:56, 178.42it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26370/57920 [02:28<02:56, 178.42it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26388/57920 [02:28<02:56, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26406/57920 [02:28<02:56, 178.45it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26424/57920 [02:28<02:56, 178.45it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26442/57920 [02:28<02:56, 178.45it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26460/57920 [02:28<02:56, 178.45it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26478/57920 [02:28<02:56, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26496/57920 [02:28<02:56, 178.42it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26514/57920 [02:28<02:56, 178.41it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26532/57920 [02:29<02:55, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26550/57920 [02:29<02:55, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26568/57920 [02:29<02:55, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26586/57920 [02:29<02:55, 178.45it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26604/57920 [02:29<02:55, 178.45it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26622/57920 [02:29<02:55, 178.45it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26640/57920 [02:29<02:55, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26658/57920 [02:29<02:55, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26676/57920 [02:29<02:55, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26694/57920 [02:29<02:54, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26712/57920 [02:30<02:54, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26730/57920 [02:30<02:54, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26748/57920 [02:30<02:54, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26766/57920 [02:30<02:54, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 26784/57920 [02:30<02:54, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26802/57920 [02:30<02:54, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26820/57920 [02:30<02:54, 178.42it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26838/57920 [02:30<02:54, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26856/57920 [02:30<02:54, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26874/57920 [02:30<02:53, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26892/57920 [02:31<02:53, 178.43it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26910/57920 [02:31<02:53, 178.44it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26928/57920 [02:31<02:53, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26946/57920 [02:31<02:53, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26964/57920 [02:31<02:53, 178.41it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26982/57920 [02:31<02:53, 178.40it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27000/57920 [02:31<02:53, 178.42it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27018/57920 [02:31<02:53, 178.42it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27036/57920 [02:31<02:53, 178.43it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27054/57920 [02:31<02:52, 178.43it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27072/57920 [02:32<02:52, 178.43it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27090/57920 [02:32<02:52, 178.43it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27108/57920 [02:32<02:52, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27126/57920 [02:32<02:52, 178.45it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27144/57920 [02:32<02:52, 178.45it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27162/57920 [02:32<02:52, 178.43it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27180/57920 [02:32<02:52, 178.43it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27198/57920 [02:32<02:52, 178.45it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27216/57920 [02:32<02:52, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27234/57920 [02:32<02:51, 178.42it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27252/57920 [02:33<02:51, 178.43it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27270/57920 [02:33<02:51, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27288/57920 [02:33<02:51, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27306/57920 [02:33<02:51, 178.45it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27324/57920 [02:33<02:51, 178.45it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27342/57920 [02:33<02:51, 178.46it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27360/57920 [02:33<02:51, 178.45it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27378/57920 [02:33<02:51, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27396/57920 [02:33<02:51, 178.44it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27414/57920 [02:34<02:50, 178.46it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27432/57920 [02:34<02:50, 178.46it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27450/57920 [02:34<02:51, 177.46it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27468/57920 [02:34<02:51, 177.73it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27486/57920 [02:34<02:51, 177.93it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 27504/57920 [02:34<02:50, 178.09it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27522/57920 [02:34<02:50, 178.19it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27540/57920 [02:34<02:50, 178.25it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27558/57920 [02:34<02:50, 178.30it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27576/57920 [02:34<02:50, 178.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27594/57920 [02:35<02:50, 178.37it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27612/57920 [02:35<02:49, 178.41it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27630/57920 [02:35<02:49, 178.42it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27648/57920 [02:35<02:49, 178.42it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27666/57920 [02:35<02:49, 178.44it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27684/57920 [02:35<02:49, 178.44it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27702/57920 [02:35<02:49, 178.44it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27720/57920 [02:35<02:49, 178.47it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27738/57920 [02:35<02:49, 178.45it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27756/57920 [02:35<02:49, 178.47it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27774/57920 [02:36<02:48, 178.45it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27792/57920 [02:36<02:48, 178.46it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27810/57920 [02:36<02:48, 178.47it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27828/57920 [02:36<02:48, 178.46it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27846/57920 [02:36<02:48, 178.47it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27864/57920 [02:36<02:48, 178.46it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27882/57920 [02:36<02:48, 178.45it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27900/57920 [02:36<02:48, 178.45it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27918/57920 [02:36<02:48, 178.41it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27936/57920 [02:36<02:48, 178.39it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27954/57920 [02:37<02:47, 178.39it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27972/57920 [02:37<02:47, 178.41it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27990/57920 [02:37<02:47, 178.42it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28008/57920 [02:37<02:47, 178.41it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28026/57920 [02:37<02:47, 178.43it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28044/57920 [02:37<02:47, 178.44it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28062/57920 [02:37<02:47, 178.42it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28080/57920 [02:37<02:47, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28098/57920 [02:37<02:47, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28116/57920 [02:37<02:47, 178.47it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28134/57920 [02:38<02:46, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28152/57920 [02:38<02:46, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28170/57920 [02:38<02:46, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28188/57920 [02:38<02:46, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28206/57920 [02:38<02:46, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 28224/57920 [02:38<02:46, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28242/57920 [02:38<02:46, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28260/57920 [02:38<02:46, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28278/57920 [02:38<02:46, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28296/57920 [02:38<02:46, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28314/57920 [02:39<02:45, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28332/57920 [02:39<02:45, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28350/57920 [02:39<02:45, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28368/57920 [02:39<02:45, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28386/57920 [02:39<02:45, 178.43it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28404/57920 [02:39<02:45, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28422/57920 [02:39<02:45, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28440/57920 [02:39<02:45, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28458/57920 [02:39<02:45, 178.44it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28476/57920 [02:39<02:45, 178.43it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28494/57920 [02:40<02:44, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28512/57920 [02:40<02:44, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28530/57920 [02:40<02:44, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28548/57920 [02:40<02:44, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28566/57920 [02:40<02:44, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28584/57920 [02:40<02:44, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28602/57920 [02:40<02:44, 178.45it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28620/57920 [02:40<02:44, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28638/57920 [02:40<02:44, 178.46it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28656/57920 [02:40<02:43, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28674/57920 [02:41<02:43, 178.46it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28692/57920 [02:41<02:43, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28710/57920 [02:41<02:43, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28728/57920 [02:41<02:43, 178.46it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28746/57920 [02:41<02:43, 178.46it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28764/57920 [02:41<02:43, 178.44it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28782/57920 [02:41<02:43, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28800/57920 [02:41<02:43, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28818/57920 [02:41<02:43, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28836/57920 [02:41<02:42, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28854/57920 [02:42<02:42, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28872/57920 [02:42<02:42, 178.43it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28890/57920 [02:42<02:42, 178.43it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28908/57920 [02:42<02:42, 178.44it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28926/57920 [02:42<02:42, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 28944/57920 [02:42<02:42, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28962/57920 [02:42<02:42, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28980/57920 [02:42<02:42, 178.44it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28998/57920 [02:42<02:42, 178.44it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29016/57920 [02:42<02:41, 178.44it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29034/57920 [02:43<02:41, 178.43it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29052/57920 [02:43<02:41, 178.42it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29070/57920 [02:43<02:41, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29088/57920 [02:43<02:41, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29106/57920 [02:43<02:41, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29124/57920 [02:43<02:41, 178.46it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29142/57920 [02:43<02:41, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29160/57920 [02:43<02:41, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29178/57920 [02:43<02:41, 178.44it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29196/57920 [02:43<02:40, 178.43it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29214/57920 [02:44<02:40, 178.45it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29232/57920 [02:44<02:40, 178.44it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29250/57920 [02:44<02:40, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29268/57920 [02:44<02:40, 178.46it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29286/57920 [02:44<02:40, 178.46it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29304/57920 [02:44<02:40, 178.46it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29322/57920 [02:44<02:40, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29340/57920 [02:44<02:40, 178.44it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29358/57920 [02:44<02:40, 178.44it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29376/57920 [02:45<02:39, 178.43it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29394/57920 [02:45<02:39, 178.43it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29412/57920 [02:45<02:39, 178.43it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29430/57920 [02:45<02:39, 178.44it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29448/57920 [02:45<02:39, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29466/57920 [02:45<02:39, 178.46it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29484/57920 [02:45<02:39, 178.44it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29502/57920 [02:45<02:39, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29520/57920 [02:45<02:39, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29538/57920 [02:45<02:39, 178.46it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29556/57920 [02:46<02:38, 178.46it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29574/57920 [02:46<02:38, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29592/57920 [02:46<02:38, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29610/57920 [02:46<02:38, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29628/57920 [02:46<02:38, 178.44it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29646/57920 [02:46<02:38, 178.43it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29664/57920 [02:46<02:38, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 29682/57920 [02:46<02:38, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29700/57920 [02:46<02:38, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29718/57920 [02:46<02:38, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29736/57920 [02:47<02:37, 178.46it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29754/57920 [02:47<02:37, 178.44it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29772/57920 [02:47<02:37, 178.42it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29790/57920 [02:47<02:37, 178.43it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29808/57920 [02:47<02:37, 178.45it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29826/57920 [02:47<02:37, 178.42it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29844/57920 [02:47<02:37, 178.42it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29862/57920 [02:47<02:37, 178.42it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29880/57920 [02:47<02:37, 178.43it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29898/57920 [02:47<02:37, 178.43it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29916/57920 [02:48<02:36, 178.45it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29934/57920 [02:48<02:36, 178.45it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29952/57920 [02:48<02:36, 178.45it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29970/57920 [02:48<02:36, 178.45it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29988/57920 [02:48<02:36, 178.45it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30006/57920 [02:48<02:36, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30024/57920 [02:48<02:36, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30042/57920 [02:48<02:36, 178.45it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30060/57920 [02:48<02:36, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30078/57920 [02:48<02:36, 178.45it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30096/57920 [02:49<02:35, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30114/57920 [02:49<02:35, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30132/57920 [02:49<02:35, 178.47it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30150/57920 [02:49<02:35, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30168/57920 [02:49<02:35, 178.47it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30186/57920 [02:49<02:35, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30204/57920 [02:49<02:35, 178.46it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30222/57920 [02:49<02:35, 178.44it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30240/57920 [02:49<02:35, 178.44it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30258/57920 [02:49<02:35, 178.44it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30276/57920 [02:50<02:34, 178.44it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30294/57920 [02:50<02:34, 178.43it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30312/57920 [02:50<02:34, 178.41it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30330/57920 [02:50<02:34, 178.43it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30348/57920 [02:50<02:34, 178.43it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30366/57920 [02:50<02:34, 178.43it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30384/57920 [02:50<02:34, 178.43it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30402/57920 [02:50<02:34, 178.44it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30420/57920 [02:50<02:34, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30438/57920 [02:50<02:34, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30456/57920 [02:51<02:33, 178.43it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30474/57920 [02:51<02:33, 178.44it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30492/57920 [02:51<02:33, 178.47it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30510/57920 [02:51<02:33, 178.47it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30528/57920 [02:51<02:33, 178.48it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30546/57920 [02:51<02:33, 178.47it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30564/57920 [02:51<02:33, 178.47it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30582/57920 [02:51<02:33, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30600/57920 [02:51<02:33, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30618/57920 [02:51<02:32, 178.46it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30636/57920 [02:52<02:32, 178.46it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30654/57920 [02:52<02:32, 178.46it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30672/57920 [02:52<02:32, 178.46it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30690/57920 [02:52<02:32, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30708/57920 [02:52<02:32, 178.44it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30726/57920 [02:52<02:32, 178.43it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30744/57920 [02:52<02:32, 178.42it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30762/57920 [02:52<02:32, 178.44it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30780/57920 [02:52<02:32, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30798/57920 [02:52<02:31, 178.43it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30816/57920 [02:53<02:31, 178.42it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30834/57920 [02:53<02:31, 178.44it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30852/57920 [02:53<02:31, 178.44it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30870/57920 [02:53<02:31, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30888/57920 [02:53<02:31, 178.46it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30906/57920 [02:53<02:31, 178.47it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30924/57920 [02:53<02:31, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30942/57920 [02:53<02:31, 178.43it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30960/57920 [02:53<02:31, 178.45it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30978/57920 [02:53<02:30, 178.44it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30996/57920 [02:54<02:30, 178.44it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 31014/57920 [02:54<02:30, 178.44it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 31032/57920 [02:54<02:30, 178.44it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 31050/57920 [02:54<02:30, 178.44it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 31068/57920 [02:54<02:30, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 31086/57920 [02:54<02:30, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 31104/57920 [02:54<02:30, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 31122/57920 [02:54<02:30, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31140/57920 [02:54<02:30, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31158/57920 [02:54<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31176/57920 [02:55<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31194/57920 [02:55<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31212/57920 [02:55<02:29, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31230/57920 [02:55<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31248/57920 [02:55<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31266/57920 [02:55<02:29, 178.47it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31284/57920 [02:55<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31302/57920 [02:55<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31320/57920 [02:55<02:29, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31338/57920 [02:55<02:28, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31356/57920 [02:56<02:28, 178.47it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31374/57920 [02:56<02:28, 178.47it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31392/57920 [02:56<02:28, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31410/57920 [02:56<02:28, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31428/57920 [02:56<02:28, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31446/57920 [02:56<02:28, 178.43it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31464/57920 [02:56<02:28, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31482/57920 [02:56<02:28, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31500/57920 [02:56<02:28, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31518/57920 [02:57<02:27, 178.46it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31536/57920 [02:57<02:27, 178.45it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31554/57920 [02:57<02:27, 178.46it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31572/57920 [02:57<02:27, 178.46it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31590/57920 [02:57<02:27, 178.47it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31608/57920 [02:57<02:27, 178.47it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31626/57920 [02:57<02:27, 178.46it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31644/57920 [02:57<02:27, 178.40it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31662/57920 [02:57<02:27, 178.40it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31680/57920 [02:57<02:27, 178.41it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31698/57920 [02:58<02:26, 178.42it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31716/57920 [02:58<02:27, 177.42it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31734/57920 [02:58<02:27, 177.70it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31752/57920 [02:58<02:27, 177.92it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31770/57920 [02:58<02:26, 178.07it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31788/57920 [02:58<02:26, 178.19it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31806/57920 [02:58<02:26, 178.26it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31824/57920 [02:58<02:26, 178.32it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31842/57920 [02:58<02:26, 178.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31860/57920 [02:58<02:26, 178.38it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31878/57920 [02:59<02:25, 178.40it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31896/57920 [02:59<02:25, 178.41it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31914/57920 [02:59<02:25, 178.39it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31932/57920 [02:59<02:25, 178.41it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31950/57920 [02:59<02:25, 178.41it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31968/57920 [02:59<02:25, 178.43it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31986/57920 [02:59<02:25, 178.44it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32004/57920 [02:59<02:25, 178.45it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32022/57920 [02:59<02:25, 178.45it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32040/57920 [02:59<02:25, 178.45it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32058/57920 [03:00<02:24, 178.40it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32076/57920 [03:00<02:24, 178.43it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32094/57920 [03:00<02:24, 178.43it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32112/57920 [03:00<02:24, 178.43it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32130/57920 [03:00<02:24, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32148/57920 [03:00<02:24, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32166/57920 [03:00<02:24, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32184/57920 [03:00<02:24, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32202/57920 [03:00<02:24, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32220/57920 [03:00<02:24, 178.43it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32238/57920 [03:01<02:23, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32256/57920 [03:01<02:23, 178.45it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32274/57920 [03:01<02:23, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32292/57920 [03:01<02:23, 178.24it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32310/57920 [03:01<02:23, 178.26it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32328/57920 [03:01<02:23, 178.31it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32346/57920 [03:01<02:23, 178.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32364/57920 [03:01<02:23, 178.37it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32382/57920 [03:01<02:23, 178.38it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32400/57920 [03:01<02:23, 178.39it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32418/57920 [03:02<02:22, 178.42it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32436/57920 [03:02<02:22, 178.41it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32454/57920 [03:02<02:22, 178.42it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32472/57920 [03:02<02:22, 178.43it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32490/57920 [03:02<02:22, 178.44it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32508/57920 [03:02<02:22, 178.46it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32526/57920 [03:02<02:22, 178.47it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32544/57920 [03:02<02:22, 178.46it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32562/57920 [03:02<02:22, 178.46it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32580/57920 [03:02<02:22, 178.45it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32598/57920 [03:03<02:21, 178.45it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32616/57920 [03:03<02:21, 178.45it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32634/57920 [03:03<02:21, 178.46it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32652/57920 [03:03<02:21, 178.47it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32670/57920 [03:03<02:21, 178.48it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32688/57920 [03:03<02:21, 178.47it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32706/57920 [03:03<02:21, 178.47it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32724/57920 [03:03<02:21, 178.45it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32742/57920 [03:03<02:21, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32760/57920 [03:03<02:20, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32778/57920 [03:04<02:20, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32796/57920 [03:04<02:20, 178.45it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32814/57920 [03:04<02:20, 178.46it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32832/57920 [03:04<02:20, 178.47it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32850/57920 [03:04<02:20, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32868/57920 [03:04<02:20, 178.42it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32886/57920 [03:04<02:20, 178.42it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32904/57920 [03:04<02:20, 178.40it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32922/57920 [03:04<02:20, 178.39it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32940/57920 [03:04<02:20, 178.40it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32958/57920 [03:05<02:19, 178.40it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32976/57920 [03:05<02:19, 178.40it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32994/57920 [03:05<02:19, 178.41it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33012/57920 [03:05<02:19, 178.42it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33030/57920 [03:05<02:19, 178.43it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33048/57920 [03:05<02:19, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33066/57920 [03:05<02:19, 178.42it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33084/57920 [03:05<02:19, 178.43it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33102/57920 [03:05<02:19, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33120/57920 [03:05<02:18, 178.45it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33138/57920 [03:06<02:18, 178.46it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33156/57920 [03:06<02:18, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33174/57920 [03:06<02:18, 178.45it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33192/57920 [03:06<02:18, 178.46it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33210/57920 [03:06<02:18, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33228/57920 [03:06<02:18, 178.43it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33246/57920 [03:06<02:18, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33264/57920 [03:06<02:18, 178.44it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33282/57920 [03:06<02:18, 178.43it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 33300/57920 [03:06<02:17, 178.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33318/57920 [03:07<02:17, 178.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33336/57920 [03:07<02:17, 178.46it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33354/57920 [03:07<02:17, 178.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33372/57920 [03:07<02:17, 178.45it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33390/57920 [03:07<02:17, 178.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33408/57920 [03:07<02:17, 178.43it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33426/57920 [03:07<02:18, 177.07it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33444/57920 [03:07<02:17, 177.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33462/57920 [03:07<02:17, 177.73it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33480/57920 [03:08<02:17, 177.93it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33498/57920 [03:08<02:17, 178.07it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33516/57920 [03:08<02:16, 178.17it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33534/57920 [03:08<02:16, 178.24it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33552/57920 [03:08<02:16, 178.29it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33570/57920 [03:08<02:16, 178.31it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33588/57920 [03:08<02:16, 178.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33606/57920 [03:08<02:16, 178.37it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33624/57920 [03:08<02:16, 178.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33642/57920 [03:08<02:16, 178.38it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33660/57920 [03:09<02:15, 178.40it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33678/57920 [03:09<02:15, 178.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33696/57920 [03:09<02:15, 178.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33714/57920 [03:09<02:15, 178.46it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33732/57920 [03:09<02:15, 178.46it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33750/57920 [03:09<02:15, 178.45it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33768/57920 [03:09<02:15, 178.44it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33786/57920 [03:09<02:15, 178.45it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33804/57920 [03:09<02:15, 178.43it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33822/57920 [03:09<02:15, 178.43it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33840/57920 [03:10<02:14, 178.42it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33858/57920 [03:10<02:14, 178.43it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33876/57920 [03:10<02:14, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33894/57920 [03:10<02:14, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33912/57920 [03:10<02:14, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33930/57920 [03:10<02:14, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33948/57920 [03:10<02:14, 178.45it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33966/57920 [03:10<02:14, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 33984/57920 [03:10<02:14, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 34002/57920 [03:10<02:14, 178.42it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 34020/57920 [03:11<02:13, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34038/57920 [03:11<02:13, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34056/57920 [03:11<02:13, 178.45it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34074/57920 [03:11<02:13, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34092/57920 [03:11<02:13, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34110/57920 [03:11<02:13, 178.45it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34128/57920 [03:11<02:13, 178.46it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34146/57920 [03:11<02:13, 178.46it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34164/57920 [03:11<02:13, 178.45it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34182/57920 [03:11<02:13, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34200/57920 [03:12<02:12, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34218/57920 [03:12<02:12, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34236/57920 [03:12<02:12, 178.42it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34254/57920 [03:12<02:12, 178.42it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34272/57920 [03:12<02:12, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34290/57920 [03:12<02:12, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34308/57920 [03:12<02:12, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34326/57920 [03:12<02:12, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34344/57920 [03:12<02:12, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34362/57920 [03:12<02:12, 178.45it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34380/57920 [03:13<02:11, 178.43it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34398/57920 [03:13<02:11, 178.44it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34416/57920 [03:13<02:11, 178.46it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34434/57920 [03:13<02:11, 178.47it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34452/57920 [03:13<02:11, 178.47it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34470/57920 [03:13<02:11, 178.47it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34488/57920 [03:13<02:11, 178.47it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34506/57920 [03:13<02:11, 178.47it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34524/57920 [03:13<02:11, 178.46it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34542/57920 [03:13<02:10, 178.46it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34560/57920 [03:14<02:10, 178.46it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34578/57920 [03:14<02:10, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34596/57920 [03:14<02:10, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34614/57920 [03:14<02:10, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34632/57920 [03:14<02:10, 178.45it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34650/57920 [03:14<02:10, 178.45it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34668/57920 [03:14<02:10, 178.43it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34686/57920 [03:14<02:10, 178.42it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34704/57920 [03:14<02:10, 178.43it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34722/57920 [03:14<02:10, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 34740/57920 [03:15<02:09, 178.43it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34758/57920 [03:15<02:09, 178.41it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34776/57920 [03:15<02:09, 178.40it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34794/57920 [03:15<02:09, 178.42it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34812/57920 [03:15<02:09, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34830/57920 [03:15<02:09, 178.45it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34848/57920 [03:15<02:09, 178.46it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34866/57920 [03:15<02:09, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34884/57920 [03:15<02:09, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34902/57920 [03:15<02:09, 178.43it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34920/57920 [03:16<02:08, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34938/57920 [03:16<02:08, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34956/57920 [03:16<02:08, 178.45it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34974/57920 [03:16<02:08, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34992/57920 [03:16<02:08, 178.43it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35010/57920 [03:16<02:08, 178.44it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35028/57920 [03:16<02:08, 178.43it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35046/57920 [03:16<02:08, 178.44it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35064/57920 [03:16<02:08, 178.44it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35082/57920 [03:16<02:07, 178.46it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35100/57920 [03:17<02:07, 178.46it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35118/57920 [03:17<02:07, 178.47it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35136/57920 [03:17<02:07, 178.47it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35154/57920 [03:17<02:07, 178.46it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35172/57920 [03:17<02:07, 178.44it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35190/57920 [03:17<02:07, 178.44it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35208/57920 [03:17<02:07, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35226/57920 [03:17<02:07, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35244/57920 [03:17<02:07, 178.46it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35262/57920 [03:17<02:06, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35280/57920 [03:18<02:06, 178.43it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35298/57920 [03:18<02:06, 178.43it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35316/57920 [03:18<02:06, 178.44it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35334/57920 [03:18<02:06, 178.44it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35352/57920 [03:18<02:06, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35370/57920 [03:18<02:06, 178.46it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35388/57920 [03:18<02:06, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35406/57920 [03:18<02:06, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35424/57920 [03:18<02:06, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35442/57920 [03:19<02:05, 178.46it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 35460/57920 [03:19<02:05, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35478/57920 [03:19<02:05, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35496/57920 [03:19<02:05, 178.45it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35514/57920 [03:19<02:05, 178.47it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35532/57920 [03:19<02:05, 178.46it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35550/57920 [03:19<02:05, 178.48it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35568/57920 [03:19<02:05, 178.47it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35586/57920 [03:19<02:05, 178.48it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35604/57920 [03:19<02:05, 178.47it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35622/57920 [03:20<02:04, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35640/57920 [03:20<02:04, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35658/57920 [03:20<02:04, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35676/57920 [03:20<02:04, 178.47it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35694/57920 [03:20<02:04, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35712/57920 [03:20<02:04, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35730/57920 [03:20<02:04, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35748/57920 [03:20<02:04, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35766/57920 [03:20<02:04, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35784/57920 [03:20<02:04, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35802/57920 [03:21<02:03, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35820/57920 [03:21<02:03, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35838/57920 [03:21<02:03, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35856/57920 [03:21<02:03, 178.44it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35874/57920 [03:21<02:03, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35892/57920 [03:21<02:03, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35910/57920 [03:21<02:03, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35928/57920 [03:21<02:03, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35946/57920 [03:21<02:03, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35964/57920 [03:21<02:03, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35982/57920 [03:22<02:02, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36000/57920 [03:22<02:02, 178.44it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36018/57920 [03:22<02:02, 178.44it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36036/57920 [03:22<02:02, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36054/57920 [03:22<02:02, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36072/57920 [03:22<02:02, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36090/57920 [03:22<02:02, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36108/57920 [03:22<02:02, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36126/57920 [03:22<02:02, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36144/57920 [03:22<02:02, 178.47it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36162/57920 [03:23<02:01, 178.45it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36180/57920 [03:23<02:01, 178.46it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36198/57920 [03:23<02:01, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36216/57920 [03:23<02:01, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36234/57920 [03:23<02:01, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36252/57920 [03:23<02:01, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36270/57920 [03:23<02:01, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36288/57920 [03:23<02:01, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36306/57920 [03:23<02:01, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36324/57920 [03:23<02:01, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36342/57920 [03:24<02:00, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36360/57920 [03:24<02:00, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36378/57920 [03:24<02:00, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36396/57920 [03:24<02:00, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36414/57920 [03:24<02:00, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36432/57920 [03:24<02:00, 178.46it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36450/57920 [03:24<02:00, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36468/57920 [03:24<02:00, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36486/57920 [03:24<02:00, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36504/57920 [03:24<02:00, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36522/57920 [03:25<01:59, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36540/57920 [03:25<01:59, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36558/57920 [03:25<01:59, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36576/57920 [03:25<01:59, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36594/57920 [03:25<01:59, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36612/57920 [03:25<01:59, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36630/57920 [03:25<01:59, 178.45it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36648/57920 [03:25<01:59, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36666/57920 [03:25<01:59, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36684/57920 [03:25<01:59, 178.44it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36702/57920 [03:26<01:58, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36720/57920 [03:26<01:58, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36738/57920 [03:26<01:58, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36756/57920 [03:26<01:58, 178.43it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36774/57920 [03:26<01:58, 178.43it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36792/57920 [03:26<01:58, 178.43it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36810/57920 [03:26<01:58, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36828/57920 [03:26<01:58, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36846/57920 [03:26<01:58, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36864/57920 [03:26<01:58, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36882/57920 [03:27<01:57, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36900/57920 [03:27<01:57, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 36918/57920 [03:27<01:57, 178.46it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36936/57920 [03:27<01:57, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36954/57920 [03:27<01:57, 178.46it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36972/57920 [03:27<01:57, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36990/57920 [03:27<01:57, 178.43it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37008/57920 [03:27<01:57, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37026/57920 [03:27<01:57, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37044/57920 [03:27<01:56, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37062/57920 [03:28<01:56, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37080/57920 [03:28<01:56, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37098/57920 [03:28<01:56, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37116/57920 [03:28<01:56, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37134/57920 [03:28<01:56, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37152/57920 [03:28<01:56, 178.46it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37170/57920 [03:28<01:56, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37188/57920 [03:28<01:56, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37206/57920 [03:28<01:56, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37224/57920 [03:28<01:55, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37242/57920 [03:29<01:55, 178.45it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37260/57920 [03:29<01:55, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37278/57920 [03:29<01:55, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37296/57920 [03:29<01:55, 178.44it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37314/57920 [03:29<01:55, 178.42it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37332/57920 [03:29<01:55, 178.43it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37350/57920 [03:29<01:55, 178.44it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37368/57920 [03:29<01:55, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37386/57920 [03:29<01:55, 178.46it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37404/57920 [03:29<01:54, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37422/57920 [03:30<01:54, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37440/57920 [03:30<01:54, 178.43it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37458/57920 [03:30<01:54, 178.42it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37476/57920 [03:30<01:54, 178.42it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37494/57920 [03:30<01:54, 178.43it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37512/57920 [03:30<01:54, 178.42it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37530/57920 [03:30<01:54, 178.42it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37548/57920 [03:30<01:54, 178.43it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37566/57920 [03:30<01:54, 178.42it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37584/57920 [03:31<01:53, 178.43it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37602/57920 [03:31<01:53, 178.43it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37620/57920 [03:31<01:53, 178.43it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 37638/57920 [03:31<01:53, 178.44it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37656/57920 [03:31<01:53, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37674/57920 [03:31<01:53, 178.44it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37692/57920 [03:31<01:53, 178.44it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37710/57920 [03:31<01:53, 178.44it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37728/57920 [03:31<01:53, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37746/57920 [03:31<01:53, 178.44it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37764/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37782/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37800/57920 [03:32<01:52, 178.46it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37818/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37836/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37854/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37872/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37890/57920 [03:32<01:52, 178.46it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37908/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37926/57920 [03:32<01:52, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37944/57920 [03:33<01:51, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37962/57920 [03:33<01:51, 178.47it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37980/57920 [03:33<01:52, 177.98it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37998/57920 [03:33<01:51, 178.10it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38016/57920 [03:33<01:51, 178.20it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38034/57920 [03:33<01:51, 178.28it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38052/57920 [03:33<01:51, 178.33it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38070/57920 [03:33<01:51, 178.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38088/57920 [03:33<01:51, 178.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38106/57920 [03:33<01:51, 178.39it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38124/57920 [03:34<01:50, 178.41it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38142/57920 [03:34<01:50, 178.43it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38160/57920 [03:34<01:50, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38178/57920 [03:34<01:50, 178.46it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38196/57920 [03:34<01:50, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38214/57920 [03:34<01:50, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38232/57920 [03:34<01:50, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38250/57920 [03:34<01:50, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38268/57920 [03:34<01:50, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38286/57920 [03:34<01:50, 178.46it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38304/57920 [03:35<01:49, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38322/57920 [03:35<01:49, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38340/57920 [03:35<01:49, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 38358/57920 [03:35<01:49, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38376/57920 [03:35<01:49, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38394/57920 [03:35<01:49, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38412/57920 [03:35<01:49, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38430/57920 [03:35<01:49, 178.45it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38448/57920 [03:35<01:49, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38466/57920 [03:35<01:49, 178.44it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38484/57920 [03:36<01:48, 178.46it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38502/57920 [03:36<01:48, 178.46it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38520/57920 [03:36<01:48, 178.46it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38538/57920 [03:36<01:48, 178.44it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38556/57920 [03:36<01:48, 178.45it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38574/57920 [03:36<01:48, 178.44it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38592/57920 [03:36<01:48, 178.44it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38610/57920 [03:36<01:48, 178.43it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38628/57920 [03:36<01:48, 178.44it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38646/57920 [03:36<01:48, 178.42it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38664/57920 [03:37<01:48, 177.54it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38682/57920 [03:37<01:48, 177.80it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38700/57920 [03:37<01:47, 178.00it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38718/57920 [03:37<01:47, 178.13it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38736/57920 [03:37<01:47, 178.21it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38754/57920 [03:37<01:47, 178.27it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38772/57920 [03:37<01:47, 178.33it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38790/57920 [03:37<01:47, 178.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38808/57920 [03:37<01:47, 178.39it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38826/57920 [03:37<01:47, 178.42it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38844/57920 [03:38<01:46, 178.41it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38862/57920 [03:38<01:46, 178.39it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38880/57920 [03:38<01:46, 178.41it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38898/57920 [03:38<01:46, 178.41it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38916/57920 [03:38<01:46, 178.42it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38934/57920 [03:38<01:46, 178.41it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38952/57920 [03:38<01:46, 178.41it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38970/57920 [03:38<01:46, 178.42it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38988/57920 [03:38<01:46, 178.43it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 39006/57920 [03:38<01:46, 178.43it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 39024/57920 [03:39<01:45, 178.43it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 39042/57920 [03:39<01:45, 178.44it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 39060/57920 [03:39<01:45, 178.45it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 39078/57920 [03:39<01:45, 178.45it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39096/57920 [03:39<01:45, 178.45it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39114/57920 [03:39<01:45, 178.46it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39132/57920 [03:39<01:45, 178.42it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39150/57920 [03:39<01:45, 178.43it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39168/57920 [03:39<01:45, 178.42it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39186/57920 [03:39<01:44, 178.44it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39204/57920 [03:40<01:44, 178.41it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39222/57920 [03:40<01:44, 178.41it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39240/57920 [03:40<01:44, 178.41it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39258/57920 [03:40<01:44, 178.41it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39276/57920 [03:40<01:44, 178.42it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39294/57920 [03:40<01:44, 178.42it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39312/57920 [03:40<01:44, 178.44it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39330/57920 [03:40<01:44, 178.44it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39348/57920 [03:40<01:44, 177.59it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39366/57920 [03:40<01:44, 177.82it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39384/57920 [03:41<01:44, 178.00it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39402/57920 [03:41<01:43, 178.12it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39420/57920 [03:41<01:43, 178.21it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39438/57920 [03:41<01:43, 178.27it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39456/57920 [03:41<01:43, 178.31it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39474/57920 [03:41<01:43, 178.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39492/57920 [03:41<01:43, 178.37it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39510/57920 [03:41<01:43, 178.39it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39528/57920 [03:41<01:43, 178.40it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39546/57920 [03:42<01:42, 178.42it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39564/57920 [03:42<01:42, 178.44it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39582/57920 [03:42<01:42, 178.45it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39600/57920 [03:42<01:42, 178.45it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39618/57920 [03:42<01:42, 178.45it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39636/57920 [03:42<01:42, 178.46it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39654/57920 [03:42<01:42, 178.45it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39672/57920 [03:42<01:42, 178.44it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39690/57920 [03:42<01:42, 178.44it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39708/57920 [03:42<01:42, 178.42it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39726/57920 [03:43<01:41, 178.43it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39744/57920 [03:43<01:41, 178.43it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39762/57920 [03:43<01:41, 178.44it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39780/57920 [03:43<01:41, 178.45it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39798/57920 [03:43<01:41, 178.45it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 39816/57920 [03:43<01:41, 178.44it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39834/57920 [03:43<01:41, 178.45it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39852/57920 [03:43<01:41, 178.43it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39870/57920 [03:43<01:41, 178.44it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39888/57920 [03:43<01:41, 178.44it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39906/57920 [03:44<01:40, 178.45it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39924/57920 [03:44<01:40, 178.45it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39942/57920 [03:44<01:40, 178.46it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39960/57920 [03:44<01:40, 178.45it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39978/57920 [03:44<01:40, 178.46it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39996/57920 [03:44<01:40, 178.45it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40014/57920 [03:44<01:41, 177.27it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40032/57920 [03:44<01:40, 177.57it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40050/57920 [03:44<01:40, 177.83it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40068/57920 [03:44<01:40, 177.99it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40086/57920 [03:45<01:40, 178.14it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40104/57920 [03:45<01:39, 178.23it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40122/57920 [03:45<01:39, 178.29it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40140/57920 [03:45<01:39, 178.33it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40158/57920 [03:45<01:39, 178.39it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40176/57920 [03:45<01:39, 178.40it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40194/57920 [03:45<01:39, 178.41it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40212/57920 [03:45<01:39, 178.43it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40230/57920 [03:45<01:39, 178.44it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40248/57920 [03:45<01:39, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40266/57920 [03:46<01:38, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40284/57920 [03:46<01:38, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40302/57920 [03:46<01:38, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40320/57920 [03:46<01:38, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40338/57920 [03:46<01:38, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40356/57920 [03:46<01:38, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40374/57920 [03:46<01:38, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40392/57920 [03:46<01:38, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40410/57920 [03:46<01:38, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40428/57920 [03:46<01:38, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40446/57920 [03:47<01:37, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40464/57920 [03:47<01:37, 178.43it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40482/57920 [03:47<01:37, 178.42it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40500/57920 [03:47<01:37, 178.43it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40518/57920 [03:47<01:37, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 40536/57920 [03:47<01:37, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40554/57920 [03:47<01:37, 178.43it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40572/57920 [03:47<01:37, 178.42it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40590/57920 [03:47<01:37, 178.42it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40608/57920 [03:47<01:37, 178.43it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40626/57920 [03:48<01:36, 178.42it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40644/57920 [03:48<01:36, 178.43it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40662/57920 [03:48<01:36, 178.43it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40680/57920 [03:48<01:36, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40698/57920 [03:48<01:36, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40716/57920 [03:48<01:36, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40734/57920 [03:48<01:36, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40752/57920 [03:48<01:36, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40770/57920 [03:48<01:36, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40788/57920 [03:48<01:36, 178.44it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40806/57920 [03:49<01:35, 178.45it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40824/57920 [03:49<01:35, 178.46it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40842/57920 [03:49<01:35, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40860/57920 [03:49<01:35, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40878/57920 [03:49<01:35, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40896/57920 [03:49<01:35, 178.43it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40914/57920 [03:49<01:35, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40932/57920 [03:49<01:35, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40950/57920 [03:49<01:35, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40968/57920 [03:49<01:34, 178.46it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 40986/57920 [03:50<01:34, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41004/57920 [03:50<01:34, 178.43it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41022/57920 [03:50<01:34, 178.42it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41040/57920 [03:50<01:34, 178.40it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41058/57920 [03:50<01:34, 178.42it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41076/57920 [03:50<01:34, 178.42it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41094/57920 [03:50<01:34, 178.43it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41112/57920 [03:50<01:34, 178.43it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41130/57920 [03:50<01:34, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41148/57920 [03:50<01:33, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41166/57920 [03:51<01:33, 178.46it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41184/57920 [03:51<01:33, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41202/57920 [03:51<01:33, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41220/57920 [03:51<01:33, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41238/57920 [03:51<01:33, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 41256/57920 [03:51<01:33, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41274/57920 [03:51<01:33, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41292/57920 [03:51<01:33, 178.44it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41310/57920 [03:51<01:33, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41328/57920 [03:51<01:32, 178.45it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41346/57920 [03:52<01:32, 178.42it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41364/57920 [03:52<01:32, 178.42it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41382/57920 [03:52<01:32, 178.42it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41400/57920 [03:52<01:32, 178.43it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41418/57920 [03:52<01:32, 178.41it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41436/57920 [03:52<01:32, 178.43it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41454/57920 [03:52<01:32, 178.43it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41472/57920 [03:52<01:32, 178.42it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41490/57920 [03:52<01:32, 178.42it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41508/57920 [03:53<01:31, 178.43it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41526/57920 [03:53<01:31, 178.43it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41544/57920 [03:53<01:31, 178.43it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41562/57920 [03:53<01:31, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41580/57920 [03:53<01:31, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41598/57920 [03:53<01:31, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41616/57920 [03:53<01:31, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41634/57920 [03:53<01:31, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41652/57920 [03:53<01:31, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41670/57920 [03:53<01:31, 178.46it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41688/57920 [03:54<01:30, 178.46it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41706/57920 [03:54<01:30, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41724/57920 [03:54<01:30, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41742/57920 [03:54<01:30, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41760/57920 [03:54<01:30, 178.45it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41778/57920 [03:54<01:30, 178.45it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41796/57920 [03:54<01:30, 178.45it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41814/57920 [03:54<01:30, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41832/57920 [03:54<01:30, 178.45it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41850/57920 [03:54<01:30, 178.47it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41868/57920 [03:55<01:29, 178.47it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41886/57920 [03:55<01:29, 178.47it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41904/57920 [03:55<01:29, 178.46it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41922/57920 [03:55<01:29, 178.45it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41940/57920 [03:55<01:29, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41958/57920 [03:55<01:29, 178.44it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41976/57920 [03:55<01:29, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 41994/57920 [03:55<01:29, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42012/57920 [03:55<01:29, 178.41it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42030/57920 [03:55<01:29, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42048/57920 [03:56<01:28, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42066/57920 [03:56<01:28, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42084/57920 [03:56<01:28, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42102/57920 [03:56<01:28, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42120/57920 [03:56<01:28, 178.45it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42138/57920 [03:56<01:28, 178.45it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42156/57920 [03:56<01:28, 178.46it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42174/57920 [03:56<01:28, 178.46it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42192/57920 [03:56<01:28, 178.45it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42210/57920 [03:56<01:28, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42228/57920 [03:57<01:27, 178.42it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42246/57920 [03:57<01:27, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42264/57920 [03:57<01:27, 178.42it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42282/57920 [03:57<01:27, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42300/57920 [03:57<01:27, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42318/57920 [03:57<01:27, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42336/57920 [03:57<01:27, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42354/57920 [03:57<01:27, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42372/57920 [03:57<01:27, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42390/57920 [03:57<01:27, 178.42it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42408/57920 [03:58<01:26, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42426/57920 [03:58<01:26, 178.41it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42444/57920 [03:58<01:26, 178.40it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42462/57920 [03:58<01:26, 178.41it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42480/57920 [03:58<01:26, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42498/57920 [03:58<01:26, 178.43it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42516/57920 [03:58<01:26, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42534/57920 [03:58<01:26, 178.45it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42552/57920 [03:58<01:26, 178.44it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42570/57920 [03:58<01:26, 178.43it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42588/57920 [03:59<01:25, 178.42it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42606/57920 [03:59<01:25, 178.42it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42624/57920 [03:59<01:25, 178.43it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42642/57920 [03:59<01:25, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42660/57920 [03:59<01:25, 178.46it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42678/57920 [03:59<01:25, 178.45it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42696/57920 [03:59<01:25, 178.45it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 42714/57920 [03:59<01:25, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42732/57920 [03:59<01:25, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42750/57920 [03:59<01:25, 178.40it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42768/57920 [04:00<01:24, 178.41it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42786/57920 [04:00<01:24, 178.42it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42804/57920 [04:00<01:24, 178.42it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42822/57920 [04:00<01:24, 178.43it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42840/57920 [04:00<01:24, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42858/57920 [04:00<01:24, 178.45it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42876/57920 [04:00<01:24, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42894/57920 [04:00<01:24, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42912/57920 [04:00<01:24, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42930/57920 [04:00<01:24, 178.43it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42948/57920 [04:01<01:23, 178.43it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42966/57920 [04:01<01:23, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 42984/57920 [04:01<01:23, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43002/57920 [04:01<01:23, 178.44it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43020/57920 [04:01<01:23, 178.43it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43038/57920 [04:01<01:23, 178.46it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43056/57920 [04:01<01:23, 178.46it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43074/57920 [04:01<01:23, 178.46it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43092/57920 [04:01<01:23, 178.46it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43110/57920 [04:01<01:22, 178.46it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43128/57920 [04:02<01:22, 178.43it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43146/57920 [04:02<01:22, 178.42it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43164/57920 [04:02<01:22, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43182/57920 [04:02<01:22, 178.42it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43200/57920 [04:02<01:22, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43218/57920 [04:02<01:22, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43236/57920 [04:02<01:22, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43254/57920 [04:02<01:22, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43272/57920 [04:02<01:22, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43290/57920 [04:02<01:21, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43308/57920 [04:03<01:21, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43326/57920 [04:03<01:21, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43344/57920 [04:03<01:21, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43362/57920 [04:03<01:21, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43380/57920 [04:03<01:21, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43398/57920 [04:03<01:21, 178.42it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43416/57920 [04:03<01:21, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43434/57920 [04:03<01:21, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43452/57920 [04:03<01:21, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43470/57920 [04:03<01:20, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43488/57920 [04:04<01:20, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43506/57920 [04:04<01:20, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43524/57920 [04:04<01:20, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43542/57920 [04:04<01:20, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43560/57920 [04:04<01:20, 178.46it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43578/57920 [04:04<01:20, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43596/57920 [04:04<01:20, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43614/57920 [04:04<01:20, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43632/57920 [04:04<01:20, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43650/57920 [04:05<01:19, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43668/57920 [04:05<01:19, 178.45it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43686/57920 [04:05<01:19, 178.44it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43704/57920 [04:05<01:19, 178.43it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43722/57920 [04:05<01:19, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43740/57920 [04:05<01:19, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43758/57920 [04:05<01:19, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43776/57920 [04:05<01:19, 178.46it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43794/57920 [04:05<01:19, 178.46it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43812/57920 [04:05<01:19, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43830/57920 [04:06<01:18, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43848/57920 [04:06<01:18, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43866/57920 [04:06<01:18, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43884/57920 [04:06<01:18, 178.43it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43902/57920 [04:06<01:18, 178.42it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43920/57920 [04:06<01:18, 178.42it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43938/57920 [04:06<01:18, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43956/57920 [04:06<01:18, 178.43it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43974/57920 [04:06<01:18, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 43992/57920 [04:06<01:18, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44010/57920 [04:07<01:17, 178.43it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44028/57920 [04:07<01:17, 178.43it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44046/57920 [04:07<01:17, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44064/57920 [04:07<01:17, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44082/57920 [04:07<01:17, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44100/57920 [04:07<01:17, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44118/57920 [04:07<01:17, 178.44it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44136/57920 [04:07<01:17, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 44154/57920 [04:07<01:17, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44172/57920 [04:07<01:17, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44190/57920 [04:08<01:16, 178.46it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44208/57920 [04:08<01:16, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44226/57920 [04:08<01:16, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44244/57920 [04:08<01:16, 178.46it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44262/57920 [04:08<01:16, 178.46it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44280/57920 [04:08<01:16, 178.45it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44298/57920 [04:08<01:16, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44316/57920 [04:08<01:16, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44334/57920 [04:08<01:16, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44352/57920 [04:08<01:16, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44370/57920 [04:09<01:15, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44388/57920 [04:09<01:15, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44406/57920 [04:09<01:15, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44424/57920 [04:09<01:15, 178.46it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44442/57920 [04:09<01:15, 178.47it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44460/57920 [04:09<01:15, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44478/57920 [04:09<01:15, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44496/57920 [04:09<01:15, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44514/57920 [04:09<01:15, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44532/57920 [04:09<01:15, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44550/57920 [04:10<01:14, 178.43it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44568/57920 [04:10<01:14, 178.42it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44586/57920 [04:10<01:14, 178.42it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44604/57920 [04:10<01:14, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44622/57920 [04:10<01:14, 178.46it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44640/57920 [04:10<01:14, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44658/57920 [04:10<01:14, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44676/57920 [04:10<01:14, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44694/57920 [04:10<01:14, 178.42it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44712/57920 [04:10<01:14, 178.43it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44730/57920 [04:11<01:13, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44748/57920 [04:11<01:13, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44766/57920 [04:11<01:13, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44784/57920 [04:11<01:13, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44802/57920 [04:11<01:13, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44820/57920 [04:11<01:13, 178.45it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44838/57920 [04:11<01:13, 178.44it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44856/57920 [04:11<01:13, 178.43it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 44874/57920 [04:11<01:13, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44892/57920 [04:11<01:13, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44910/57920 [04:12<01:12, 178.42it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44928/57920 [04:12<01:12, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44946/57920 [04:12<01:12, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44964/57920 [04:12<01:12, 178.46it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44982/57920 [04:12<01:12, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45000/57920 [04:12<01:12, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45018/57920 [04:12<01:12, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45036/57920 [04:12<01:12, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45054/57920 [04:12<01:12, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45072/57920 [04:12<01:11, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45090/57920 [04:13<01:11, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45108/57920 [04:13<01:11, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45126/57920 [04:13<01:11, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45144/57920 [04:13<01:11, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45162/57920 [04:13<01:11, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45180/57920 [04:13<01:11, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45198/57920 [04:13<01:11, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45216/57920 [04:13<01:11, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45234/57920 [04:13<01:11, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45252/57920 [04:13<01:10, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45270/57920 [04:14<01:10, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45288/57920 [04:14<01:10, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45306/57920 [04:14<01:10, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45324/57920 [04:14<01:10, 178.44it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45342/57920 [04:14<01:10, 178.43it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45360/57920 [04:14<01:10, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45378/57920 [04:14<01:10, 178.46it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45396/57920 [04:14<01:10, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45414/57920 [04:14<01:10, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45432/57920 [04:14<01:09, 178.45it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45450/57920 [04:15<01:09, 178.46it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45468/57920 [04:15<01:09, 178.42it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45486/57920 [04:15<01:09, 178.40it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45504/57920 [04:15<01:09, 178.38it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45522/57920 [04:15<01:09, 178.38it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45540/57920 [04:15<01:09, 178.40it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45558/57920 [04:15<01:09, 178.41it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45576/57920 [04:15<01:09, 178.43it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 45594/57920 [04:15<01:09, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45612/57920 [04:16<01:08, 178.45it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45630/57920 [04:16<01:08, 178.45it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45648/57920 [04:16<01:08, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45666/57920 [04:16<01:08, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45684/57920 [04:16<01:08, 178.45it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45702/57920 [04:16<01:08, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45720/57920 [04:16<01:08, 178.45it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45738/57920 [04:16<01:08, 178.46it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45756/57920 [04:16<01:08, 178.45it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45774/57920 [04:16<01:08, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45792/57920 [04:17<01:07, 178.43it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45810/57920 [04:17<01:07, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45828/57920 [04:17<01:07, 178.43it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45846/57920 [04:17<01:07, 178.42it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45864/57920 [04:17<01:07, 178.41it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45882/57920 [04:17<01:07, 178.42it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45900/57920 [04:17<01:07, 178.43it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45918/57920 [04:17<01:07, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45936/57920 [04:17<01:07, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45954/57920 [04:17<01:07, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45972/57920 [04:18<01:06, 178.44it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 45990/57920 [04:18<01:06, 178.43it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46008/57920 [04:18<01:06, 178.41it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46026/57920 [04:18<01:06, 178.42it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46044/57920 [04:18<01:06, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46062/57920 [04:18<01:06, 178.44it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46080/57920 [04:18<01:06, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46098/57920 [04:18<01:06, 178.44it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46116/57920 [04:18<01:06, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46134/57920 [04:18<01:06, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46152/57920 [04:19<01:05, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46170/57920 [04:19<01:05, 178.45it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46188/57920 [04:19<01:05, 178.45it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46206/57920 [04:19<01:05, 178.45it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46224/57920 [04:19<01:05, 178.44it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46242/57920 [04:19<01:05, 178.44it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46260/57920 [04:19<01:05, 178.45it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46278/57920 [04:19<01:05, 178.44it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46296/57920 [04:19<01:05, 177.60it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46314/57920 [04:19<01:05, 177.83it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 46332/57920 [04:20<01:05, 178.01it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46350/57920 [04:20<01:04, 178.12it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46368/57920 [04:20<01:04, 178.22it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46386/57920 [04:20<01:04, 178.26it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46404/57920 [04:20<01:04, 178.30it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46422/57920 [04:20<01:04, 178.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46440/57920 [04:20<01:04, 178.39it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46458/57920 [04:20<01:04, 178.41it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46476/57920 [04:20<01:04, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46494/57920 [04:20<01:04, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46512/57920 [04:21<01:03, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46530/57920 [04:21<01:03, 178.44it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46548/57920 [04:21<01:03, 178.44it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46566/57920 [04:21<01:03, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46584/57920 [04:21<01:03, 178.41it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46602/57920 [04:21<01:03, 178.43it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46620/57920 [04:21<01:03, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46638/57920 [04:21<01:03, 178.43it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46656/57920 [04:21<01:03, 178.43it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46674/57920 [04:21<01:03, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46692/57920 [04:22<01:02, 178.46it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46710/57920 [04:22<01:02, 178.46it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46728/57920 [04:22<01:02, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46746/57920 [04:22<01:02, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46764/57920 [04:22<01:02, 178.46it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46782/57920 [04:22<01:02, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46800/57920 [04:22<01:02, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46818/57920 [04:22<01:02, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46836/57920 [04:22<01:02, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46854/57920 [04:22<01:02, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46872/57920 [04:23<01:01, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46890/57920 [04:23<01:01, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46908/57920 [04:23<01:01, 178.43it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46926/57920 [04:23<01:01, 178.43it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46944/57920 [04:23<01:01, 178.43it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46962/57920 [04:23<01:01, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46980/57920 [04:23<01:01, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 46998/57920 [04:23<01:01, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 47016/57920 [04:23<01:01, 178.43it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 47034/57920 [04:23<01:01, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 47052/57920 [04:24<01:00, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47070/57920 [04:24<01:00, 178.44it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47088/57920 [04:24<01:00, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47106/57920 [04:24<01:00, 178.45it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47124/57920 [04:24<01:00, 178.42it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47142/57920 [04:24<01:00, 178.39it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47160/57920 [04:24<01:00, 178.40it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47178/57920 [04:24<01:00, 178.41it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47196/57920 [04:24<01:00, 178.43it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47214/57920 [04:24<00:59, 178.43it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47232/57920 [04:25<00:59, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47250/57920 [04:25<00:59, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47268/57920 [04:25<00:59, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47286/57920 [04:25<00:59, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47304/57920 [04:25<00:59, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47322/57920 [04:25<00:59, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47340/57920 [04:25<00:59, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47358/57920 [04:25<00:59, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47376/57920 [04:25<00:59, 178.43it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47394/57920 [04:25<00:58, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47412/57920 [04:26<00:58, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47430/57920 [04:26<00:58, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47448/57920 [04:26<00:58, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47466/57920 [04:26<00:58, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47484/57920 [04:26<00:58, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47502/57920 [04:26<00:58, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47520/57920 [04:26<00:58, 178.41it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47538/57920 [04:26<00:58, 178.42it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47556/57920 [04:26<00:58, 178.42it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47574/57920 [04:26<00:57, 178.43it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47592/57920 [04:27<00:57, 178.43it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47610/57920 [04:27<00:57, 178.42it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47628/57920 [04:27<00:57, 178.40it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47646/57920 [04:27<00:57, 178.40it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47664/57920 [04:27<00:57, 178.41it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47682/57920 [04:27<00:57, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47700/57920 [04:27<00:57, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47718/57920 [04:27<00:57, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47736/57920 [04:27<00:57, 178.45it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47754/57920 [04:28<00:56, 178.44it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47772/57920 [04:28<00:56, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47790/57920 [04:28<00:56, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47808/57920 [04:28<00:56, 178.47it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47826/57920 [04:28<00:56, 178.46it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47844/57920 [04:28<00:56, 178.46it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47862/57920 [04:28<00:56, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47880/57920 [04:28<00:56, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47898/57920 [04:28<00:56, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47916/57920 [04:28<00:56, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47934/57920 [04:29<00:56, 178.24it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47952/57920 [04:29<00:55, 178.25it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47970/57920 [04:29<00:55, 178.31it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 47988/57920 [04:29<00:55, 178.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48006/57920 [04:29<00:55, 178.39it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48024/57920 [04:29<00:55, 178.41it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48042/57920 [04:29<00:55, 178.42it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48060/57920 [04:29<00:55, 178.43it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48078/57920 [04:29<00:55, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48096/57920 [04:29<00:55, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48114/57920 [04:30<00:54, 178.46it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48132/57920 [04:30<00:54, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48150/57920 [04:30<00:54, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48168/57920 [04:30<00:54, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48186/57920 [04:30<00:54, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48204/57920 [04:30<00:54, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48222/57920 [04:30<00:54, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48240/57920 [04:30<00:54, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48258/57920 [04:30<00:54, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48276/57920 [04:30<00:54, 178.46it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48294/57920 [04:31<00:53, 178.46it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48312/57920 [04:31<00:53, 178.44it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48330/57920 [04:31<00:53, 178.45it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48348/57920 [04:31<00:53, 178.47it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48366/57920 [04:31<00:53, 178.47it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48384/57920 [04:31<00:53, 178.47it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48402/57920 [04:31<00:53, 178.46it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48420/57920 [04:31<00:53, 178.44it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48438/57920 [04:31<00:53, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48456/57920 [04:31<00:53, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48474/57920 [04:32<00:52, 178.45it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 48492/57920 [04:32<00:52, 178.45it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48510/57920 [04:32<00:52, 178.44it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48528/57920 [04:32<00:52, 178.44it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48546/57920 [04:32<00:52, 178.46it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48564/57920 [04:32<00:52, 178.45it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48582/57920 [04:32<00:52, 178.45it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48600/57920 [04:32<00:52, 178.46it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48618/57920 [04:32<00:52, 178.45it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48636/57920 [04:32<00:52, 178.44it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48654/57920 [04:33<00:51, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48672/57920 [04:33<00:51, 178.42it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48690/57920 [04:33<00:51, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48708/57920 [04:33<00:51, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48726/57920 [04:33<00:51, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48744/57920 [04:33<00:51, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48762/57920 [04:33<00:51, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48780/57920 [04:33<00:51, 178.44it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48798/57920 [04:33<00:51, 178.43it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48816/57920 [04:33<00:51, 178.45it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48834/57920 [04:34<00:50, 178.44it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48852/57920 [04:34<00:50, 178.46it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48870/57920 [04:34<00:50, 178.47it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48888/57920 [04:34<00:50, 178.45it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48906/57920 [04:34<00:50, 178.46it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48924/57920 [04:34<00:50, 178.46it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48942/57920 [04:34<00:50, 178.46it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48960/57920 [04:34<00:50, 178.46it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48978/57920 [04:34<00:50, 178.47it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 48996/57920 [04:34<00:50, 178.46it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49014/57920 [04:35<00:49, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49032/57920 [04:35<00:49, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49050/57920 [04:35<00:49, 178.43it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49068/57920 [04:35<00:49, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49086/57920 [04:35<00:49, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49104/57920 [04:35<00:49, 178.43it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49122/57920 [04:35<00:49, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49140/57920 [04:35<00:49, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49158/57920 [04:35<00:49, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49176/57920 [04:35<00:49, 178.43it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49194/57920 [04:36<00:48, 178.43it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49212/57920 [04:36<00:48, 178.43it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49230/57920 [04:36<00:48, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49248/57920 [04:36<00:48, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49266/57920 [04:36<00:48, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49284/57920 [04:36<00:48, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49302/57920 [04:36<00:48, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49320/57920 [04:36<00:48, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49338/57920 [04:36<00:48, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49356/57920 [04:36<00:47, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49374/57920 [04:37<00:47, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49392/57920 [04:37<00:47, 178.45it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49410/57920 [04:37<00:47, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49428/57920 [04:37<00:47, 178.43it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49446/57920 [04:37<00:47, 178.41it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49464/57920 [04:37<00:47, 178.42it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49482/57920 [04:37<00:47, 178.44it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49500/57920 [04:37<00:47, 178.43it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49518/57920 [04:37<00:47, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49536/57920 [04:37<00:46, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49554/57920 [04:38<00:46, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49572/57920 [04:38<00:46, 178.42it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49590/57920 [04:38<00:46, 178.43it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49608/57920 [04:38<00:46, 178.42it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49626/57920 [04:38<00:46, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49644/57920 [04:38<00:46, 178.43it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49662/57920 [04:38<00:46, 178.42it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49680/57920 [04:38<00:46, 178.42it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49698/57920 [04:38<00:46, 178.43it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49716/57920 [04:39<00:45, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49734/57920 [04:39<00:45, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49752/57920 [04:39<00:45, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49770/57920 [04:39<00:45, 178.45it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49788/57920 [04:39<00:45, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49806/57920 [04:39<00:45, 178.45it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49824/57920 [04:39<00:45, 178.45it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49842/57920 [04:39<00:45, 178.47it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49860/57920 [04:39<00:45, 178.46it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49878/57920 [04:39<00:45, 178.47it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49896/57920 [04:40<00:44, 178.46it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49914/57920 [04:40<00:44, 178.46it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49932/57920 [04:40<00:44, 178.46it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 49950/57920 [04:40<00:44, 178.46it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 49968/57920 [04:40<00:44, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 49986/57920 [04:40<00:44, 178.43it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50004/57920 [04:40<00:44, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50022/57920 [04:40<00:44, 178.45it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50040/57920 [04:40<00:44, 178.45it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50058/57920 [04:40<00:44, 178.45it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50076/57920 [04:41<00:43, 178.44it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50094/57920 [04:41<00:43, 178.45it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50112/57920 [04:41<00:43, 178.45it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50130/57920 [04:41<00:43, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50148/57920 [04:41<00:43, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50166/57920 [04:41<00:43, 178.45it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50184/57920 [04:41<00:43, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50202/57920 [04:41<00:43, 178.42it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50220/57920 [04:41<00:43, 178.42it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50238/57920 [04:41<00:43, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50256/57920 [04:42<00:42, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50274/57920 [04:42<00:42, 178.42it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50292/57920 [04:42<00:42, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50310/57920 [04:42<00:42, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50328/57920 [04:42<00:42, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50346/57920 [04:42<00:42, 178.45it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50364/57920 [04:42<00:42, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50382/57920 [04:42<00:42, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50400/57920 [04:42<00:42, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50418/57920 [04:42<00:42, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50436/57920 [04:43<00:41, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50454/57920 [04:43<00:41, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50472/57920 [04:43<00:41, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50490/57920 [04:43<00:41, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50508/57920 [04:43<00:41, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50526/57920 [04:43<00:41, 178.42it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50544/57920 [04:43<00:41, 178.42it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50562/57920 [04:43<00:41, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50580/57920 [04:43<00:41, 178.43it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50598/57920 [04:43<00:41, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50616/57920 [04:44<00:40, 178.44it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50634/57920 [04:44<00:40, 178.45it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50652/57920 [04:44<00:40, 178.45it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 50670/57920 [04:44<00:40, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50688/57920 [04:44<00:40, 178.46it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50706/57920 [04:44<00:40, 178.46it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50724/57920 [04:44<00:40, 178.46it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50742/57920 [04:44<00:40, 178.47it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50760/57920 [04:44<00:40, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50778/57920 [04:44<00:40, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50796/57920 [04:45<00:39, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50814/57920 [04:45<00:39, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50832/57920 [04:45<00:39, 178.43it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50850/57920 [04:45<00:39, 178.42it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50868/57920 [04:45<00:39, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50886/57920 [04:45<00:39, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50904/57920 [04:45<00:39, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50922/57920 [04:45<00:39, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50940/57920 [04:45<00:39, 178.41it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50958/57920 [04:45<00:39, 178.43it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50976/57920 [04:46<00:38, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50994/57920 [04:46<00:38, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51012/57920 [04:46<00:38, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51030/57920 [04:46<00:38, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51048/57920 [04:46<00:38, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51066/57920 [04:46<00:38, 178.43it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51084/57920 [04:46<00:38, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51102/57920 [04:46<00:38, 178.43it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51120/57920 [04:46<00:38, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51138/57920 [04:46<00:38, 178.42it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51156/57920 [04:47<00:37, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51174/57920 [04:47<00:37, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51192/57920 [04:47<00:37, 178.45it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51210/57920 [04:47<00:37, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51228/57920 [04:47<00:37, 178.44it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51246/57920 [04:47<00:37, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51264/57920 [04:47<00:37, 178.46it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51282/57920 [04:47<00:37, 178.46it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51300/57920 [04:47<00:37, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51318/57920 [04:47<00:36, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51336/57920 [04:48<00:36, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51354/57920 [04:48<00:36, 178.43it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51372/57920 [04:48<00:36, 178.43it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 51390/57920 [04:48<00:36, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51408/57920 [04:48<00:36, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51426/57920 [04:48<00:36, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51444/57920 [04:48<00:36, 178.46it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51462/57920 [04:48<00:36, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51480/57920 [04:48<00:36, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51498/57920 [04:48<00:35, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51516/57920 [04:49<00:35, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51534/57920 [04:49<00:35, 178.42it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51552/57920 [04:49<00:35, 178.42it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51570/57920 [04:49<00:35, 178.42it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51588/57920 [04:49<00:35, 178.43it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51606/57920 [04:49<00:35, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51624/57920 [04:49<00:35, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51642/57920 [04:49<00:35, 178.45it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51660/57920 [04:49<00:35, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51678/57920 [04:49<00:34, 178.43it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51696/57920 [04:50<00:34, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51714/57920 [04:50<00:34, 178.43it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51732/57920 [04:50<00:34, 178.42it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51750/57920 [04:50<00:34, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51768/57920 [04:50<00:34, 178.44it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51786/57920 [04:50<00:34, 178.43it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51804/57920 [04:50<00:34, 178.43it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51822/57920 [04:50<00:34, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51840/57920 [04:50<00:34, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51858/57920 [04:51<00:33, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51876/57920 [04:51<00:33, 178.45it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51894/57920 [04:51<00:33, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51912/57920 [04:51<00:33, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51930/57920 [04:51<00:33, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51948/57920 [04:51<00:33, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51966/57920 [04:51<00:33, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 51984/57920 [04:51<00:33, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 52002/57920 [04:51<00:33, 178.43it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 52020/57920 [04:51<00:33, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 52038/57920 [04:52<00:32, 178.45it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 52056/57920 [04:52<00:32, 178.47it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 52074/57920 [04:52<00:32, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 52092/57920 [04:52<00:32, 178.45it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 52110/57920 [04:52<00:32, 178.42it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52128/57920 [04:52<00:32, 178.42it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52146/57920 [04:52<00:32, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52164/57920 [04:52<00:32, 178.45it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52182/57920 [04:52<00:32, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52200/57920 [04:52<00:32, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52218/57920 [04:53<00:31, 178.47it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52236/57920 [04:53<00:31, 178.45it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52254/57920 [04:53<00:31, 178.45it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52272/57920 [04:53<00:31, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52290/57920 [04:53<00:31, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52308/57920 [04:53<00:31, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52326/57920 [04:53<00:31, 178.45it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52344/57920 [04:53<00:31, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52362/57920 [04:53<00:31, 178.44it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52380/57920 [04:53<00:31, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52398/57920 [04:54<00:30, 178.46it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52416/57920 [04:54<00:30, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52434/57920 [04:54<00:30, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52452/57920 [04:54<00:30, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52470/57920 [04:54<00:30, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52488/57920 [04:54<00:30, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52506/57920 [04:54<00:30, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52524/57920 [04:54<00:30, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52542/57920 [04:54<00:30, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52560/57920 [04:54<00:30, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52578/57920 [04:55<00:29, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52596/57920 [04:55<00:29, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52614/57920 [04:55<00:29, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52632/57920 [04:55<00:29, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52650/57920 [04:55<00:29, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52668/57920 [04:55<00:29, 178.45it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52686/57920 [04:55<00:29, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52704/57920 [04:55<00:29, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52722/57920 [04:55<00:29, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52740/57920 [04:55<00:29, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52758/57920 [04:56<00:28, 178.45it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52776/57920 [04:56<00:28, 178.45it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52794/57920 [04:56<00:28, 178.45it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52812/57920 [04:56<00:28, 178.46it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52830/57920 [04:56<00:28, 178.47it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 52848/57920 [04:56<00:28, 178.47it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52866/57920 [04:56<00:28, 178.47it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52884/57920 [04:56<00:28, 178.46it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52902/57920 [04:56<00:28, 178.46it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52920/57920 [04:56<00:28, 178.46it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52938/57920 [04:57<00:27, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52956/57920 [04:57<00:27, 178.43it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52974/57920 [04:57<00:27, 178.44it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52992/57920 [04:57<00:27, 178.44it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53010/57920 [04:57<00:27, 178.44it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53028/57920 [04:57<00:27, 178.45it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53046/57920 [04:57<00:27, 178.45it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53064/57920 [04:57<00:27, 178.46it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53082/57920 [04:57<00:27, 178.46it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53100/57920 [04:57<00:27, 178.46it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53118/57920 [04:58<00:26, 178.46it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53136/57920 [04:58<00:26, 178.45it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53154/57920 [04:58<00:26, 178.44it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53172/57920 [04:58<00:26, 178.41it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53190/57920 [04:58<00:26, 178.41it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53208/57920 [04:58<00:26, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53226/57920 [04:58<00:26, 178.44it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53244/57920 [04:58<00:26, 178.44it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53262/57920 [04:58<00:26, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53280/57920 [04:58<00:26, 178.42it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53298/57920 [04:59<00:25, 178.40it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53316/57920 [04:59<00:25, 178.42it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53334/57920 [04:59<00:25, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53352/57920 [04:59<00:25, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53370/57920 [04:59<00:25, 178.44it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53388/57920 [04:59<00:25, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53406/57920 [04:59<00:25, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53424/57920 [04:59<00:25, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53442/57920 [04:59<00:25, 178.42it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53460/57920 [04:59<00:24, 178.43it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53478/57920 [05:00<00:24, 178.45it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53496/57920 [05:00<00:24, 178.45it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53514/57920 [05:00<00:24, 178.45it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53532/57920 [05:00<00:24, 178.45it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53550/57920 [05:00<00:24, 178.46it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53568/57920 [05:00<00:24, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53586/57920 [05:00<00:24, 178.43it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53604/57920 [05:00<00:24, 178.43it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53622/57920 [05:00<00:24, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53640/57920 [05:00<00:23, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53658/57920 [05:01<00:23, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53676/57920 [05:01<00:23, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53694/57920 [05:01<00:23, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53712/57920 [05:01<00:23, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53730/57920 [05:01<00:23, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53748/57920 [05:01<00:23, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53766/57920 [05:01<00:23, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53784/57920 [05:01<00:23, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53802/57920 [05:01<00:23, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53820/57920 [05:02<00:22, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53838/57920 [05:02<00:22, 178.43it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53856/57920 [05:02<00:22, 178.43it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53874/57920 [05:02<00:22, 178.42it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53892/57920 [05:02<00:22, 178.43it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53910/57920 [05:02<00:22, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53928/57920 [05:02<00:22, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53946/57920 [05:02<00:22, 178.46it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53964/57920 [05:02<00:22, 178.46it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 53982/57920 [05:02<00:22, 178.46it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54000/57920 [05:03<00:21, 178.47it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54018/57920 [05:03<00:21, 178.47it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54036/57920 [05:03<00:21, 178.46it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54054/57920 [05:03<00:21, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54072/57920 [05:03<00:21, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54090/57920 [05:03<00:21, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54108/57920 [05:03<00:21, 178.45it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54126/57920 [05:03<00:21, 178.44it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54144/57920 [05:03<00:21, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54162/57920 [05:03<00:21, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54180/57920 [05:04<00:20, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54198/57920 [05:04<00:20, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54216/57920 [05:04<00:20, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54234/57920 [05:04<00:20, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54252/57920 [05:04<00:20, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54270/57920 [05:04<00:20, 178.47it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 54288/57920 [05:04<00:20, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54306/57920 [05:04<00:20, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54324/57920 [05:04<00:20, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54342/57920 [05:04<00:20, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54360/57920 [05:05<00:19, 178.43it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54378/57920 [05:05<00:19, 178.42it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54396/57920 [05:05<00:19, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54414/57920 [05:05<00:19, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54432/57920 [05:05<00:19, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54450/57920 [05:05<00:19, 178.46it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54468/57920 [05:05<00:19, 178.47it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54486/57920 [05:05<00:19, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54504/57920 [05:05<00:19, 178.42it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54522/57920 [05:05<00:19, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54540/57920 [05:06<00:18, 178.43it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54558/57920 [05:06<00:18, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54576/57920 [05:06<00:18, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54594/57920 [05:06<00:18, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54612/57920 [05:06<00:18, 178.46it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54630/57920 [05:06<00:18, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54648/57920 [05:06<00:18, 178.46it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54666/57920 [05:06<00:18, 178.47it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54684/57920 [05:06<00:18, 178.45it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54702/57920 [05:06<00:18, 178.44it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54720/57920 [05:07<00:17, 178.43it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54738/57920 [05:07<00:17, 178.44it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54756/57920 [05:07<00:17, 178.44it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54774/57920 [05:07<00:17, 178.44it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54792/57920 [05:07<00:17, 178.44it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54810/57920 [05:07<00:17, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54828/57920 [05:07<00:17, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54846/57920 [05:07<00:17, 178.46it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54864/57920 [05:07<00:17, 178.46it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54882/57920 [05:07<00:17, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54900/57920 [05:08<00:16, 178.46it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54918/57920 [05:08<00:16, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54936/57920 [05:08<00:16, 178.46it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54954/57920 [05:08<00:16, 178.47it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54972/57920 [05:08<00:16, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 54990/57920 [05:08<00:16, 178.43it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 55008/57920 [05:08<00:16, 178.44it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55026/57920 [05:08<00:16, 178.43it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55044/57920 [05:08<00:16, 178.44it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55062/57920 [05:08<00:16, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55080/57920 [05:09<00:15, 178.46it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55098/57920 [05:09<00:15, 178.47it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55116/57920 [05:09<00:15, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55134/57920 [05:09<00:15, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55152/57920 [05:09<00:15, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55170/57920 [05:09<00:15, 178.46it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55188/57920 [05:09<00:15, 178.47it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55206/57920 [05:09<00:15, 178.46it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55224/57920 [05:09<00:15, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55242/57920 [05:09<00:15, 178.44it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55260/57920 [05:10<00:14, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55278/57920 [05:10<00:14, 178.45it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55296/57920 [05:10<00:14, 178.47it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55314/57920 [05:10<00:14, 178.46it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55332/57920 [05:10<00:14, 178.43it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55350/57920 [05:10<00:14, 178.44it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55368/57920 [05:10<00:14, 178.44it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55386/57920 [05:10<00:14, 178.43it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55404/57920 [05:10<00:14, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55422/57920 [05:10<00:13, 178.46it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55440/57920 [05:11<00:13, 178.46it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55458/57920 [05:11<00:13, 178.46it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55476/57920 [05:11<00:13, 176.88it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55494/57920 [05:11<00:13, 177.31it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55512/57920 [05:11<00:13, 177.63it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55530/57920 [05:11<00:13, 177.87it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55548/57920 [05:11<00:13, 178.05it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55566/57920 [05:11<00:13, 178.17it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55584/57920 [05:11<00:13, 178.24it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55602/57920 [05:11<00:13, 178.30it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55620/57920 [05:12<00:12, 178.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55638/57920 [05:12<00:12, 178.39it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55656/57920 [05:12<00:12, 178.41it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55674/57920 [05:12<00:12, 178.42it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55692/57920 [05:12<00:12, 178.44it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55710/57920 [05:12<00:12, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55728/57920 [05:12<00:12, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 55746/57920 [05:12<00:12, 178.44it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55764/57920 [05:12<00:12, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55782/57920 [05:12<00:11, 178.43it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55800/57920 [05:13<00:11, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55818/57920 [05:13<00:11, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55836/57920 [05:13<00:11, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55854/57920 [05:13<00:11, 178.46it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55872/57920 [05:13<00:11, 178.45it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55890/57920 [05:13<00:11, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55908/57920 [05:13<00:11, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55926/57920 [05:13<00:11, 178.46it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55944/57920 [05:13<00:11, 178.46it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55962/57920 [05:14<00:10, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55980/57920 [05:14<00:10, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 55998/57920 [05:14<00:10, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56016/57920 [05:14<00:10, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56034/57920 [05:14<00:10, 178.46it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56052/57920 [05:14<00:10, 178.47it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56070/57920 [05:14<00:10, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56088/57920 [05:14<00:10, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56106/57920 [05:14<00:10, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56124/57920 [05:14<00:10, 178.43it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56142/57920 [05:15<00:09, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56160/57920 [05:15<00:09, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56178/57920 [05:15<00:09, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56196/57920 [05:15<00:09, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56214/57920 [05:15<00:09, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56232/57920 [05:15<00:09, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56250/57920 [05:15<00:09, 178.46it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56268/57920 [05:15<00:09, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56286/57920 [05:15<00:09, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56304/57920 [05:15<00:09, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56322/57920 [05:16<00:08, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56340/57920 [05:16<00:08, 178.45it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56358/57920 [05:16<00:08, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56376/57920 [05:16<00:08, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56394/57920 [05:16<00:08, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56412/57920 [05:16<00:08, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56430/57920 [05:16<00:08, 178.44it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56448/57920 [05:16<00:08, 178.03it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 56466/57920 [05:16<00:08, 178.11it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56484/57920 [05:16<00:08, 178.20it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56502/57920 [05:17<00:07, 178.27it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56520/57920 [05:17<00:07, 178.31it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56538/57920 [05:17<00:07, 178.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56556/57920 [05:17<00:07, 178.37it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56574/57920 [05:17<00:07, 178.39it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56592/57920 [05:17<00:07, 178.40it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56610/57920 [05:17<00:07, 178.42it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56628/57920 [05:17<00:07, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56646/57920 [05:17<00:07, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56664/57920 [05:17<00:07, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56682/57920 [05:18<00:06, 178.45it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56700/57920 [05:18<00:06, 178.45it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56718/57920 [05:18<00:06, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56736/57920 [05:18<00:06, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56754/57920 [05:18<00:06, 178.42it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56772/57920 [05:18<00:06, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56790/57920 [05:18<00:06, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56808/57920 [05:18<00:06, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56826/57920 [05:18<00:06, 178.45it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56844/57920 [05:18<00:06, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56862/57920 [05:19<00:05, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56880/57920 [05:19<00:05, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56898/57920 [05:19<00:05, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56916/57920 [05:19<00:05, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56934/57920 [05:19<00:05, 178.42it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56952/57920 [05:19<00:05, 178.43it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56970/57920 [05:19<00:05, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 56988/57920 [05:19<00:05, 178.44it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57006/57920 [05:19<00:05, 178.46it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57024/57920 [05:19<00:05, 178.46it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57042/57920 [05:20<00:04, 178.46it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57060/57920 [05:20<00:04, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57078/57920 [05:20<00:04, 178.46it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57096/57920 [05:20<00:04, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57114/57920 [05:20<00:04, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57132/57920 [05:20<00:04, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57150/57920 [05:20<00:04, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57168/57920 [05:20<00:04, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 57186/57920 [05:20<00:04, 178.44it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57204/57920 [05:20<00:04, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57222/57920 [05:21<00:03, 178.44it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57240/57920 [05:21<00:03, 178.44it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57258/57920 [05:21<00:03, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57276/57920 [05:21<00:03, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57294/57920 [05:21<00:03, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57312/57920 [05:21<00:03, 178.41it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57330/57920 [05:21<00:03, 178.42it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57348/57920 [05:21<00:03, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57366/57920 [05:21<00:03, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57384/57920 [05:21<00:03, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57402/57920 [05:22<00:02, 178.47it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57420/57920 [05:22<00:02, 178.46it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57438/57920 [05:22<00:02, 178.42it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57456/57920 [05:22<00:02, 178.40it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57474/57920 [05:22<00:02, 178.41it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57492/57920 [05:22<00:02, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57510/57920 [05:22<00:02, 178.43it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57528/57920 [05:22<00:02, 178.44it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57546/57920 [05:22<00:02, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57564/57920 [05:22<00:01, 178.46it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57582/57920 [05:23<00:01, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57600/57920 [05:23<00:01, 178.45it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57618/57920 [05:23<00:01, 178.44it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57636/57920 [05:23<00:01, 178.45it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57654/57920 [05:23<00:01, 178.45it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57672/57920 [05:23<00:01, 178.46it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57690/57920 [05:23<00:01, 178.45it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57708/57920 [05:23<00:01, 178.46it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57726/57920 [05:23<00:01, 178.46it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57744/57920 [05:23<00:00, 178.45it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57762/57920 [05:24<00:00, 178.45it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57780/57920 [05:24<00:00, 178.45it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57798/57920 [05:24<00:00, 178.44it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57816/57920 [05:24<00:00, 178.43it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57834/57920 [05:24<00:00, 178.43it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57852/57920 [05:24<00:00, 178.43it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57870/57920 [05:24<00:00, 178.43it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57888/57920 [05:24<00:00, 178.42it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 57906/57920 [05:24<00:00, 178.42it/s][A[ASelecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57920/57920 [05:24<00:00, 178.23it/s]

Validation:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   4%|â–         | 1/26 [00:00<00:07,  3.25it/s][A
Validation DataLoader 0:   8%|â–Š         | 2/26 [00:00<00:04,  5.64it/s][A
Validation DataLoader 0:  12%|â–ˆâ–        | 3/26 [00:00<00:03,  7.51it/s][A
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 4/26 [00:00<00:04,  5.39it/s][A
Validation DataLoader 0:  19%|â–ˆâ–‰        | 5/26 [00:01<00:04,  4.64it/s][A
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 6/26 [00:01<00:04,  4.25it/s][A
Validation DataLoader 0:  27%|â–ˆâ–ˆâ–‹       | 7/26 [00:01<00:04,  4.00it/s][A
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 8/26 [00:02<00:04,  3.83it/s][A
Validation DataLoader 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 9/26 [00:02<00:04,  3.70it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 10/26 [00:02<00:04,  3.62it/s][A
Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/26 [00:03<00:04,  3.53it/s][A
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/26 [00:03<00:04,  3.47it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 13/26 [00:03<00:03,  3.49it/s][A
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/26 [00:03<00:03,  3.58it/s][A
Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 15/26 [00:04<00:03,  3.66it/s][A
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/26 [00:04<00:02,  3.73it/s][A
Validation DataLoader 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 17/26 [00:04<00:02,  3.80it/s][A
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 18/26 [00:04<00:02,  3.87it/s][A
Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 19/26 [00:04<00:01,  3.92it/s][A
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 20/26 [00:05<00:01,  3.98it/s][A
Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 21/26 [00:05<00:01,  4.03it/s][A
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/26 [00:05<00:00,  4.07it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 23/26 [00:05<00:00,  4.12it/s][A
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 24/26 [00:05<00:00,  4.16it/s][A
Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 25/26 [00:05<00:00,  4.19it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:06<00:00,  3.94it/s][Aâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:161 in <module>    â”‚
â”‚                                                                              â”‚
â”‚   158 â”‚   â”‚   print("Image AUROC: {}, Pixel AUPRO: {}".format(image_AUROC, p â”‚
â”‚   159                                                                        â”‚
â”‚   160 if __name__ == '__main__':                                             â”‚
â”‚ â± 161 â”‚   main()                                                             â”‚
â”‚   162 â”‚   torch.cuda.empty_cache()                                           â”‚
â”‚   163                                                                        â”‚
â”‚   164                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:137 in main        â”‚
â”‚                                                                              â”‚
â”‚   134 â”‚                                                                      â”‚
â”‚   135 â”‚   # start training                                                   â”‚
â”‚   136 â”‚   engine = Engine(accelerator=args.gpu_type,task=TaskType.SEGMENTATI â”‚
â”‚ â± 137 â”‚   engine.fit(model=model, datamodule=datamodule)                     â”‚
â”‚   138 â”‚                                                                      â”‚
â”‚   139 â”‚   # load best model from checkpoint before evaluating                â”‚
â”‚   140 â”‚   test_results = engine.test(                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/engine/engine.p â”‚
â”‚ y:549 in fit                                                                 â”‚
â”‚                                                                              â”‚
â”‚    546 â”‚   â”‚   â”‚   # if the model is zero-shot or few-shot, we only need to  â”‚
â”‚    547 â”‚   â”‚   â”‚   self.trainer.validate(model, val_dataloaders, datamodule= â”‚
â”‚    548 â”‚   â”‚   else:                                                         â”‚
â”‚ â±  549 â”‚   â”‚   â”‚   self.trainer.fit(model, train_dataloaders, val_dataloader â”‚
â”‚    550 â”‚                                                                     â”‚
â”‚    551 â”‚   def validate(                                                     â”‚
â”‚    552 â”‚   â”‚   self,                                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:538 in fit              â”‚
â”‚                                                                              â”‚
â”‚    535 â”‚   â”‚   self.state.fn = TrainerFn.FITTING                             â”‚
â”‚    536 â”‚   â”‚   self.state.status = TrainerStatus.RUNNING                     â”‚
â”‚    537 â”‚   â”‚   self.training = True                                          â”‚
â”‚ â±  538 â”‚   â”‚   call._call_and_handle_interrupt(                              â”‚
â”‚    539 â”‚   â”‚   â”‚   self, self._fit_impl, model, train_dataloaders, val_datal â”‚
â”‚    540 â”‚   â”‚   )                                                             â”‚
â”‚    541                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/call.py:47 in                      â”‚
â”‚ _call_and_handle_interrupt                                                   â”‚
â”‚                                                                              â”‚
â”‚    44 â”‚   try:                                                               â”‚
â”‚    45 â”‚   â”‚   if trainer.strategy.launcher is not None:                      â”‚
â”‚    46 â”‚   â”‚   â”‚   return trainer.strategy.launcher.launch(trainer_fn, *args, â”‚
â”‚ â±  47 â”‚   â”‚   return trainer_fn(*args, **kwargs)                             â”‚
â”‚    48 â”‚                                                                      â”‚
â”‚    49 â”‚   except _TunerExitException:                                        â”‚
â”‚    50 â”‚   â”‚   _call_teardown_hook(trainer)                                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:574 in _fit_impl        â”‚
â”‚                                                                              â”‚
â”‚    571 â”‚   â”‚   â”‚   model_provided=True,                                      â”‚
â”‚    572 â”‚   â”‚   â”‚   model_connected=self.lightning_module is not None,        â”‚
â”‚    573 â”‚   â”‚   )                                                             â”‚
â”‚ â±  574 â”‚   â”‚   self._run(model, ckpt_path=ckpt_path)                         â”‚
â”‚    575 â”‚   â”‚                                                                 â”‚
â”‚    576 â”‚   â”‚   assert self.state.stopped                                     â”‚
â”‚    577 â”‚   â”‚   self.training = False                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:981 in _run             â”‚
â”‚                                                                              â”‚
â”‚    978 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    979 â”‚   â”‚   # RUN THE TRAINER                                             â”‚
â”‚    980 â”‚   â”‚   # ----------------------------                                â”‚
â”‚ â±  981 â”‚   â”‚   results = self._run_stage()                                   â”‚
â”‚    982 â”‚   â”‚                                                                 â”‚
â”‚    983 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    984 â”‚   â”‚   # POST-Training CLEAN UP                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:1025 in _run_stage      â”‚
â”‚                                                                              â”‚
â”‚   1022 â”‚   â”‚   â”‚   with isolate_rng():                                       â”‚
â”‚   1023 â”‚   â”‚   â”‚   â”‚   self._run_sanity_check()                              â”‚
â”‚   1024 â”‚   â”‚   â”‚   with torch.autograd.set_detect_anomaly(self._detect_anoma â”‚
â”‚ â± 1025 â”‚   â”‚   â”‚   â”‚   self.fit_loop.run()                                   â”‚
â”‚   1026 â”‚   â”‚   â”‚   return None                                               â”‚
â”‚   1027 â”‚   â”‚   raise RuntimeError(f"Unexpected state {self.state}")          â”‚
â”‚   1028                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:205 in run               â”‚
â”‚                                                                              â”‚
â”‚   202 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   203 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   204 â”‚   â”‚   â”‚   â”‚   self.on_advance_start()                                â”‚
â”‚ â± 205 â”‚   â”‚   â”‚   â”‚   self.advance()                                         â”‚
â”‚   206 â”‚   â”‚   â”‚   â”‚   self.on_advance_end()                                  â”‚
â”‚   207 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   208 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:363 in advance           â”‚
â”‚                                                                              â”‚
â”‚   360 â”‚   â”‚   â”‚   )                                                          â”‚
â”‚   361 â”‚   â”‚   with self.trainer.profiler.profile("run_training_epoch"):      â”‚
â”‚   362 â”‚   â”‚   â”‚   assert self._data_fetcher is not None                      â”‚
â”‚ â± 363 â”‚   â”‚   â”‚   self.epoch_loop.run(self._data_fetcher)                    â”‚
â”‚   364 â”‚                                                                      â”‚
â”‚   365 â”‚   def on_advance_end(self) -> None:                                  â”‚
â”‚   366 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:141 in run    â”‚
â”‚                                                                              â”‚
â”‚   138 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   139 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self.advance(data_fetcher)                             â”‚
â”‚ â± 141 â”‚   â”‚   â”‚   â”‚   self.on_advance_end(data_fetcher)                      â”‚
â”‚   142 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   143 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚   144 â”‚   â”‚   â”‚   â”‚   break                                                  â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:295 in        â”‚
â”‚ on_advance_end                                                               â”‚
â”‚                                                                              â”‚
â”‚   292 â”‚   â”‚   â”‚   â”‚   # clear gradients to not leave any unused memory durin â”‚
â”‚   293 â”‚   â”‚   â”‚   â”‚   call._call_lightning_module_hook(self.trainer, "on_val â”‚
â”‚   294 â”‚   â”‚   â”‚                                                              â”‚
â”‚ â± 295 â”‚   â”‚   â”‚   self.val_loop.run()                                        â”‚
â”‚   296 â”‚   â”‚   â”‚   self.trainer.training = True                               â”‚
â”‚   297 â”‚   â”‚   â”‚   self.trainer._logger_connector._first_loop_iter = first_lo â”‚
â”‚   298                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/utilities.py:178 in _decorator       â”‚
â”‚                                                                              â”‚
â”‚   175 â”‚   â”‚   else:                                                          â”‚
â”‚   176 â”‚   â”‚   â”‚   context_manager = torch.no_grad                            â”‚
â”‚   177 â”‚   â”‚   with context_manager():                                        â”‚
â”‚ â± 178 â”‚   â”‚   â”‚   return loop_run(self, *args, **kwargs)                     â”‚
â”‚   179 â”‚                                                                      â”‚
â”‚   180 â”‚   return _decorator                                                  â”‚
â”‚   181                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:142 in run        â”‚
â”‚                                                                              â”‚
â”‚   139 â”‚   â”‚   â”‚   finally:                                                   â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   141 â”‚   â”‚   self._store_dataloader_outputs()                               â”‚
â”‚ â± 142 â”‚   â”‚   return self.on_run_end()                                       â”‚
â”‚   143 â”‚                                                                      â”‚
â”‚   144 â”‚   def setup_data(self) -> None:                                      â”‚
â”‚   145 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:254 in on_run_end â”‚
â”‚                                                                              â”‚
â”‚   251 â”‚   â”‚   self.trainer._logger_connector._evaluation_epoch_end()         â”‚
â”‚   252 â”‚   â”‚                                                                  â”‚
â”‚   253 â”‚   â”‚   # hook                                                         â”‚
â”‚ â± 254 â”‚   â”‚   self._on_evaluation_epoch_end()                                â”‚
â”‚   255 â”‚   â”‚                                                                  â”‚
â”‚   256 â”‚   â”‚   logged_outputs, self._logged_outputs = self._logged_outputs, [ â”‚
â”‚   257 â”‚   â”‚   # include any logged outputs on epoch_end                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:336 in            â”‚
â”‚ _on_evaluation_epoch_end                                                     â”‚
â”‚                                                                              â”‚
â”‚   333 â”‚   â”‚   call._call_callback_hooks(trainer, hook_name)                  â”‚
â”‚   334 â”‚   â”‚   call._call_lightning_module_hook(trainer, hook_name)           â”‚
â”‚   335 â”‚   â”‚                                                                  â”‚
â”‚ â± 336 â”‚   â”‚   trainer._logger_connector.on_epoch_end()                       â”‚
â”‚   337 â”‚                                                                      â”‚
â”‚   338 â”‚   def _store_dataloader_outputs(self) -> None:                       â”‚
â”‚   339 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:195 in on_epoch_end                                            â”‚
â”‚                                                                              â”‚
â”‚   192 â”‚                                                                      â”‚
â”‚   193 â”‚   def on_epoch_end(self) -> None:                                    â”‚
â”‚   194 â”‚   â”‚   assert self._first_loop_iter is None                           â”‚
â”‚ â± 195 â”‚   â”‚   metrics = self.metrics                                         â”‚
â”‚   196 â”‚   â”‚   self._progress_bar_metrics.update(metrics["pbar"])             â”‚
â”‚   197 â”‚   â”‚   self._callback_metrics.update(metrics["callback"])             â”‚
â”‚   198 â”‚   â”‚   self._logged_metrics.update(metrics["log"])                    â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:234 in metrics                                                 â”‚
â”‚                                                                              â”‚
â”‚   231 â”‚   â”‚   """This function returns either batch or epoch metrics."""     â”‚
â”‚   232 â”‚   â”‚   on_step = self._first_loop_iter is not None                    â”‚
â”‚   233 â”‚   â”‚   assert self.trainer._results is not None                       â”‚
â”‚ â± 234 â”‚   â”‚   return self.trainer._results.metrics(on_step)                  â”‚
â”‚   235 â”‚                                                                      â”‚
â”‚   236 â”‚   @property                                                          â”‚
â”‚   237 â”‚   def callback_metrics(self) -> _OUT_DICT:                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:473 in metrics                                                           â”‚
â”‚                                                                              â”‚
â”‚   470 â”‚   â”‚                                                                  â”‚
â”‚   471 â”‚   â”‚   for _, result_metric in self.valid_items():                    â”‚
â”‚   472 â”‚   â”‚   â”‚   # extract forward_cache or computed from the _ResultMetric â”‚
â”‚ â± 473 â”‚   â”‚   â”‚   value = self._get_cache(result_metric, on_step)            â”‚
â”‚   474 â”‚   â”‚   â”‚   if not isinstance(value, Tensor):                          â”‚
â”‚   475 â”‚   â”‚   â”‚   â”‚   continue                                               â”‚
â”‚   476                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:437 in _get_cache                                                        â”‚
â”‚                                                                              â”‚
â”‚   434 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   " devices.",                                   â”‚
â”‚   435 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   category=PossibleUserWarning,                  â”‚
â”‚   436 â”‚   â”‚   â”‚   â”‚   â”‚   )                                                  â”‚
â”‚ â± 437 â”‚   â”‚   â”‚   â”‚   result_metric.compute()                                â”‚
â”‚   438 â”‚   â”‚   â”‚   â”‚   result_metric.meta.sync.should = should                â”‚
â”‚   439 â”‚   â”‚   â”‚                                                              â”‚
â”‚   440 â”‚   â”‚   â”‚   cache = result_metric._computed                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:288 in wrapped_func                                                      â”‚
â”‚                                                                              â”‚
â”‚   285 â”‚   â”‚   â”‚   # return cached value                                      â”‚
â”‚   286 â”‚   â”‚   â”‚   if self._computed is not None:                             â”‚
â”‚   287 â”‚   â”‚   â”‚   â”‚   return self._computed                                  â”‚
â”‚ â± 288 â”‚   â”‚   â”‚   self._computed = compute(*args, **kwargs)                  â”‚
â”‚   289 â”‚   â”‚   â”‚   return self._computed                                      â”‚
â”‚   290 â”‚   â”‚                                                                  â”‚
â”‚   291 â”‚   â”‚   return wrapped_func                                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:253 in compute                                                           â”‚
â”‚                                                                              â”‚
â”‚   250 â”‚   â”‚   â”‚   â”‚   cumulated_batch_size = self.meta.sync(self.cumulated_b â”‚
â”‚   251 â”‚   â”‚   â”‚   â”‚   return value / cumulated_batch_size                    â”‚
â”‚   252 â”‚   â”‚   â”‚   return value                                               â”‚
â”‚ â± 253 â”‚   â”‚   return self.value.compute()                                    â”‚
â”‚   254 â”‚                                                                      â”‚
â”‚   255 â”‚   @override                                                          â”‚
â”‚   256 â”‚   def reset(self) -> None:                                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/metric.py:700 in wrapped_func                   â”‚
â”‚                                                                              â”‚
â”‚    697 â”‚   â”‚   â”‚   â”‚   should_sync=self._to_sync,                            â”‚
â”‚    698 â”‚   â”‚   â”‚   â”‚   should_unsync=self._should_unsync,                    â”‚
â”‚    699 â”‚   â”‚   â”‚   ):                                                        â”‚
â”‚ â±  700 â”‚   â”‚   â”‚   â”‚   value = _squeeze_if_scalar(compute(*args, **kwargs))  â”‚
â”‚    701 â”‚   â”‚   â”‚   â”‚   # clone tensor to avoid in-place operations after com â”‚
â”‚    702 â”‚   â”‚   â”‚   â”‚   value = apply_to_collection(value, Tensor, lambda x:  â”‚
â”‚    703                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:241 in compute                                                             â”‚
â”‚                                                                              â”‚
â”‚   238 â”‚   â”‚   Returns:                                                       â”‚
â”‚   239 â”‚   â”‚   â”‚   Tensor: Value of the AUPRO metric                          â”‚
â”‚   240 â”‚   â”‚   """                                                            â”‚
â”‚ â± 241 â”‚   â”‚   fpr, tpr = self._compute()                                     â”‚
â”‚   242 â”‚   â”‚                                                                  â”‚
â”‚   243 â”‚   â”‚   aupro = auc(fpr, tpr, reorder=True)                            â”‚
â”‚   244 â”‚   â”‚   return aupro / fpr[-1]  # normalize the area                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:229 in _compute                                                            â”‚
â”‚                                                                              â”‚
â”‚   226 â”‚   â”‚   Returns:                                                       â”‚
â”‚   227 â”‚   â”‚   â”‚   tuple[torch.Tensor, torch.Tensor]: tuple containing final  â”‚
â”‚   228 â”‚   â”‚   """                                                            â”‚
â”‚ â± 229 â”‚   â”‚   cca = self.perform_cca().flatten()                             â”‚
â”‚   230 â”‚   â”‚   target = dim_zero_cat(self.target).flatten()                   â”‚
â”‚   231 â”‚   â”‚   preds = dim_zero_cat(self.preds).flatten()                     â”‚
â”‚   232                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:108 in perform_cca                                                         â”‚
â”‚                                                                              â”‚
â”‚   105 â”‚   â”‚   Returns:                                                       â”‚
â”‚   106 â”‚   â”‚   â”‚   Tensor: Components labeled from 0 to N.                    â”‚
â”‚   107 â”‚   â”‚   """                                                            â”‚
â”‚ â± 108 â”‚   â”‚   target = dim_zero_cat(self.target)                             â”‚
â”‚   109 â”‚   â”‚                                                                  â”‚
â”‚   110 â”‚   â”‚   # check and prepare target for labeling via kornia             â”‚
â”‚   111 â”‚   â”‚   if target.min() < 0 or target.max() > 1:                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/utilities/data.py:36 in dim_zero_cat            â”‚
â”‚                                                                              â”‚
â”‚    33 â”‚   x = [y.unsqueeze(0) if y.numel() == 1 and y.ndim == 0 else y for y â”‚
â”‚    34 â”‚   if not x:  # empty list                                            â”‚
â”‚    35 â”‚   â”‚   raise ValueError("No samples to concatenate")                  â”‚
â”‚ â±  36 â”‚   return torch.cat(x, dim=0)                                         â”‚
â”‚    37                                                                        â”‚
â”‚    38                                                                        â”‚
â”‚    39 def dim_zero_sum(x: Tensor) -> Tensor:                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [05:56<00:00,  0.32it/s]

                                                                        [A/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
INFO:anomalib.models.components.base.anomaly_module:Initializing Padim model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing LWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPADE model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:anomalib.models.components.base.anomaly_module:Initializing SPALWinNN model.
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:src.anomalib.data.image.visa:Found the dataset and train/test split.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer

  | Name                  | Type                     | Params | Mode 
---------------------------------------------------------------------------
0 | model                 | PatchcoreModel           | 2.8 M  | train
1 | _transform            | Compose                  | 0      | train
2 | normalization_metrics | MetricCollection         | 0      | train
3 | image_threshold       | F1AdaptiveThreshold      | 0      | train
4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train
5 | image_metrics         | AnomalibMetricCollection | 0      | train
6 | pixel_metrics         | AnomalibMetricCollection | 0      | train
---------------------------------------------------------------------------
2.8 M     Trainable params
0         Non-trainable params
2.8 M     Total params
11.131    Total estimated model params size (MB)
15        Modules in train mode
69        Modules in eval mode
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Running dataset visa pcb4 with model patchcore
/cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/113 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/113 [00:00<?, ?it/s] /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   1%|          | 1/113 [00:00<00:50,  2.21it/s]Epoch 0:   1%|          | 1/113 [00:00<00:50,  2.20it/s]Epoch 0:   2%|â–         | 2/113 [00:00<00:25,  4.33it/s]Epoch 0:   2%|â–         | 2/113 [00:00<00:25,  4.33it/s]Epoch 0:   3%|â–Ž         | 3/113 [00:00<00:24,  4.55it/s]Epoch 0:   3%|â–Ž         | 3/113 [00:00<00:24,  4.55it/s]Epoch 0:   4%|â–Ž         | 4/113 [00:00<00:23,  4.68it/s]Epoch 0:   4%|â–Ž         | 4/113 [00:00<00:23,  4.68it/s]Epoch 0:   4%|â–         | 5/113 [00:01<00:22,  4.76it/s]Epoch 0:   4%|â–         | 5/113 [00:01<00:22,  4.75it/s]Epoch 0:   5%|â–Œ         | 6/113 [00:01<00:22,  4.83it/s]Epoch 0:   5%|â–Œ         | 6/113 [00:01<00:22,  4.82it/s]Epoch 0:   6%|â–Œ         | 7/113 [00:01<00:21,  4.87it/s]Epoch 0:   6%|â–Œ         | 7/113 [00:01<00:21,  4.87it/s]Epoch 0:   7%|â–‹         | 8/113 [00:01<00:21,  4.91it/s]Epoch 0:   7%|â–‹         | 8/113 [00:01<00:21,  4.91it/s]Epoch 0:   8%|â–Š         | 9/113 [00:01<00:21,  4.94it/s]Epoch 0:   8%|â–Š         | 9/113 [00:01<00:21,  4.94it/s]Epoch 0:   9%|â–‰         | 10/113 [00:02<00:20,  4.95it/s]Epoch 0:   9%|â–‰         | 10/113 [00:02<00:20,  4.95it/s]Epoch 0:  10%|â–‰         | 11/113 [00:02<00:20,  4.98it/s]Epoch 0:  10%|â–‰         | 11/113 [00:02<00:20,  4.97it/s]Epoch 0:  11%|â–ˆ         | 12/113 [00:02<00:20,  4.99it/s]Epoch 0:  11%|â–ˆ         | 12/113 [00:02<00:20,  4.99it/s]Epoch 0:  12%|â–ˆâ–        | 13/113 [00:02<00:19,  5.01it/s]Epoch 0:  12%|â–ˆâ–        | 13/113 [00:02<00:19,  5.01it/s]Epoch 0:  12%|â–ˆâ–        | 14/113 [00:02<00:19,  5.02it/s]Epoch 0:  12%|â–ˆâ–        | 14/113 [00:02<00:19,  5.01it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/113 [00:02<00:19,  5.03it/s]Epoch 0:  13%|â–ˆâ–Ž        | 15/113 [00:02<00:19,  5.03it/s]Epoch 0:  14%|â–ˆâ–        | 16/113 [00:03<00:19,  5.03it/s]Epoch 0:  14%|â–ˆâ–        | 16/113 [00:03<00:19,  5.03it/s]Epoch 0:  15%|â–ˆâ–Œ        | 17/113 [00:03<00:19,  5.04it/s]Epoch 0:  15%|â–ˆâ–Œ        | 17/113 [00:03<00:19,  5.04it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/113 [00:03<00:18,  5.05it/s]Epoch 0:  16%|â–ˆâ–Œ        | 18/113 [00:03<00:18,  5.05it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/113 [00:03<00:18,  5.06it/s]Epoch 0:  17%|â–ˆâ–‹        | 19/113 [00:03<00:18,  5.06it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/113 [00:03<00:18,  5.06it/s]Epoch 0:  18%|â–ˆâ–Š        | 20/113 [00:03<00:18,  5.06it/s]Epoch 0:  19%|â–ˆâ–Š        | 21/113 [00:04<00:18,  5.07it/s]Epoch 0:  19%|â–ˆâ–Š        | 21/113 [00:04<00:18,  5.07it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/113 [00:04<00:17,  5.07it/s]Epoch 0:  19%|â–ˆâ–‰        | 22/113 [00:04<00:17,  5.07it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/113 [00:04<00:17,  5.08it/s]Epoch 0:  20%|â–ˆâ–ˆ        | 23/113 [00:04<00:17,  5.08it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/113 [00:04<00:17,  5.08it/s]Epoch 0:  21%|â–ˆâ–ˆ        | 24/113 [00:04<00:17,  5.08it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/113 [00:04<00:17,  5.08it/s]Epoch 0:  22%|â–ˆâ–ˆâ–       | 25/113 [00:04<00:17,  5.08it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/113 [00:05<00:17,  5.08it/s]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 26/113 [00:05<00:17,  5.08it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 27/113 [00:05<00:16,  5.08it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 27/113 [00:05<00:16,  5.08it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/113 [00:05<00:16,  5.08it/s]Epoch 0:  25%|â–ˆâ–ˆâ–       | 28/113 [00:05<00:16,  5.08it/s]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 29/113 [00:05<00:16,  5.08it/s]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 29/113 [00:05<00:16,  5.08it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 30/113 [00:05<00:16,  5.09it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 30/113 [00:05<00:16,  5.09it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/113 [00:06<00:16,  5.09it/s]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 31/113 [00:06<00:16,  5.09it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/113 [00:06<00:15,  5.08it/s]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 32/113 [00:06<00:15,  5.08it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/113 [00:06<00:15,  5.08it/s]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 33/113 [00:06<00:15,  5.08it/s]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 34/113 [00:06<00:15,  5.08it/s]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 34/113 [00:06<00:15,  5.08it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/113 [00:06<00:15,  5.08it/s]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 35/113 [00:06<00:15,  5.08it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/113 [00:07<00:15,  5.09it/s]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 36/113 [00:07<00:15,  5.09it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 37/113 [00:07<00:14,  5.09it/s]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 37/113 [00:07<00:14,  5.09it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/113 [00:07<00:14,  5.09it/s]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 38/113 [00:07<00:14,  5.09it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 39/113 [00:07<00:14,  5.10it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 39/113 [00:07<00:14,  5.10it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/113 [00:07<00:14,  5.10it/s]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/113 [00:07<00:14,  5.10it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 41/113 [00:08<00:14,  5.10it/s]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 41/113 [00:08<00:14,  5.10it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/113 [00:08<00:13,  5.10it/s]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 42/113 [00:08<00:13,  5.10it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/113 [00:08<00:13,  5.10it/s]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/113 [00:08<00:13,  5.10it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 44/113 [00:08<00:13,  5.10it/s]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 44/113 [00:08<00:13,  5.10it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 45/113 [00:08<00:13,  5.10it/s]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 45/113 [00:08<00:13,  5.10it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/113 [00:09<00:13,  5.10it/s]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/113 [00:09<00:13,  5.10it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/113 [00:09<00:12,  5.11it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/113 [00:09<00:12,  5.11it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/113 [00:09<00:12,  5.11it/s]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/113 [00:09<00:12,  5.11it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/113 [00:09<00:12,  5.11it/s]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 49/113 [00:09<00:12,  5.11it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/113 [00:09<00:12,  5.11it/s]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/113 [00:09<00:12,  5.11it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 51/113 [00:09<00:12,  5.11it/s]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 51/113 [00:09<00:12,  5.11it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/113 [00:10<00:11,  5.11it/s]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 52/113 [00:10<00:11,  5.11it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/113 [00:10<00:11,  5.11it/s]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/113 [00:10<00:11,  5.11it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 54/113 [00:10<00:11,  5.11it/s]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 54/113 [00:10<00:11,  5.11it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/113 [00:10<00:11,  5.12it/s]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 55/113 [00:10<00:11,  5.12it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/113 [00:10<00:11,  5.12it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 56/113 [00:10<00:11,  5.12it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/113 [00:11<00:10,  5.12it/s]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/113 [00:11<00:10,  5.12it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 58/113 [00:11<00:10,  5.12it/s]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 58/113 [00:11<00:10,  5.12it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/113 [00:11<00:10,  5.12it/s]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/113 [00:11<00:10,  5.12it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/113 [00:11<00:10,  5.12it/s]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/113 [00:11<00:10,  5.12it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 61/113 [00:11<00:10,  5.12it/s]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 61/113 [00:11<00:10,  5.12it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/113 [00:12<00:09,  5.12it/s]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 62/113 [00:12<00:09,  5.12it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/113 [00:12<00:09,  5.13it/s]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 63/113 [00:12<00:09,  5.13it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 64/113 [00:12<00:09,  5.13it/s]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 64/113 [00:12<00:09,  5.13it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 65/113 [00:12<00:09,  5.13it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 65/113 [00:12<00:09,  5.13it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/113 [00:12<00:09,  5.13it/s]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 66/113 [00:12<00:09,  5.13it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/113 [00:13<00:08,  5.13it/s]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/113 [00:13<00:08,  5.13it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 68/113 [00:13<00:08,  5.13it/s]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 68/113 [00:13<00:08,  5.13it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/113 [00:13<00:08,  5.13it/s]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 69/113 [00:13<00:08,  5.13it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/113 [00:13<00:08,  5.13it/s]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/113 [00:13<00:08,  5.13it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 71/113 [00:13<00:08,  5.13it/s]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 71/113 [00:13<00:08,  5.13it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/113 [00:14<00:07,  5.14it/s]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 72/113 [00:14<00:07,  5.14it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/113 [00:14<00:07,  5.14it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 73/113 [00:14<00:07,  5.14it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 74/113 [00:14<00:07,  5.14it/s]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 74/113 [00:14<00:07,  5.14it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 75/113 [00:14<00:07,  5.14it/s]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 75/113 [00:14<00:07,  5.14it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/113 [00:14<00:07,  5.14it/s]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 76/113 [00:14<00:07,  5.14it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/113 [00:14<00:07,  5.14it/s]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 77/113 [00:14<00:07,  5.14it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 78/113 [00:15<00:06,  5.14it/s]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 78/113 [00:15<00:06,  5.14it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/113 [00:15<00:06,  5.14it/s]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 79/113 [00:15<00:06,  5.14it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/113 [00:15<00:06,  5.14it/s]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 80/113 [00:15<00:06,  5.14it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 81/113 [00:15<00:06,  5.15it/s]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 81/113 [00:15<00:06,  5.15it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 82/113 [00:15<00:06,  5.15it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 82/113 [00:15<00:06,  5.15it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/113 [00:16<00:05,  5.15it/s]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 83/113 [00:16<00:05,  5.15it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 84/113 [00:16<00:05,  5.15it/s]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 84/113 [00:16<00:05,  5.15it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 85/113 [00:16<00:05,  5.15it/s]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 85/113 [00:16<00:05,  5.15it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/113 [00:16<00:05,  5.15it/s]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 86/113 [00:16<00:05,  5.15it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/113 [00:16<00:05,  5.16it/s]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 87/113 [00:16<00:05,  5.16it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 88/113 [00:17<00:04,  5.16it/s]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 88/113 [00:17<00:04,  5.16it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 89/113 [00:17<00:04,  5.16it/s]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 89/113 [00:17<00:04,  5.16it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/113 [00:17<00:04,  5.16it/s]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 90/113 [00:17<00:04,  5.16it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 91/113 [00:17<00:04,  5.16it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 91/113 [00:17<00:04,  5.16it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 92/113 [00:17<00:04,  5.16it/s]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 92/113 [00:17<00:04,  5.16it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/113 [00:18<00:03,  5.16it/s]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/113 [00:18<00:03,  5.16it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 94/113 [00:18<00:03,  5.16it/s]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 94/113 [00:18<00:03,  5.16it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 95/113 [00:18<00:03,  5.17it/s]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 95/113 [00:18<00:03,  5.17it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/113 [00:18<00:03,  5.17it/s]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 96/113 [00:18<00:03,  5.17it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/113 [00:18<00:03,  5.17it/s]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 97/113 [00:18<00:03,  5.17it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 98/113 [00:18<00:02,  5.17it/s]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 98/113 [00:18<00:02,  5.17it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 99/113 [00:19<00:02,  5.17it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 99/113 [00:19<00:02,  5.17it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/113 [00:19<00:02,  5.17it/s]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 100/113 [00:19<00:02,  5.17it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 101/113 [00:19<00:02,  5.17it/s]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 101/113 [00:19<00:02,  5.17it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 102/113 [00:19<00:02,  5.17it/s]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 102/113 [00:19<00:02,  5.17it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/113 [00:19<00:01,  5.17it/s]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 103/113 [00:19<00:01,  5.17it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 104/113 [00:20<00:01,  5.17it/s]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 104/113 [00:20<00:01,  5.17it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 105/113 [00:20<00:01,  5.18it/s]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 105/113 [00:20<00:01,  5.18it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 106/113 [00:20<00:01,  5.18it/s]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 106/113 [00:20<00:01,  5.18it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/113 [00:20<00:01,  5.18it/s]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 107/113 [00:20<00:01,  5.18it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 108/113 [00:20<00:00,  5.18it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 108/113 [00:20<00:00,  5.18it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 109/113 [00:21<00:00,  5.18it/s]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 109/113 [00:21<00:00,  5.18it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/113 [00:21<00:00,  5.18it/s]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 110/113 [00:21<00:00,  5.18it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 111/113 [00:21<00:00,  5.18it/s]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 111/113 [00:21<00:00,  5.18it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 112/113 [00:21<00:00,  5.18it/s]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 112/113 [00:21<00:00,  5.18it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:21<00:00,  5.18it/s]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:21<00:00,  5.18it/s]
Validation: |          | 0/? [00:00<?, ?it/s][AINFO:src.anomalib.models.image.patchcore.lightning_model:Aggregating the embedding extracted from the training set.
INFO:src.anomalib.models.image.patchcore.lightning_model:Applying core-set subsampling to get the embedding.


Selecting Coreset Indices.:   0%|          | 0/75212 [00:00<?, ?it/s][A[A

Selecting Coreset Indices.:   0%|          | 8/75212 [00:00<16:24, 76.41it/s][A[A

Selecting Coreset Indices.:   0%|          | 22/75212 [00:00<11:18, 110.74it/s][A[A

Selecting Coreset Indices.:   0%|          | 36/75212 [00:00<10:16, 121.90it/s][A[A

Selecting Coreset Indices.:   0%|          | 50/75212 [00:00<09:51, 127.17it/s][A[A

Selecting Coreset Indices.:   0%|          | 64/75212 [00:00<09:37, 130.10it/s][A[A

Selecting Coreset Indices.:   0%|          | 78/75212 [00:00<09:29, 131.86it/s][A[A

Selecting Coreset Indices.:   0%|          | 92/75212 [00:00<09:24, 132.98it/s][A[A

Selecting Coreset Indices.:   0%|          | 106/75212 [00:00<09:21, 133.72it/s][A[A

Selecting Coreset Indices.:   0%|          | 120/75212 [00:00<09:19, 134.21it/s][A[A

Selecting Coreset Indices.:   0%|          | 134/75212 [00:01<09:18, 134.55it/s][A[A

Selecting Coreset Indices.:   0%|          | 148/75212 [00:01<09:16, 134.78it/s][A[A

Selecting Coreset Indices.:   0%|          | 162/75212 [00:01<09:16, 134.93it/s][A[A

Selecting Coreset Indices.:   0%|          | 176/75212 [00:01<09:15, 135.05it/s][A[A

Selecting Coreset Indices.:   0%|          | 190/75212 [00:01<09:15, 135.12it/s][A[A

Selecting Coreset Indices.:   0%|          | 204/75212 [00:01<09:14, 135.16it/s][A[A

Selecting Coreset Indices.:   0%|          | 218/75212 [00:01<09:14, 135.21it/s][A[A

Selecting Coreset Indices.:   0%|          | 232/75212 [00:01<09:14, 135.24it/s][A[A

Selecting Coreset Indices.:   0%|          | 246/75212 [00:01<09:14, 135.26it/s][A[A

Selecting Coreset Indices.:   0%|          | 260/75212 [00:01<09:14, 135.28it/s][A[A

Selecting Coreset Indices.:   0%|          | 274/75212 [00:02<09:13, 135.30it/s][A[A

Selecting Coreset Indices.:   0%|          | 288/75212 [00:02<09:13, 135.31it/s][A[A

Selecting Coreset Indices.:   0%|          | 302/75212 [00:02<09:13, 135.31it/s][A[A

Selecting Coreset Indices.:   0%|          | 316/75212 [00:02<09:13, 135.32it/s][A[A

Selecting Coreset Indices.:   0%|          | 330/75212 [00:02<09:14, 135.11it/s][A[A

Selecting Coreset Indices.:   0%|          | 344/75212 [00:02<09:14, 135.10it/s][A[A

Selecting Coreset Indices.:   0%|          | 358/75212 [00:02<09:13, 135.16it/s][A[A

Selecting Coreset Indices.:   0%|          | 372/75212 [00:02<09:13, 135.19it/s][A[A

Selecting Coreset Indices.:   1%|          | 386/75212 [00:02<09:13, 135.23it/s][A[A

Selecting Coreset Indices.:   1%|          | 400/75212 [00:03<09:13, 135.25it/s][A[A

Selecting Coreset Indices.:   1%|          | 414/75212 [00:03<09:12, 135.27it/s][A[A

Selecting Coreset Indices.:   1%|          | 428/75212 [00:03<09:12, 135.28it/s][A[A

Selecting Coreset Indices.:   1%|          | 442/75212 [00:03<09:12, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 456/75212 [00:03<09:12, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 470/75212 [00:03<09:12, 135.31it/s][A[A

Selecting Coreset Indices.:   1%|          | 484/75212 [00:03<09:12, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 498/75212 [00:03<09:12, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 512/75212 [00:03<09:12, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 526/75212 [00:03<09:12, 135.29it/s][A[A

Selecting Coreset Indices.:   1%|          | 540/75212 [00:04<09:11, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 554/75212 [00:04<09:11, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 568/75212 [00:04<09:11, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 582/75212 [00:04<09:11, 135.29it/s][A[A

Selecting Coreset Indices.:   1%|          | 596/75212 [00:04<09:11, 135.29it/s][A[A

Selecting Coreset Indices.:   1%|          | 610/75212 [00:04<09:11, 135.29it/s][A[A

Selecting Coreset Indices.:   1%|          | 624/75212 [00:04<09:11, 135.30it/s][A[A

Selecting Coreset Indices.:   1%|          | 638/75212 [00:04<09:11, 135.31it/s][A[A

Selecting Coreset Indices.:   1%|          | 652/75212 [00:04<09:11, 135.31it/s][A[A

Selecting Coreset Indices.:   1%|          | 666/75212 [00:04<09:11, 135.24it/s][A[A

Selecting Coreset Indices.:   1%|          | 680/75212 [00:05<09:11, 135.21it/s][A[A

Selecting Coreset Indices.:   1%|          | 694/75212 [00:05<09:11, 135.22it/s][A[A

Selecting Coreset Indices.:   1%|          | 708/75212 [00:05<09:10, 135.26it/s][A[A

Selecting Coreset Indices.:   1%|          | 722/75212 [00:05<09:10, 135.28it/s][A[A

Selecting Coreset Indices.:   1%|          | 736/75212 [00:05<09:10, 135.28it/s][A[A

Selecting Coreset Indices.:   1%|          | 750/75212 [00:05<09:10, 135.29it/s][A[A

Selecting Coreset Indices.:   1%|          | 764/75212 [00:05<09:10, 135.15it/s][A[A

Selecting Coreset Indices.:   1%|          | 778/75212 [00:05<09:10, 135.13it/s][A[A

Selecting Coreset Indices.:   1%|          | 792/75212 [00:05<09:10, 135.18it/s][A[A

Selecting Coreset Indices.:   1%|          | 806/75212 [00:06<09:10, 135.22it/s][A[A

Selecting Coreset Indices.:   1%|          | 820/75212 [00:06<09:10, 135.25it/s][A[A

Selecting Coreset Indices.:   1%|          | 834/75212 [00:06<09:09, 135.28it/s][A[A

Selecting Coreset Indices.:   1%|          | 848/75212 [00:06<09:09, 135.27it/s][A[A

Selecting Coreset Indices.:   1%|          | 862/75212 [00:06<09:09, 135.27it/s][A[A

Selecting Coreset Indices.:   1%|          | 876/75212 [00:06<09:14, 134.12it/s][A[A

Selecting Coreset Indices.:   1%|          | 890/75212 [00:06<09:12, 134.41it/s][A[A

Selecting Coreset Indices.:   1%|          | 904/75212 [00:06<09:11, 134.68it/s][A[A

Selecting Coreset Indices.:   1%|          | 918/75212 [00:06<09:10, 134.88it/s][A[A

Selecting Coreset Indices.:   1%|          | 932/75212 [00:06<09:10, 135.00it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 946/75212 [00:07<09:09, 135.06it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 960/75212 [00:07<09:09, 135.07it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 974/75212 [00:07<09:09, 135.13it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 988/75212 [00:07<09:08, 135.20it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1002/75212 [00:07<09:08, 135.23it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1016/75212 [00:07<09:08, 135.25it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1030/75212 [00:07<09:08, 135.26it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1044/75212 [00:07<09:08, 135.26it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1058/75212 [00:07<09:08, 135.27it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1072/75212 [00:07<09:07, 135.29it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1086/75212 [00:08<09:07, 135.28it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1100/75212 [00:08<09:07, 135.27it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1114/75212 [00:08<09:07, 135.28it/s][A[A

Selecting Coreset Indices.:   1%|â–         | 1128/75212 [00:08<09:07, 135.28it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1142/75212 [00:08<09:07, 135.28it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1156/75212 [00:08<09:07, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1170/75212 [00:08<09:07, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1184/75212 [00:08<09:07, 135.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1198/75212 [00:08<09:06, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1212/75212 [00:09<09:06, 135.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1226/75212 [00:09<09:06, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1240/75212 [00:09<09:06, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1254/75212 [00:09<09:06, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1268/75212 [00:09<09:06, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1282/75212 [00:09<09:06, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1296/75212 [00:09<09:06, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1310/75212 [00:09<09:06, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1324/75212 [00:09<09:06, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1338/75212 [00:09<09:05, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1352/75212 [00:10<09:05, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1366/75212 [00:10<09:05, 135.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1380/75212 [00:10<09:05, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1394/75212 [00:10<09:05, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1408/75212 [00:10<09:05, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1422/75212 [00:10<09:05, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1436/75212 [00:10<09:05, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1450/75212 [00:10<09:05, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1464/75212 [00:10<09:05, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1478/75212 [00:10<09:04, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1492/75212 [00:11<09:04, 135.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1506/75212 [00:11<09:04, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1520/75212 [00:11<09:04, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1534/75212 [00:11<09:04, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1548/75212 [00:11<09:04, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1562/75212 [00:11<09:04, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1576/75212 [00:11<09:04, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1590/75212 [00:11<09:04, 135.33it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1604/75212 [00:11<09:03, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1618/75212 [00:12<09:03, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1632/75212 [00:12<09:03, 135.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1646/75212 [00:12<09:03, 135.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1660/75212 [00:12<09:03, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1674/75212 [00:12<09:03, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1688/75212 [00:12<09:03, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1702/75212 [00:12<09:03, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1716/75212 [00:12<09:03, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1730/75212 [00:12<09:03, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1744/75212 [00:12<09:02, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1758/75212 [00:13<09:02, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1772/75212 [00:13<09:02, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1786/75212 [00:13<09:02, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1800/75212 [00:13<09:02, 135.30it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1814/75212 [00:13<09:02, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1828/75212 [00:13<09:02, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1842/75212 [00:13<09:02, 135.31it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1856/75212 [00:13<09:02, 135.32it/s][A[A

Selecting Coreset Indices.:   2%|â–         | 1870/75212 [00:13<09:02, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1884/75212 [00:13<09:01, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1898/75212 [00:14<09:01, 135.29it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1912/75212 [00:14<09:01, 135.28it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1926/75212 [00:14<09:01, 135.29it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1940/75212 [00:14<09:01, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1954/75212 [00:14<09:01, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1968/75212 [00:14<09:01, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1982/75212 [00:14<09:01, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 1996/75212 [00:14<09:01, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2010/75212 [00:14<09:01, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2024/75212 [00:15<09:00, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2038/75212 [00:15<09:02, 134.88it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2052/75212 [00:15<09:01, 134.99it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2066/75212 [00:15<09:01, 135.08it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2080/75212 [00:15<09:01, 135.15it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2094/75212 [00:15<09:00, 135.19it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2108/75212 [00:15<09:00, 135.23it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2122/75212 [00:15<09:00, 135.25it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2136/75212 [00:15<09:00, 135.27it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2150/75212 [00:15<09:00, 135.29it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2164/75212 [00:16<08:59, 135.29it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2178/75212 [00:16<08:59, 135.28it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2192/75212 [00:16<08:59, 135.27it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2206/75212 [00:16<08:59, 135.28it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2220/75212 [00:16<08:59, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2234/75212 [00:16<08:59, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2248/75212 [00:16<08:59, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2262/75212 [00:16<08:59, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2276/75212 [00:16<08:58, 135.33it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2290/75212 [00:16<08:58, 135.33it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2304/75212 [00:17<08:58, 135.33it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2318/75212 [00:17<09:03, 134.10it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2332/75212 [00:17<09:02, 134.44it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2346/75212 [00:17<09:00, 134.71it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2360/75212 [00:17<09:00, 134.89it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2374/75212 [00:17<08:59, 135.01it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2388/75212 [00:17<08:58, 135.11it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2402/75212 [00:17<08:58, 135.17it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2416/75212 [00:17<08:58, 135.22it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2430/75212 [00:18<08:58, 135.26it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2444/75212 [00:18<08:57, 135.28it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2458/75212 [00:18<08:57, 135.29it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2472/75212 [00:18<08:57, 135.29it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2486/75212 [00:18<08:57, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2500/75212 [00:18<08:57, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2514/75212 [00:18<08:57, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2528/75212 [00:18<08:57, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2542/75212 [00:18<08:57, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2556/75212 [00:18<08:56, 135.30it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2570/75212 [00:19<08:56, 135.31it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2584/75212 [00:19<08:56, 135.32it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2598/75212 [00:19<08:56, 135.33it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2612/75212 [00:19<08:56, 135.33it/s][A[A

Selecting Coreset Indices.:   3%|â–Ž         | 2626/75212 [00:19<08:56, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2640/75212 [00:19<08:56, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2654/75212 [00:19<08:56, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2668/75212 [00:19<08:56, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2682/75212 [00:19<08:55, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2696/75212 [00:19<08:55, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2710/75212 [00:20<08:55, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2724/75212 [00:20<08:55, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2738/75212 [00:20<08:55, 135.31it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2752/75212 [00:20<08:55, 135.31it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2766/75212 [00:20<08:55, 135.31it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2780/75212 [00:20<08:55, 135.31it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2794/75212 [00:20<08:55, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–Ž         | 2808/75212 [00:20<08:55, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2822/75212 [00:20<08:54, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2836/75212 [00:21<08:54, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2850/75212 [00:21<08:54, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2864/75212 [00:21<08:54, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2878/75212 [00:21<08:54, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2892/75212 [00:21<08:54, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2906/75212 [00:21<08:54, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2920/75212 [00:21<08:54, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2934/75212 [00:21<08:54, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2948/75212 [00:21<08:54, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2962/75212 [00:21<08:53, 135.31it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2976/75212 [00:22<08:53, 135.31it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 2990/75212 [00:22<08:53, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3004/75212 [00:22<08:53, 135.34it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3018/75212 [00:22<08:53, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3032/75212 [00:22<08:53, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3046/75212 [00:22<08:53, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3060/75212 [00:22<08:53, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3074/75212 [00:22<08:53, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3088/75212 [00:22<08:52, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3102/75212 [00:22<08:52, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3116/75212 [00:23<08:52, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3130/75212 [00:23<08:52, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3144/75212 [00:23<08:52, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3158/75212 [00:23<08:52, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3172/75212 [00:23<08:52, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3186/75212 [00:23<08:52, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3200/75212 [00:23<08:52, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3214/75212 [00:23<08:52, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3228/75212 [00:23<08:51, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3242/75212 [00:24<08:51, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3256/75212 [00:24<08:51, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3270/75212 [00:24<08:51, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3284/75212 [00:24<08:51, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3298/75212 [00:24<08:51, 135.31it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3312/75212 [00:24<08:51, 135.32it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3326/75212 [00:24<08:51, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3340/75212 [00:24<08:51, 135.33it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3354/75212 [00:24<08:50, 135.34it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3368/75212 [00:24<08:50, 135.34it/s][A[A

Selecting Coreset Indices.:   4%|â–         | 3382/75212 [00:25<08:50, 135.34it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3396/75212 [00:25<08:50, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3410/75212 [00:25<08:50, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3424/75212 [00:25<08:50, 135.30it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3438/75212 [00:25<08:50, 135.30it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3452/75212 [00:25<08:50, 135.31it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3466/75212 [00:25<08:50, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3480/75212 [00:25<08:50, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3494/75212 [00:25<08:49, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3508/75212 [00:25<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3522/75212 [00:26<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3536/75212 [00:26<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3550/75212 [00:26<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3564/75212 [00:26<08:49, 135.34it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3578/75212 [00:26<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3592/75212 [00:26<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3606/75212 [00:26<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3620/75212 [00:26<08:49, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3634/75212 [00:26<08:48, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3648/75212 [00:27<08:48, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3662/75212 [00:27<08:48, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3676/75212 [00:27<08:48, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3690/75212 [00:27<08:48, 135.28it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3704/75212 [00:27<08:48, 135.29it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3718/75212 [00:27<08:48, 135.31it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3732/75212 [00:27<08:48, 135.31it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3746/75212 [00:27<08:48, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–         | 3760/75212 [00:27<08:48, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3774/75212 [00:27<08:47, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3788/75212 [00:28<08:47, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3802/75212 [00:28<08:47, 135.34it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3816/75212 [00:28<08:47, 135.34it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3830/75212 [00:28<08:47, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3844/75212 [00:28<08:47, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3858/75212 [00:28<08:47, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3872/75212 [00:28<08:47, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3886/75212 [00:28<08:47, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3900/75212 [00:28<08:46, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3914/75212 [00:28<08:46, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3928/75212 [00:29<08:46, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3942/75212 [00:29<08:46, 135.32it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3956/75212 [00:29<08:46, 135.33it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3970/75212 [00:29<08:50, 134.31it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3984/75212 [00:29<08:49, 134.60it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 3998/75212 [00:29<08:48, 134.83it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4012/75212 [00:29<08:47, 134.97it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4026/75212 [00:29<08:47, 135.08it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4040/75212 [00:29<08:46, 135.14it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4054/75212 [00:30<08:46, 135.19it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4068/75212 [00:30<08:46, 135.23it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4082/75212 [00:30<08:45, 135.26it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4096/75212 [00:30<08:45, 135.27it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4110/75212 [00:30<08:45, 135.29it/s][A[A

Selecting Coreset Indices.:   5%|â–Œ         | 4124/75212 [00:30<08:45, 135.31it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4138/75212 [00:30<08:45, 135.31it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4152/75212 [00:30<08:45, 135.31it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4166/75212 [00:30<08:45, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4180/75212 [00:30<08:44, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4194/75212 [00:31<08:44, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4208/75212 [00:31<08:44, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4222/75212 [00:31<08:44, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4236/75212 [00:31<08:44, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4250/75212 [00:31<08:44, 135.30it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4264/75212 [00:31<08:44, 135.30it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4278/75212 [00:31<08:44, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4292/75212 [00:31<08:44, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4306/75212 [00:31<08:43, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4320/75212 [00:31<08:43, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4334/75212 [00:32<08:43, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4348/75212 [00:32<08:43, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4362/75212 [00:32<08:43, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4376/75212 [00:32<08:43, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4390/75212 [00:32<08:43, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4404/75212 [00:32<08:43, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4418/75212 [00:32<08:43, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4432/75212 [00:32<08:43, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4446/75212 [00:32<08:42, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4460/75212 [00:33<08:42, 135.35it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4474/75212 [00:33<08:42, 135.35it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4488/75212 [00:33<08:42, 135.35it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4502/75212 [00:33<08:42, 135.36it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4516/75212 [00:33<08:42, 135.31it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4530/75212 [00:33<08:42, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4544/75212 [00:33<08:42, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4558/75212 [00:33<08:42, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4572/75212 [00:33<08:41, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4586/75212 [00:33<08:41, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4600/75212 [00:34<08:41, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4614/75212 [00:34<08:41, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4628/75212 [00:34<08:41, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4642/75212 [00:34<08:41, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4656/75212 [00:34<08:41, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4670/75212 [00:34<08:41, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4684/75212 [00:34<08:41, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–Œ         | 4698/75212 [00:34<08:41, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4712/75212 [00:34<08:40, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4726/75212 [00:34<08:40, 135.35it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4740/75212 [00:35<08:40, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4754/75212 [00:35<08:40, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4768/75212 [00:35<08:40, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4782/75212 [00:35<08:40, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4796/75212 [00:35<08:40, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4810/75212 [00:35<08:40, 135.32it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4824/75212 [00:35<08:40, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4838/75212 [00:35<08:40, 135.33it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4852/75212 [00:35<08:39, 135.34it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4866/75212 [00:36<08:39, 135.35it/s][A[A

Selecting Coreset Indices.:   6%|â–‹         | 4880/75212 [00:36<08:39, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4894/75212 [00:36<08:39, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4908/75212 [00:36<08:39, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4922/75212 [00:36<08:39, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4936/75212 [00:36<08:39, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4950/75212 [00:36<08:39, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4964/75212 [00:36<08:38, 135.36it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4978/75212 [00:36<08:38, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 4992/75212 [00:36<08:38, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5006/75212 [00:37<08:38, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5020/75212 [00:37<08:38, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5034/75212 [00:37<08:38, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5048/75212 [00:37<08:38, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5062/75212 [00:37<08:38, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5076/75212 [00:37<08:38, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5090/75212 [00:37<08:38, 135.32it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5104/75212 [00:37<08:38, 135.32it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5118/75212 [00:37<08:37, 135.32it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5132/75212 [00:37<08:37, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5146/75212 [00:38<08:37, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5160/75212 [00:38<08:37, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5174/75212 [00:38<08:37, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5188/75212 [00:38<08:37, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5202/75212 [00:38<08:37, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5216/75212 [00:38<08:37, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5230/75212 [00:38<08:37, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5244/75212 [00:38<08:36, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5258/75212 [00:38<08:36, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5272/75212 [00:39<08:36, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5286/75212 [00:39<08:36, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5300/75212 [00:39<08:36, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5314/75212 [00:39<08:36, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5328/75212 [00:39<08:36, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5342/75212 [00:39<08:36, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5356/75212 [00:39<08:36, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5370/75212 [00:39<08:35, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5384/75212 [00:39<08:35, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5398/75212 [00:39<08:35, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5412/75212 [00:40<08:35, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5426/75212 [00:40<08:35, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5440/75212 [00:40<08:35, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5454/75212 [00:40<08:35, 135.32it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5468/75212 [00:40<08:35, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5482/75212 [00:40<08:35, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5496/75212 [00:40<08:35, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5510/75212 [00:40<08:34, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5524/75212 [00:40<08:34, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5538/75212 [00:40<08:34, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5552/75212 [00:41<08:34, 135.35it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5566/75212 [00:41<08:34, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5580/75212 [00:41<08:34, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5594/75212 [00:41<08:34, 135.33it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5608/75212 [00:41<08:34, 135.32it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5622/75212 [00:41<08:34, 135.34it/s][A[A

Selecting Coreset Indices.:   7%|â–‹         | 5636/75212 [00:41<08:34, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5650/75212 [00:41<08:33, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5664/75212 [00:41<08:33, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5678/75212 [00:42<08:33, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5692/75212 [00:42<08:33, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5706/75212 [00:42<08:33, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5720/75212 [00:42<08:33, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5734/75212 [00:42<08:33, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5748/75212 [00:42<08:33, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5762/75212 [00:42<08:33, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5776/75212 [00:42<08:33, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5790/75212 [00:42<08:32, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5804/75212 [00:42<08:32, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5818/75212 [00:43<08:32, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5832/75212 [00:43<08:32, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5846/75212 [00:43<08:32, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5860/75212 [00:43<08:32, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5874/75212 [00:43<08:32, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5888/75212 [00:43<08:32, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5902/75212 [00:43<08:32, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5916/75212 [00:43<08:32, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5930/75212 [00:43<08:31, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5944/75212 [00:43<08:31, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5958/75212 [00:44<08:31, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5972/75212 [00:44<08:31, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 5986/75212 [00:44<08:31, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6000/75212 [00:44<08:31, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6014/75212 [00:44<08:31, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6028/75212 [00:44<08:31, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6042/75212 [00:44<08:31, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6056/75212 [00:44<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6070/75212 [00:44<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6084/75212 [00:45<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6098/75212 [00:45<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6112/75212 [00:45<08:30, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6126/75212 [00:45<08:30, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6140/75212 [00:45<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6154/75212 [00:45<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6168/75212 [00:45<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6182/75212 [00:45<08:30, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6196/75212 [00:45<08:29, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6210/75212 [00:45<08:29, 135.33it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6224/75212 [00:46<08:29, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6238/75212 [00:46<08:29, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6252/75212 [00:46<08:29, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6266/75212 [00:46<08:29, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6280/75212 [00:46<08:29, 135.36it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6294/75212 [00:46<08:29, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6308/75212 [00:46<08:29, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6322/75212 [00:46<08:28, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6336/75212 [00:46<08:28, 135.34it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6350/75212 [00:46<08:28, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6364/75212 [00:47<08:28, 135.36it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6378/75212 [00:47<08:28, 135.35it/s][A[A

Selecting Coreset Indices.:   8%|â–Š         | 6392/75212 [00:47<08:28, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6406/75212 [00:47<08:28, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6420/75212 [00:47<08:28, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6434/75212 [00:47<08:29, 135.06it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6448/75212 [00:47<08:28, 135.13it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6462/75212 [00:47<08:28, 135.18it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6476/75212 [00:47<08:28, 135.23it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6490/75212 [00:48<08:28, 135.27it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6504/75212 [00:48<08:27, 135.29it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6518/75212 [00:48<08:27, 135.31it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6532/75212 [00:48<08:27, 135.31it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6546/75212 [00:48<08:27, 135.32it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6560/75212 [00:48<08:27, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–Š         | 6574/75212 [00:48<08:27, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6588/75212 [00:48<08:26, 135.36it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6602/75212 [00:48<08:26, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6616/75212 [00:48<08:26, 135.36it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6630/75212 [00:49<08:26, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6644/75212 [00:49<08:26, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6658/75212 [00:49<08:26, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6672/75212 [00:49<08:26, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6686/75212 [00:49<08:26, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6700/75212 [00:49<08:26, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6714/75212 [00:49<08:26, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6728/75212 [00:49<08:26, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6742/75212 [00:49<08:25, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6756/75212 [00:49<08:25, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6770/75212 [00:50<08:25, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6784/75212 [00:50<08:25, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6798/75212 [00:50<08:25, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6812/75212 [00:50<08:25, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6826/75212 [00:50<08:25, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6840/75212 [00:50<08:25, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6854/75212 [00:50<08:25, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6868/75212 [00:50<08:24, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6882/75212 [00:50<08:24, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6896/75212 [00:51<08:24, 135.33it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6910/75212 [00:51<08:24, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6924/75212 [00:51<08:24, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6938/75212 [00:51<08:24, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6952/75212 [00:51<08:24, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6966/75212 [00:51<08:24, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6980/75212 [00:51<08:24, 135.35it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 6994/75212 [00:51<08:24, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7008/75212 [00:51<08:23, 135.33it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7022/75212 [00:51<08:23, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7036/75212 [00:52<08:23, 135.33it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7050/75212 [00:52<08:23, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7064/75212 [00:52<08:23, 135.34it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7078/75212 [00:52<08:23, 135.33it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7092/75212 [00:52<08:23, 135.33it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7106/75212 [00:52<08:23, 135.33it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7120/75212 [00:52<08:23, 135.32it/s][A[A

Selecting Coreset Indices.:   9%|â–‰         | 7134/75212 [00:52<08:23, 135.33it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7148/75212 [00:52<08:22, 135.33it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7162/75212 [00:52<08:22, 135.33it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7176/75212 [00:53<08:22, 135.32it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7190/75212 [00:53<08:22, 135.33it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7204/75212 [00:53<08:22, 135.33it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7218/75212 [00:53<08:22, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7232/75212 [00:53<08:22, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7246/75212 [00:53<08:22, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7260/75212 [00:53<08:22, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7274/75212 [00:53<08:21, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7288/75212 [00:53<08:21, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7302/75212 [00:54<08:21, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7316/75212 [00:54<08:21, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7330/75212 [00:54<08:21, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7344/75212 [00:54<08:21, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7358/75212 [00:54<08:21, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7372/75212 [00:54<08:21, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7386/75212 [00:54<08:21, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7400/75212 [00:54<08:20, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7414/75212 [00:54<08:20, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7428/75212 [00:54<08:20, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7442/75212 [00:55<08:20, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7456/75212 [00:55<08:20, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7470/75212 [00:55<08:20, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7484/75212 [00:55<08:20, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7498/75212 [00:55<08:20, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–‰         | 7512/75212 [00:55<08:25, 133.91it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7526/75212 [00:55<08:23, 134.32it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7540/75212 [00:55<08:22, 134.63it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7554/75212 [00:55<08:21, 134.85it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7568/75212 [00:55<08:21, 135.00it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7582/75212 [00:56<08:20, 135.10it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7596/75212 [00:56<08:20, 135.15it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7610/75212 [00:56<08:19, 135.22it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7624/75212 [00:56<08:19, 135.26it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7638/75212 [00:56<08:19, 135.28it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7652/75212 [00:56<08:19, 135.30it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7666/75212 [00:56<08:19, 135.32it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7680/75212 [00:56<08:19, 135.33it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7694/75212 [00:56<08:18, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7708/75212 [00:57<08:18, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7722/75212 [00:57<08:18, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7736/75212 [00:57<08:18, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7750/75212 [00:57<08:18, 135.32it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7764/75212 [00:57<08:18, 135.33it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7778/75212 [00:57<08:18, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7792/75212 [00:57<08:18, 135.34it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7806/75212 [00:57<08:18, 135.35it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7820/75212 [00:57<08:17, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7834/75212 [00:57<08:17, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7848/75212 [00:58<08:17, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7862/75212 [00:58<08:17, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7876/75212 [00:58<08:17, 135.36it/s][A[A

Selecting Coreset Indices.:  10%|â–ˆ         | 7890/75212 [00:58<08:17, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 7904/75212 [00:58<08:17, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 7918/75212 [00:58<08:17, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 7932/75212 [00:58<08:17, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 7946/75212 [00:58<08:16, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 7960/75212 [00:58<08:16, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 7974/75212 [00:58<08:16, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 7988/75212 [00:59<08:16, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8002/75212 [00:59<08:16, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8016/75212 [00:59<08:16, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8030/75212 [00:59<08:16, 135.36it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8044/75212 [00:59<08:16, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8058/75212 [00:59<08:20, 134.18it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8072/75212 [00:59<08:19, 134.52it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8086/75212 [00:59<08:18, 134.76it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8100/75212 [00:59<08:17, 134.93it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8114/75212 [01:00<08:16, 135.04it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8128/75212 [01:00<08:16, 135.12it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8142/75212 [01:00<08:16, 135.19it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8156/75212 [01:00<08:15, 135.24it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8170/75212 [01:00<08:15, 135.27it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8184/75212 [01:00<08:15, 135.28it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8198/75212 [01:00<08:15, 135.29it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8212/75212 [01:00<08:15, 135.31it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8226/75212 [01:00<08:14, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8240/75212 [01:00<08:14, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8254/75212 [01:01<08:14, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8268/75212 [01:01<08:14, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8282/75212 [01:01<08:14, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8296/75212 [01:01<08:14, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8310/75212 [01:01<08:14, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8324/75212 [01:01<08:14, 135.35it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8338/75212 [01:01<08:14, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8352/75212 [01:01<08:13, 135.36it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8366/75212 [01:01<08:13, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8380/75212 [01:01<08:13, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8394/75212 [01:02<08:13, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8408/75212 [01:02<08:13, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8422/75212 [01:02<08:13, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8436/75212 [01:02<08:13, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆ         | 8450/75212 [01:02<08:13, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8464/75212 [01:02<08:13, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8478/75212 [01:02<08:13, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8492/75212 [01:02<08:13, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8506/75212 [01:02<08:12, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8520/75212 [01:03<08:12, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8534/75212 [01:03<08:12, 135.34it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8548/75212 [01:03<08:12, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8562/75212 [01:03<08:12, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8576/75212 [01:03<08:12, 135.33it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8590/75212 [01:03<08:18, 133.72it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8604/75212 [01:03<08:16, 134.16it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8618/75212 [01:03<08:15, 134.51it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8632/75212 [01:03<08:14, 134.76it/s][A[A

Selecting Coreset Indices.:  11%|â–ˆâ–        | 8646/75212 [01:03<08:13, 134.93it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8660/75212 [01:04<08:12, 135.05it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8674/75212 [01:04<08:12, 135.14it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8688/75212 [01:04<08:12, 135.20it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8702/75212 [01:04<08:11, 135.24it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8716/75212 [01:04<08:11, 135.26it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8730/75212 [01:04<08:11, 135.29it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8744/75212 [01:04<08:11, 135.31it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8758/75212 [01:04<08:11, 135.31it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8772/75212 [01:04<08:10, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8786/75212 [01:04<08:10, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8800/75212 [01:05<08:10, 135.32it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8814/75212 [01:05<08:10, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8828/75212 [01:05<08:10, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8842/75212 [01:05<08:10, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8856/75212 [01:05<08:10, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8870/75212 [01:05<08:10, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8884/75212 [01:05<08:10, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8898/75212 [01:05<08:09, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8912/75212 [01:05<08:09, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8926/75212 [01:06<08:09, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8940/75212 [01:06<08:09, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8954/75212 [01:06<08:09, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8968/75212 [01:06<08:09, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8982/75212 [01:06<08:09, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 8996/75212 [01:06<08:09, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9010/75212 [01:06<08:09, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9024/75212 [01:06<08:09, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9038/75212 [01:06<08:08, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9052/75212 [01:06<08:08, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9066/75212 [01:07<08:08, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9080/75212 [01:07<08:08, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9094/75212 [01:07<08:08, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9108/75212 [01:07<08:08, 135.36it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9122/75212 [01:07<08:08, 135.36it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9136/75212 [01:07<08:08, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9150/75212 [01:07<08:08, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9164/75212 [01:07<08:07, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9178/75212 [01:07<08:07, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9192/75212 [01:07<08:07, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9206/75212 [01:08<08:07, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9220/75212 [01:08<08:07, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9234/75212 [01:08<08:07, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9248/75212 [01:08<08:07, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9262/75212 [01:08<08:07, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9276/75212 [01:08<08:07, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9290/75212 [01:08<08:07, 135.33it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9304/75212 [01:08<08:06, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9318/75212 [01:08<08:06, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9332/75212 [01:09<08:06, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9346/75212 [01:09<08:06, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9360/75212 [01:09<08:06, 135.34it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9374/75212 [01:09<08:06, 135.35it/s][A[A

Selecting Coreset Indices.:  12%|â–ˆâ–        | 9388/75212 [01:09<08:06, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9402/75212 [01:09<08:06, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9416/75212 [01:09<08:06, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9430/75212 [01:09<08:06, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9444/75212 [01:09<08:05, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9458/75212 [01:09<08:05, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9472/75212 [01:10<08:05, 135.33it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9486/75212 [01:10<08:05, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9500/75212 [01:10<08:05, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9514/75212 [01:10<08:05, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9528/75212 [01:10<08:05, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9542/75212 [01:10<08:05, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9556/75212 [01:10<08:05, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9570/75212 [01:10<08:05, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9584/75212 [01:10<08:04, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9598/75212 [01:10<08:04, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9612/75212 [01:11<08:04, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9626/75212 [01:11<08:04, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9640/75212 [01:11<08:04, 135.33it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9654/75212 [01:11<08:04, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9668/75212 [01:11<08:04, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9682/75212 [01:11<08:04, 135.33it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9696/75212 [01:11<08:04, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9710/75212 [01:11<08:03, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9724/75212 [01:11<08:03, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9738/75212 [01:12<08:03, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9752/75212 [01:12<08:03, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9766/75212 [01:12<08:03, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9780/75212 [01:12<08:03, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9794/75212 [01:12<08:03, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9808/75212 [01:12<08:03, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9822/75212 [01:12<08:03, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9836/75212 [01:12<08:03, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9850/75212 [01:12<08:02, 135.33it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9864/75212 [01:12<08:02, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9878/75212 [01:13<08:02, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9892/75212 [01:13<08:02, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9906/75212 [01:13<08:02, 135.33it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9920/75212 [01:13<08:02, 135.33it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9934/75212 [01:13<08:02, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9948/75212 [01:13<08:02, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9962/75212 [01:13<08:02, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9976/75212 [01:13<08:02, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 9990/75212 [01:13<08:01, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10004/75212 [01:13<08:01, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10018/75212 [01:14<08:01, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10032/75212 [01:14<08:01, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10046/75212 [01:14<08:01, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10060/75212 [01:14<08:01, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10074/75212 [01:14<08:01, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10088/75212 [01:14<08:01, 135.35it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10102/75212 [01:14<08:01, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10116/75212 [01:14<08:00, 135.34it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10130/75212 [01:14<08:00, 135.33it/s][A[A

Selecting Coreset Indices.:  13%|â–ˆâ–Ž        | 10144/75212 [01:15<08:00, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10158/75212 [01:15<08:00, 135.32it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10172/75212 [01:15<08:00, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10186/75212 [01:15<08:00, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10200/75212 [01:15<08:00, 135.36it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10214/75212 [01:15<08:00, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10228/75212 [01:15<08:00, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10242/75212 [01:15<07:59, 135.36it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10256/75212 [01:15<07:59, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10270/75212 [01:15<07:59, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10284/75212 [01:16<07:59, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10298/75212 [01:16<07:59, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10312/75212 [01:16<07:59, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10326/75212 [01:16<07:59, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–Ž        | 10340/75212 [01:16<07:59, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10354/75212 [01:16<07:59, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10368/75212 [01:16<07:59, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10382/75212 [01:16<07:58, 135.37it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10396/75212 [01:16<07:58, 135.37it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10410/75212 [01:16<07:58, 135.36it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10424/75212 [01:17<07:58, 135.36it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10438/75212 [01:17<07:58, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10452/75212 [01:17<07:58, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10466/75212 [01:17<07:58, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10480/75212 [01:17<07:58, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10494/75212 [01:17<07:58, 135.36it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10508/75212 [01:17<07:58, 135.36it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10522/75212 [01:17<07:57, 135.36it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10536/75212 [01:17<07:57, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10550/75212 [01:18<07:57, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10564/75212 [01:18<07:57, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10578/75212 [01:18<07:57, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10592/75212 [01:18<07:57, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10606/75212 [01:18<07:57, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10620/75212 [01:18<07:57, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10634/75212 [01:18<07:57, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10648/75212 [01:18<07:57, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10662/75212 [01:18<07:56, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10676/75212 [01:18<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10690/75212 [01:19<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10704/75212 [01:19<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10718/75212 [01:19<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10732/75212 [01:19<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10746/75212 [01:19<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10760/75212 [01:19<07:56, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10774/75212 [01:19<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10788/75212 [01:19<07:56, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10802/75212 [01:19<07:55, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10816/75212 [01:19<07:55, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10830/75212 [01:20<07:55, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10844/75212 [01:20<07:55, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10858/75212 [01:20<07:55, 135.34it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10872/75212 [01:20<07:55, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10886/75212 [01:20<07:55, 135.35it/s][A[A

Selecting Coreset Indices.:  14%|â–ˆâ–        | 10900/75212 [01:20<07:55, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 10914/75212 [01:20<07:55, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 10928/75212 [01:20<07:54, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 10942/75212 [01:20<07:54, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 10956/75212 [01:21<07:54, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 10970/75212 [01:21<07:54, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 10984/75212 [01:21<07:54, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 10998/75212 [01:21<07:54, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11012/75212 [01:21<07:54, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11026/75212 [01:21<07:54, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11040/75212 [01:21<07:54, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11054/75212 [01:21<07:54, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11068/75212 [01:21<07:53, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11082/75212 [01:21<07:53, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11096/75212 [01:22<07:53, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11110/75212 [01:22<07:53, 135.32it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11124/75212 [01:22<07:53, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11138/75212 [01:22<07:53, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11152/75212 [01:22<07:53, 135.32it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11166/75212 [01:22<07:53, 135.32it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11180/75212 [01:22<07:53, 135.32it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11194/75212 [01:22<07:53, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11208/75212 [01:22<07:52, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11222/75212 [01:22<07:52, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11236/75212 [01:23<07:52, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11250/75212 [01:23<07:52, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11264/75212 [01:23<07:52, 135.32it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–        | 11278/75212 [01:23<07:52, 135.32it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11292/75212 [01:23<07:52, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11306/75212 [01:23<07:52, 135.33it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11320/75212 [01:23<07:52, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11334/75212 [01:23<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11348/75212 [01:23<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11362/75212 [01:24<07:51, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11376/75212 [01:24<07:51, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11390/75212 [01:24<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11404/75212 [01:24<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11418/75212 [01:24<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11432/75212 [01:24<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11446/75212 [01:24<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11460/75212 [01:24<07:51, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11474/75212 [01:24<07:50, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11488/75212 [01:24<07:50, 135.34it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11502/75212 [01:25<07:50, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11516/75212 [01:25<07:50, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11530/75212 [01:25<07:50, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11544/75212 [01:25<07:50, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11558/75212 [01:25<07:50, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11572/75212 [01:25<07:50, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11586/75212 [01:25<07:50, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11600/75212 [01:25<07:49, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11614/75212 [01:25<07:49, 135.35it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11628/75212 [01:25<07:49, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11642/75212 [01:26<07:49, 135.36it/s][A[A

Selecting Coreset Indices.:  15%|â–ˆâ–Œ        | 11656/75212 [01:26<07:49, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11670/75212 [01:26<07:49, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11684/75212 [01:26<07:49, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11698/75212 [01:26<07:49, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11712/75212 [01:26<07:49, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11726/75212 [01:26<07:49, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11740/75212 [01:26<07:48, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11754/75212 [01:26<07:48, 135.37it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11768/75212 [01:27<07:48, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11782/75212 [01:27<07:48, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11796/75212 [01:27<07:48, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11810/75212 [01:27<07:48, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11824/75212 [01:27<07:48, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11838/75212 [01:27<07:48, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11852/75212 [01:27<07:48, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11866/75212 [01:27<07:48, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11880/75212 [01:27<07:47, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11894/75212 [01:27<07:47, 135.37it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11908/75212 [01:28<07:47, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11922/75212 [01:28<07:47, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11936/75212 [01:28<07:47, 135.33it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11950/75212 [01:28<07:47, 135.33it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11964/75212 [01:28<07:47, 135.33it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11978/75212 [01:28<07:47, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 11992/75212 [01:28<07:47, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12006/75212 [01:28<07:47, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12020/75212 [01:28<07:46, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12034/75212 [01:28<07:46, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12048/75212 [01:29<07:46, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12062/75212 [01:29<07:46, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12076/75212 [01:29<07:46, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12090/75212 [01:29<07:46, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12104/75212 [01:29<07:46, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12118/75212 [01:29<07:46, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12132/75212 [01:29<07:46, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12146/75212 [01:29<07:45, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12160/75212 [01:29<07:45, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12174/75212 [01:30<07:45, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12188/75212 [01:30<07:45, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12202/75212 [01:30<07:45, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–Œ        | 12216/75212 [01:30<07:45, 135.34it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12230/75212 [01:30<07:45, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12244/75212 [01:30<07:45, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12258/75212 [01:30<07:45, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12272/75212 [01:30<07:44, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12286/75212 [01:30<07:44, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12300/75212 [01:30<07:44, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12314/75212 [01:31<07:44, 135.36it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12328/75212 [01:31<07:44, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12342/75212 [01:31<07:44, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12356/75212 [01:31<07:44, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12370/75212 [01:31<07:44, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12384/75212 [01:31<07:44, 135.35it/s][A[A

Selecting Coreset Indices.:  16%|â–ˆâ–‹        | 12398/75212 [01:31<07:44, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12412/75212 [01:31<07:43, 135.36it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12426/75212 [01:31<07:43, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12440/75212 [01:31<07:43, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12454/75212 [01:32<07:43, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12468/75212 [01:32<07:43, 135.36it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12482/75212 [01:32<07:43, 135.36it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12496/75212 [01:32<07:43, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12510/75212 [01:32<07:43, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12524/75212 [01:32<07:43, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12538/75212 [01:32<07:43, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12552/75212 [01:32<07:42, 135.36it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12566/75212 [01:32<07:42, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12580/75212 [01:33<07:42, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12594/75212 [01:33<07:42, 135.33it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12608/75212 [01:33<07:42, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12622/75212 [01:33<07:42, 135.33it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12636/75212 [01:33<07:42, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12650/75212 [01:33<07:42, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12664/75212 [01:33<07:42, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12678/75212 [01:33<07:42, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12692/75212 [01:33<07:41, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12706/75212 [01:33<07:41, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12720/75212 [01:34<07:41, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12734/75212 [01:34<07:41, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12748/75212 [01:34<07:41, 135.36it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12762/75212 [01:34<07:41, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12776/75212 [01:34<07:41, 135.36it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12790/75212 [01:34<07:41, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12804/75212 [01:34<07:41, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12818/75212 [01:34<07:40, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12832/75212 [01:34<07:40, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12846/75212 [01:34<07:40, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12860/75212 [01:35<07:40, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12874/75212 [01:35<07:40, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12888/75212 [01:35<07:40, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12902/75212 [01:35<07:40, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12916/75212 [01:35<07:40, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12930/75212 [01:35<07:40, 135.33it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12944/75212 [01:35<07:40, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12958/75212 [01:35<07:40, 135.33it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12972/75212 [01:35<07:39, 135.31it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 12986/75212 [01:36<07:39, 135.32it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13000/75212 [01:36<07:39, 135.33it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13014/75212 [01:36<07:39, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13028/75212 [01:36<07:39, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13042/75212 [01:36<07:39, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13056/75212 [01:36<07:39, 135.33it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13070/75212 [01:36<07:39, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13084/75212 [01:36<07:39, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13098/75212 [01:36<07:38, 135.34it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13112/75212 [01:36<07:38, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13126/75212 [01:37<07:38, 135.35it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13140/75212 [01:37<07:38, 135.36it/s][A[A

Selecting Coreset Indices.:  17%|â–ˆâ–‹        | 13154/75212 [01:37<07:38, 135.37it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13168/75212 [01:37<07:38, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13182/75212 [01:37<07:38, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13196/75212 [01:37<07:38, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13210/75212 [01:37<07:38, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13224/75212 [01:37<07:38, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13238/75212 [01:37<07:37, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13252/75212 [01:37<07:37, 135.33it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13266/75212 [01:38<07:37, 135.33it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13280/75212 [01:38<07:37, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13294/75212 [01:38<07:37, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13308/75212 [01:38<07:37, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13322/75212 [01:38<07:37, 135.33it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13336/75212 [01:38<07:37, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13350/75212 [01:38<07:37, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13364/75212 [01:38<07:36, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13378/75212 [01:38<07:36, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13392/75212 [01:39<07:36, 135.36it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13406/75212 [01:39<07:36, 135.36it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13420/75212 [01:39<07:36, 135.36it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13434/75212 [01:39<07:36, 135.36it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13448/75212 [01:39<07:36, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13462/75212 [01:39<07:36, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13476/75212 [01:39<07:36, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13490/75212 [01:39<07:36, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13504/75212 [01:39<07:35, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13518/75212 [01:39<07:35, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13532/75212 [01:40<07:35, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13546/75212 [01:40<07:35, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13560/75212 [01:40<07:35, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13574/75212 [01:40<07:35, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13588/75212 [01:40<07:35, 135.36it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13602/75212 [01:40<07:35, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13616/75212 [01:40<07:35, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13630/75212 [01:40<07:35, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13644/75212 [01:40<07:34, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13658/75212 [01:40<07:34, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13672/75212 [01:41<07:34, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13686/75212 [01:41<07:34, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13700/75212 [01:41<07:34, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13714/75212 [01:41<07:34, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13728/75212 [01:41<07:34, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13742/75212 [01:41<07:34, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13756/75212 [01:41<07:34, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13770/75212 [01:41<07:33, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13784/75212 [01:41<07:33, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13798/75212 [01:42<07:33, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13812/75212 [01:42<07:33, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13826/75212 [01:42<07:33, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13840/75212 [01:42<07:33, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13854/75212 [01:42<07:33, 135.35it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13868/75212 [01:42<07:33, 135.34it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13882/75212 [01:42<07:33, 135.33it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13896/75212 [01:42<07:33, 135.33it/s][A[A

Selecting Coreset Indices.:  18%|â–ˆâ–Š        | 13910/75212 [01:42<07:32, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 13924/75212 [01:42<07:32, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 13938/75212 [01:43<07:32, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 13952/75212 [01:43<07:32, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 13966/75212 [01:43<07:32, 135.33it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 13980/75212 [01:43<07:32, 135.33it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 13994/75212 [01:43<07:32, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 14008/75212 [01:43<07:32, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 14022/75212 [01:43<07:32, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 14036/75212 [01:43<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 14050/75212 [01:43<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 14064/75212 [01:43<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 14078/75212 [01:44<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–Š        | 14092/75212 [01:44<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14106/75212 [01:44<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14120/75212 [01:44<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14134/75212 [01:44<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14148/75212 [01:44<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14162/75212 [01:44<07:31, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14176/75212 [01:44<07:30, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14190/75212 [01:44<07:30, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14204/75212 [01:45<07:30, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14218/75212 [01:45<07:30, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14232/75212 [01:45<07:30, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14246/75212 [01:45<07:30, 135.36it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14260/75212 [01:45<07:30, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14274/75212 [01:45<07:30, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14288/75212 [01:45<07:30, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14302/75212 [01:45<07:30, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14316/75212 [01:45<07:29, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14330/75212 [01:45<07:29, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14344/75212 [01:46<07:29, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14358/75212 [01:46<07:29, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14372/75212 [01:46<07:29, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14386/75212 [01:46<07:29, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14400/75212 [01:46<07:29, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14414/75212 [01:46<07:29, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14428/75212 [01:46<07:29, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14442/75212 [01:46<07:28, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14456/75212 [01:46<07:28, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14470/75212 [01:46<07:28, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14484/75212 [01:47<07:28, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14498/75212 [01:47<07:28, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14512/75212 [01:47<07:28, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14526/75212 [01:47<07:28, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14540/75212 [01:47<07:28, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14554/75212 [01:47<07:28, 135.33it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14568/75212 [01:47<07:28, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14582/75212 [01:47<07:27, 135.34it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14596/75212 [01:47<07:27, 135.35it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14610/75212 [01:48<07:27, 135.36it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14624/75212 [01:48<07:27, 135.36it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14638/75212 [01:48<07:27, 135.36it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14652/75212 [01:48<07:27, 135.36it/s][A[A

Selecting Coreset Indices.:  19%|â–ˆâ–‰        | 14666/75212 [01:48<07:27, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14680/75212 [01:48<07:27, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14694/75212 [01:48<07:27, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14708/75212 [01:48<07:27, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14722/75212 [01:48<07:26, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14736/75212 [01:48<07:26, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14750/75212 [01:49<07:26, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14764/75212 [01:49<07:26, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14778/75212 [01:49<07:26, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14792/75212 [01:49<07:26, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14806/75212 [01:49<07:26, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14820/75212 [01:49<07:26, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14834/75212 [01:49<07:26, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14848/75212 [01:49<07:26, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14862/75212 [01:49<07:25, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14876/75212 [01:49<07:25, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14890/75212 [01:50<07:25, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14904/75212 [01:50<07:25, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14918/75212 [01:50<07:25, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14932/75212 [01:50<07:25, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14946/75212 [01:50<07:25, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14960/75212 [01:50<07:25, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14974/75212 [01:50<07:25, 135.36it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 14988/75212 [01:50<07:24, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 15002/75212 [01:50<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 15016/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–‰        | 15030/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15044/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15058/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15072/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15086/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15100/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15114/75212 [01:51<07:24, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15128/75212 [01:51<07:25, 134.75it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15142/75212 [01:51<07:25, 134.91it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15156/75212 [01:52<07:24, 135.05it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15170/75212 [01:52<07:24, 135.14it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15184/75212 [01:52<07:24, 135.20it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15198/75212 [01:52<07:23, 135.24it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15212/75212 [01:52<07:23, 135.28it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15226/75212 [01:52<07:23, 135.30it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15240/75212 [01:52<07:23, 135.32it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15254/75212 [01:52<07:23, 135.32it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15268/75212 [01:52<07:22, 135.33it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15282/75212 [01:52<07:22, 135.33it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15296/75212 [01:53<07:22, 135.34it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15310/75212 [01:53<07:22, 135.33it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15324/75212 [01:53<07:22, 135.33it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15338/75212 [01:53<07:22, 135.33it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15352/75212 [01:53<07:22, 135.31it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15366/75212 [01:53<07:22, 135.33it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15380/75212 [01:53<07:22, 135.35it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15394/75212 [01:53<07:21, 135.36it/s][A[A

Selecting Coreset Indices.:  20%|â–ˆâ–ˆ        | 15408/75212 [01:53<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15422/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15436/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15450/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15464/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15478/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15492/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15506/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15520/75212 [01:54<07:21, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15534/75212 [01:54<07:20, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15548/75212 [01:54<07:20, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15562/75212 [01:55<07:20, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15576/75212 [01:55<07:20, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15590/75212 [01:55<07:20, 135.34it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15604/75212 [01:55<07:20, 135.33it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15618/75212 [01:55<07:20, 135.34it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15632/75212 [01:55<07:20, 135.34it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15646/75212 [01:55<07:20, 135.34it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15660/75212 [01:55<07:19, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15674/75212 [01:55<07:19, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15688/75212 [01:55<07:19, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15702/75212 [01:56<07:19, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15716/75212 [01:56<07:19, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15730/75212 [01:56<07:19, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15744/75212 [01:56<07:19, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15758/75212 [01:56<07:19, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15772/75212 [01:56<07:19, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15786/75212 [01:56<07:19, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15800/75212 [01:56<07:18, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15814/75212 [01:56<07:18, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15828/75212 [01:57<07:18, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15842/75212 [01:57<07:18, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15856/75212 [01:57<07:18, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15870/75212 [01:57<07:18, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15884/75212 [01:57<07:18, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15898/75212 [01:57<07:18, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15912/75212 [01:57<07:18, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15926/75212 [01:57<07:18, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15940/75212 [01:57<07:17, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15954/75212 [01:57<07:17, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15968/75212 [01:58<07:17, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆ        | 15982/75212 [01:58<07:17, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 15996/75212 [01:58<07:17, 135.37it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16010/75212 [01:58<07:17, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16024/75212 [01:58<07:17, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16038/75212 [01:58<07:17, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16052/75212 [01:58<07:17, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16066/75212 [01:58<07:16, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16080/75212 [01:58<07:16, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16094/75212 [01:58<07:16, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16108/75212 [01:59<07:16, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16122/75212 [01:59<07:16, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16136/75212 [01:59<07:16, 135.35it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16150/75212 [01:59<07:16, 135.36it/s][A[A

Selecting Coreset Indices.:  21%|â–ˆâ–ˆâ–       | 16164/75212 [01:59<07:16, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16178/75212 [01:59<07:16, 135.36it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16192/75212 [01:59<07:16, 135.36it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16206/75212 [01:59<07:19, 134.28it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16220/75212 [01:59<07:18, 134.58it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16234/75212 [02:00<07:17, 134.80it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16248/75212 [02:00<07:16, 134.97it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16262/75212 [02:00<07:16, 135.09it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16276/75212 [02:00<07:16, 135.16it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16290/75212 [02:00<07:15, 135.22it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16304/75212 [02:00<07:15, 135.26it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16318/75212 [02:00<07:15, 135.30it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16332/75212 [02:00<07:15, 135.32it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16346/75212 [02:00<07:14, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16360/75212 [02:00<07:14, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16374/75212 [02:01<07:14, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16388/75212 [02:01<07:14, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16402/75212 [02:01<07:14, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16416/75212 [02:01<07:14, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16430/75212 [02:01<07:14, 135.33it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16444/75212 [02:01<07:14, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16458/75212 [02:01<07:14, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16472/75212 [02:01<07:13, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16486/75212 [02:01<07:13, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16500/75212 [02:01<07:13, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16514/75212 [02:02<07:13, 135.36it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16528/75212 [02:02<07:13, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16542/75212 [02:02<07:13, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16556/75212 [02:02<07:13, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16570/75212 [02:02<07:13, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16584/75212 [02:02<07:13, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16598/75212 [02:02<07:13, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16612/75212 [02:02<07:12, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16626/75212 [02:02<07:12, 135.36it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16640/75212 [02:03<07:12, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16654/75212 [02:03<07:12, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16668/75212 [02:03<07:12, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16682/75212 [02:03<07:12, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16696/75212 [02:03<07:12, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16710/75212 [02:03<07:12, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16724/75212 [02:03<07:12, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16738/75212 [02:03<07:12, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16752/75212 [02:03<07:11, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16766/75212 [02:03<07:11, 135.36it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16780/75212 [02:04<07:11, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16794/75212 [02:04<07:11, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16808/75212 [02:04<07:11, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16822/75212 [02:04<07:11, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16836/75212 [02:04<07:11, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16850/75212 [02:04<07:11, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16864/75212 [02:04<07:11, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16878/75212 [02:04<07:11, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16892/75212 [02:04<07:10, 135.34it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16906/75212 [02:04<07:10, 135.35it/s][A[A

Selecting Coreset Indices.:  22%|â–ˆâ–ˆâ–       | 16920/75212 [02:05<07:10, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 16934/75212 [02:05<07:10, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 16948/75212 [02:05<07:10, 135.37it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 16962/75212 [02:05<07:10, 135.37it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 16976/75212 [02:05<07:10, 135.37it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 16990/75212 [02:05<07:10, 135.38it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17004/75212 [02:05<07:10, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17018/75212 [02:05<07:09, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17032/75212 [02:05<07:09, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17046/75212 [02:06<07:09, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17060/75212 [02:06<07:09, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17074/75212 [02:06<07:09, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17088/75212 [02:06<07:09, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17102/75212 [02:06<07:09, 135.37it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17116/75212 [02:06<07:09, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17130/75212 [02:06<07:09, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17144/75212 [02:06<07:09, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17158/75212 [02:06<07:08, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17172/75212 [02:06<07:08, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17186/75212 [02:07<07:08, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17200/75212 [02:07<07:08, 135.37it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17214/75212 [02:07<07:08, 135.37it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17228/75212 [02:07<07:08, 135.38it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17242/75212 [02:07<07:08, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17256/75212 [02:07<07:08, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17270/75212 [02:07<07:08, 135.36it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17284/75212 [02:07<07:13, 133.74it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17298/75212 [02:07<07:11, 134.17it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17312/75212 [02:07<07:10, 134.51it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17326/75212 [02:08<07:09, 134.75it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17340/75212 [02:08<07:08, 134.93it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17354/75212 [02:08<07:08, 135.05it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17368/75212 [02:08<07:08, 135.14it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17382/75212 [02:08<07:07, 135.21it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17396/75212 [02:08<07:07, 135.25it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17410/75212 [02:08<07:07, 135.26it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17424/75212 [02:08<07:07, 135.28it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17438/75212 [02:08<07:07, 135.29it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17452/75212 [02:09<07:06, 135.30it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17466/75212 [02:09<07:06, 135.31it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17480/75212 [02:09<07:06, 135.33it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17494/75212 [02:09<07:06, 135.33it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17508/75212 [02:09<07:06, 135.34it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17522/75212 [02:09<07:06, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17536/75212 [02:09<07:06, 135.34it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17550/75212 [02:09<07:06, 135.34it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17564/75212 [02:09<07:05, 135.34it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17578/75212 [02:09<07:05, 135.34it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17592/75212 [02:10<07:05, 135.34it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17606/75212 [02:10<07:05, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17620/75212 [02:10<07:05, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17634/75212 [02:10<07:05, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17648/75212 [02:10<07:05, 135.35it/s][A[A

Selecting Coreset Indices.:  23%|â–ˆâ–ˆâ–Ž       | 17662/75212 [02:10<07:05, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17676/75212 [02:10<07:05, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17690/75212 [02:10<07:04, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17704/75212 [02:10<07:04, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17718/75212 [02:10<07:04, 135.37it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17732/75212 [02:11<07:04, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17746/75212 [02:11<07:04, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17760/75212 [02:11<07:04, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17774/75212 [02:11<07:04, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17788/75212 [02:11<07:04, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17802/75212 [02:11<07:04, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17816/75212 [02:11<07:04, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17830/75212 [02:11<07:03, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17844/75212 [02:11<07:03, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–Ž       | 17858/75212 [02:12<07:03, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17872/75212 [02:12<07:03, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17886/75212 [02:12<07:03, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17900/75212 [02:12<07:03, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17914/75212 [02:12<07:03, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17928/75212 [02:12<07:03, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17942/75212 [02:12<07:03, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17956/75212 [02:12<07:03, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17970/75212 [02:12<07:02, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17984/75212 [02:12<07:02, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 17998/75212 [02:13<07:02, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18012/75212 [02:13<07:02, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18026/75212 [02:13<07:02, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18040/75212 [02:13<07:02, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18054/75212 [02:13<07:02, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18068/75212 [02:13<07:02, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18082/75212 [02:13<07:02, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18096/75212 [02:13<07:01, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18110/75212 [02:13<07:01, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18124/75212 [02:13<07:01, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18138/75212 [02:14<07:01, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18152/75212 [02:14<07:01, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18166/75212 [02:14<07:01, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18180/75212 [02:14<07:01, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18194/75212 [02:14<07:01, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18208/75212 [02:14<07:01, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18222/75212 [02:14<07:01, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18236/75212 [02:14<07:00, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18250/75212 [02:14<07:00, 135.33it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18264/75212 [02:15<07:00, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18278/75212 [02:15<07:00, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18292/75212 [02:15<07:00, 135.36it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18306/75212 [02:15<07:00, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18320/75212 [02:15<07:00, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18334/75212 [02:15<07:00, 135.33it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18348/75212 [02:15<07:00, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18362/75212 [02:15<07:00, 135.34it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18376/75212 [02:15<06:59, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18390/75212 [02:15<06:59, 135.35it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18404/75212 [02:16<06:59, 135.33it/s][A[A

Selecting Coreset Indices.:  24%|â–ˆâ–ˆâ–       | 18418/75212 [02:16<06:59, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18432/75212 [02:16<06:59, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18446/75212 [02:16<06:59, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18460/75212 [02:16<06:59, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18474/75212 [02:16<06:59, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18488/75212 [02:16<06:59, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18502/75212 [02:16<06:58, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18516/75212 [02:16<06:58, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18530/75212 [02:16<06:58, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18544/75212 [02:17<06:58, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18558/75212 [02:17<06:58, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18572/75212 [02:17<06:58, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18586/75212 [02:17<06:58, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18600/75212 [02:17<06:58, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18614/75212 [02:17<06:58, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18628/75212 [02:17<06:58, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18642/75212 [02:17<06:57, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18656/75212 [02:17<06:57, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18670/75212 [02:18<06:57, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18684/75212 [02:18<06:57, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18698/75212 [02:18<06:57, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18712/75212 [02:18<06:57, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18726/75212 [02:18<06:57, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18740/75212 [02:18<06:57, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18754/75212 [02:18<06:57, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18768/75212 [02:18<06:56, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18782/75212 [02:18<06:56, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–       | 18796/75212 [02:18<06:56, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18810/75212 [02:19<06:56, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18824/75212 [02:19<06:56, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18838/75212 [02:19<06:56, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18852/75212 [02:19<06:56, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18866/75212 [02:19<06:56, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18880/75212 [02:19<06:56, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18894/75212 [02:19<06:56, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18908/75212 [02:19<06:55, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18922/75212 [02:19<06:55, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18936/75212 [02:19<06:55, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18950/75212 [02:20<06:55, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18964/75212 [02:20<06:55, 135.33it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18978/75212 [02:20<06:55, 135.33it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 18992/75212 [02:20<06:55, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19006/75212 [02:20<06:55, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19020/75212 [02:20<06:55, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19034/75212 [02:20<06:55, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19048/75212 [02:20<06:54, 135.37it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19062/75212 [02:20<06:54, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19076/75212 [02:21<06:54, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19090/75212 [02:21<06:54, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19104/75212 [02:21<06:54, 135.36it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19118/75212 [02:21<06:54, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19132/75212 [02:21<06:54, 135.35it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19146/75212 [02:21<06:54, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19160/75212 [02:21<06:54, 135.34it/s][A[A

Selecting Coreset Indices.:  25%|â–ˆâ–ˆâ–Œ       | 19174/75212 [02:21<06:54, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19188/75212 [02:21<06:53, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19202/75212 [02:21<06:53, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19216/75212 [02:22<06:53, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19230/75212 [02:22<06:53, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19244/75212 [02:22<06:53, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19258/75212 [02:22<06:53, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19272/75212 [02:22<06:53, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19286/75212 [02:22<06:53, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19300/75212 [02:22<06:53, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19314/75212 [02:22<06:52, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19328/75212 [02:22<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19342/75212 [02:22<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19356/75212 [02:23<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19370/75212 [02:23<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19384/75212 [02:23<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19398/75212 [02:23<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19412/75212 [02:23<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19426/75212 [02:23<06:52, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19440/75212 [02:23<06:52, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19454/75212 [02:23<06:51, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19468/75212 [02:23<06:51, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19482/75212 [02:24<06:51, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19496/75212 [02:24<06:51, 135.33it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19510/75212 [02:24<06:51, 135.33it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19524/75212 [02:24<06:51, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19538/75212 [02:24<06:51, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19552/75212 [02:24<06:51, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19566/75212 [02:24<06:51, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19580/75212 [02:24<06:51, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19594/75212 [02:24<06:50, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19608/75212 [02:24<06:50, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19622/75212 [02:25<06:50, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19636/75212 [02:25<06:50, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19650/75212 [02:25<06:50, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19664/75212 [02:25<06:50, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19678/75212 [02:25<06:50, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19692/75212 [02:25<06:50, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19706/75212 [02:25<06:50, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19720/75212 [02:25<06:50, 135.34it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–Œ       | 19734/75212 [02:25<06:49, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19748/75212 [02:25<06:49, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19762/75212 [02:26<06:49, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19776/75212 [02:26<06:49, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19790/75212 [02:26<06:49, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19804/75212 [02:26<06:49, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19818/75212 [02:26<06:49, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19832/75212 [02:26<06:49, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19846/75212 [02:26<06:49, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19860/75212 [02:26<06:48, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19874/75212 [02:26<06:48, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19888/75212 [02:27<06:48, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19902/75212 [02:27<06:48, 135.35it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19916/75212 [02:27<06:48, 135.36it/s][A[A

Selecting Coreset Indices.:  26%|â–ˆâ–ˆâ–‹       | 19930/75212 [02:27<06:48, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 19944/75212 [02:27<06:48, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 19958/75212 [02:27<06:48, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 19972/75212 [02:27<06:48, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 19986/75212 [02:27<06:47, 135.37it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20000/75212 [02:27<06:47, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20014/75212 [02:27<06:47, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20028/75212 [02:28<06:47, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20042/75212 [02:28<06:47, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20056/75212 [02:28<06:47, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20070/75212 [02:28<06:47, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20084/75212 [02:28<06:47, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20098/75212 [02:28<06:47, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20112/75212 [02:28<06:47, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20126/75212 [02:28<06:46, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20140/75212 [02:28<06:46, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20154/75212 [02:28<06:46, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20168/75212 [02:29<06:46, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20182/75212 [02:29<06:46, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20196/75212 [02:29<06:46, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20210/75212 [02:29<06:46, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20224/75212 [02:29<06:46, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20238/75212 [02:29<06:46, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20252/75212 [02:29<06:46, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20266/75212 [02:29<06:45, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20280/75212 [02:29<06:45, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20294/75212 [02:30<06:45, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20308/75212 [02:30<06:45, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20322/75212 [02:30<06:45, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20336/75212 [02:30<06:45, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20350/75212 [02:30<06:45, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20364/75212 [02:30<06:45, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20378/75212 [02:30<06:45, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20392/75212 [02:30<06:45, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20406/75212 [02:30<06:44, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20420/75212 [02:30<06:44, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20434/75212 [02:31<06:44, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20448/75212 [02:31<06:44, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20462/75212 [02:31<06:44, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20476/75212 [02:31<06:44, 135.33it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20490/75212 [02:31<06:44, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20504/75212 [02:31<06:44, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20518/75212 [02:31<06:44, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20532/75212 [02:31<06:43, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20546/75212 [02:31<06:43, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20560/75212 [02:31<06:43, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20574/75212 [02:32<06:43, 135.35it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20588/75212 [02:32<06:43, 135.34it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20602/75212 [02:32<06:43, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20616/75212 [02:32<06:43, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20630/75212 [02:32<06:43, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20644/75212 [02:32<06:43, 135.37it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20658/75212 [02:32<06:43, 135.36it/s][A[A

Selecting Coreset Indices.:  27%|â–ˆâ–ˆâ–‹       | 20672/75212 [02:32<06:42, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20686/75212 [02:32<06:42, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20700/75212 [02:33<06:42, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20714/75212 [02:33<06:42, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20728/75212 [02:33<06:42, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20742/75212 [02:33<06:42, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20756/75212 [02:33<06:42, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20770/75212 [02:33<06:42, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20784/75212 [02:33<06:42, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20798/75212 [02:33<06:42, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20812/75212 [02:33<06:41, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20826/75212 [02:33<06:41, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20840/75212 [02:34<06:41, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20854/75212 [02:34<06:41, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20868/75212 [02:34<06:41, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20882/75212 [02:34<06:41, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20896/75212 [02:34<06:41, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20910/75212 [02:34<06:41, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20924/75212 [02:34<06:41, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20938/75212 [02:34<06:40, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20952/75212 [02:34<06:40, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20966/75212 [02:34<06:40, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20980/75212 [02:35<06:40, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 20994/75212 [02:35<06:40, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21008/75212 [02:35<06:40, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21022/75212 [02:35<06:40, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21036/75212 [02:35<06:40, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21050/75212 [02:35<06:40, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21064/75212 [02:35<06:40, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21078/75212 [02:35<06:39, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21092/75212 [02:35<06:39, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21106/75212 [02:36<06:39, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21120/75212 [02:36<06:39, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21134/75212 [02:36<06:39, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21148/75212 [02:36<06:39, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21162/75212 [02:36<06:39, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21176/75212 [02:36<06:39, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21190/75212 [02:36<06:39, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21204/75212 [02:36<06:39, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21218/75212 [02:36<06:38, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21232/75212 [02:36<06:38, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21246/75212 [02:37<06:38, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21260/75212 [02:37<06:38, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21274/75212 [02:37<06:38, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21288/75212 [02:37<06:38, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21302/75212 [02:37<06:38, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21316/75212 [02:37<06:38, 135.37it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21330/75212 [02:37<06:38, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21344/75212 [02:37<06:38, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21358/75212 [02:37<06:37, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21372/75212 [02:37<06:37, 135.35it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21386/75212 [02:38<06:37, 135.34it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21400/75212 [02:38<06:37, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21414/75212 [02:38<06:37, 135.36it/s][A[A

Selecting Coreset Indices.:  28%|â–ˆâ–ˆâ–Š       | 21428/75212 [02:38<06:37, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21442/75212 [02:38<06:37, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21456/75212 [02:38<06:37, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21470/75212 [02:38<06:37, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21484/75212 [02:38<06:36, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21498/75212 [02:38<06:36, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21512/75212 [02:39<06:36, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21526/75212 [02:39<06:36, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21540/75212 [02:39<06:36, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21554/75212 [02:39<06:36, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21568/75212 [02:39<06:36, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21582/75212 [02:39<06:36, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21596/75212 [02:39<06:36, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–Š       | 21610/75212 [02:39<06:36, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21624/75212 [02:39<06:35, 135.33it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21638/75212 [02:39<06:35, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21652/75212 [02:40<06:35, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21666/75212 [02:40<06:35, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21680/75212 [02:40<06:35, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21694/75212 [02:40<06:35, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21708/75212 [02:40<06:35, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21722/75212 [02:40<06:35, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21736/75212 [02:40<06:35, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21750/75212 [02:40<06:34, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21764/75212 [02:40<06:34, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21778/75212 [02:40<06:34, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21792/75212 [02:41<06:34, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21806/75212 [02:41<06:34, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21820/75212 [02:41<06:34, 135.37it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21834/75212 [02:41<06:34, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21848/75212 [02:41<06:34, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21862/75212 [02:41<06:34, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21876/75212 [02:41<06:34, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21890/75212 [02:41<06:33, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21904/75212 [02:41<06:33, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21918/75212 [02:42<06:33, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21932/75212 [02:42<06:33, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21946/75212 [02:42<06:33, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21960/75212 [02:42<06:33, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21974/75212 [02:42<06:33, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 21988/75212 [02:42<06:33, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22002/75212 [02:42<06:33, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22016/75212 [02:42<06:33, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22030/75212 [02:42<06:32, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22044/75212 [02:42<06:32, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22058/75212 [02:43<06:32, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22072/75212 [02:43<06:32, 135.36it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22086/75212 [02:43<06:32, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22100/75212 [02:43<06:32, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22114/75212 [02:43<06:32, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22128/75212 [02:43<06:32, 135.35it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22142/75212 [02:43<06:32, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22156/75212 [02:43<06:32, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22170/75212 [02:43<06:31, 135.34it/s][A[A

Selecting Coreset Indices.:  29%|â–ˆâ–ˆâ–‰       | 22184/75212 [02:43<06:31, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22198/75212 [02:44<06:31, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22212/75212 [02:44<06:31, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22226/75212 [02:44<06:31, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22240/75212 [02:44<06:31, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22254/75212 [02:44<06:31, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22268/75212 [02:44<06:31, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22282/75212 [02:44<06:31, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22296/75212 [02:44<06:30, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22310/75212 [02:44<06:30, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22324/75212 [02:45<06:30, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22338/75212 [02:45<06:30, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22352/75212 [02:45<06:30, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22366/75212 [02:45<06:30, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22380/75212 [02:45<06:30, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22394/75212 [02:45<06:30, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22408/75212 [02:45<06:30, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22422/75212 [02:45<06:30, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22436/75212 [02:45<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22450/75212 [02:45<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22464/75212 [02:46<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22478/75212 [02:46<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22492/75212 [02:46<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22506/75212 [02:46<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22520/75212 [02:46<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22534/75212 [02:46<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22548/75212 [02:46<06:29, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–‰       | 22562/75212 [02:46<06:28, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22576/75212 [02:46<06:28, 135.37it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22590/75212 [02:46<06:28, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22604/75212 [02:47<06:28, 135.37it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22618/75212 [02:47<06:28, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22632/75212 [02:47<06:28, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22646/75212 [02:47<06:28, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22660/75212 [02:47<06:28, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22674/75212 [02:47<06:28, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22688/75212 [02:47<06:28, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22702/75212 [02:47<06:27, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22716/75212 [02:47<06:27, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22730/75212 [02:48<06:27, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22744/75212 [02:48<06:27, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22758/75212 [02:48<06:27, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22772/75212 [02:48<06:27, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22786/75212 [02:48<06:27, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22800/75212 [02:48<06:27, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22814/75212 [02:48<06:27, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22828/75212 [02:48<06:27, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22842/75212 [02:48<06:26, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22856/75212 [02:48<06:26, 135.34it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22870/75212 [02:49<06:26, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22884/75212 [02:49<06:26, 135.35it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22898/75212 [02:49<06:26, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22912/75212 [02:49<06:26, 135.36it/s][A[A

Selecting Coreset Indices.:  30%|â–ˆâ–ˆâ–ˆ       | 22926/75212 [02:49<06:26, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 22940/75212 [02:49<06:26, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 22954/75212 [02:49<06:26, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 22968/75212 [02:49<06:25, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 22982/75212 [02:49<06:25, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 22996/75212 [02:49<06:25, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23010/75212 [02:50<06:25, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23024/75212 [02:50<06:25, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23038/75212 [02:50<06:25, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23052/75212 [02:50<06:25, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23066/75212 [02:50<06:25, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23080/75212 [02:50<06:25, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23094/75212 [02:50<06:25, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23108/75212 [02:50<06:24, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23122/75212 [02:50<06:24, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23136/75212 [02:51<06:24, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23150/75212 [02:51<06:24, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23164/75212 [02:51<06:24, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23178/75212 [02:51<06:24, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23192/75212 [02:51<06:24, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23206/75212 [02:51<06:24, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23220/75212 [02:51<06:24, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23234/75212 [02:51<06:24, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23248/75212 [02:51<06:23, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23262/75212 [02:51<06:23, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23276/75212 [02:52<06:23, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23290/75212 [02:52<06:23, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23304/75212 [02:52<06:23, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23318/75212 [02:52<06:23, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23332/75212 [02:52<06:23, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23346/75212 [02:52<06:23, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23360/75212 [02:52<06:23, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23374/75212 [02:52<06:22, 135.37it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23388/75212 [02:52<06:22, 135.37it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23402/75212 [02:52<06:22, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23416/75212 [02:53<06:22, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23430/75212 [02:53<06:22, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23444/75212 [02:53<06:22, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23458/75212 [02:53<06:22, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23472/75212 [02:53<06:22, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23486/75212 [02:53<06:22, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆ       | 23500/75212 [02:53<06:22, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23514/75212 [02:53<06:21, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23528/75212 [02:53<06:21, 135.36it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23542/75212 [02:54<06:21, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23556/75212 [02:54<06:21, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23570/75212 [02:54<06:21, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23584/75212 [02:54<06:21, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23598/75212 [02:54<06:21, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23612/75212 [02:54<06:21, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23626/75212 [02:54<06:21, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23640/75212 [02:54<06:21, 135.35it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23654/75212 [02:54<06:20, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23668/75212 [02:54<06:20, 135.34it/s][A[A

Selecting Coreset Indices.:  31%|â–ˆâ–ˆâ–ˆâ–      | 23682/75212 [02:55<06:20, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23696/75212 [02:55<06:20, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23710/75212 [02:55<06:20, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23724/75212 [02:55<06:20, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23738/75212 [02:55<06:20, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23752/75212 [02:55<06:20, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23766/75212 [02:55<06:20, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23780/75212 [02:55<06:19, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23794/75212 [02:55<06:19, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23808/75212 [02:55<06:19, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23822/75212 [02:56<06:19, 135.33it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23836/75212 [02:56<06:19, 135.33it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23850/75212 [02:56<06:19, 135.33it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23864/75212 [02:56<06:19, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23878/75212 [02:56<06:19, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23892/75212 [02:56<06:19, 135.33it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23906/75212 [02:56<06:19, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23920/75212 [02:56<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23934/75212 [02:56<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23948/75212 [02:57<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23962/75212 [02:57<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23976/75212 [02:57<06:18, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 23990/75212 [02:57<06:18, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24004/75212 [02:57<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24018/75212 [02:57<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24032/75212 [02:57<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24046/75212 [02:57<06:18, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24060/75212 [02:57<06:17, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24074/75212 [02:57<06:17, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24088/75212 [02:58<06:17, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24102/75212 [02:58<06:17, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24116/75212 [02:58<06:17, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24130/75212 [02:58<06:17, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24144/75212 [02:58<06:17, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24158/75212 [02:58<06:17, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24172/75212 [02:58<06:17, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24186/75212 [02:58<06:16, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24200/75212 [02:58<06:16, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24214/75212 [02:58<06:16, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24228/75212 [02:59<06:16, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24242/75212 [02:59<06:16, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24256/75212 [02:59<06:16, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24270/75212 [02:59<06:16, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24284/75212 [02:59<06:16, 135.36it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24298/75212 [02:59<06:16, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24312/75212 [02:59<06:16, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24326/75212 [02:59<06:15, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24340/75212 [02:59<06:15, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24354/75212 [03:00<06:15, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24368/75212 [03:00<06:15, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24382/75212 [03:00<06:15, 135.34it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24396/75212 [03:00<06:15, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24410/75212 [03:00<06:15, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24424/75212 [03:00<06:15, 135.35it/s][A[A

Selecting Coreset Indices.:  32%|â–ˆâ–ˆâ–ˆâ–      | 24438/75212 [03:00<06:15, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24452/75212 [03:00<06:15, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24466/75212 [03:00<06:14, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24480/75212 [03:00<06:14, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24494/75212 [03:01<06:14, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24508/75212 [03:01<06:14, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24522/75212 [03:01<06:14, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24536/75212 [03:01<06:14, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24550/75212 [03:01<06:14, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24564/75212 [03:01<06:14, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24578/75212 [03:01<06:14, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24592/75212 [03:01<06:13, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24606/75212 [03:01<06:13, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24620/75212 [03:01<06:13, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24634/75212 [03:02<06:13, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24648/75212 [03:02<06:13, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24662/75212 [03:02<06:13, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24676/75212 [03:02<06:13, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24690/75212 [03:02<06:13, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24704/75212 [03:02<06:13, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24718/75212 [03:02<06:13, 135.37it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24732/75212 [03:02<06:12, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24746/75212 [03:02<06:12, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24760/75212 [03:03<06:12, 135.33it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24774/75212 [03:03<06:12, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24788/75212 [03:03<06:12, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24802/75212 [03:03<06:12, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24816/75212 [03:03<06:12, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24830/75212 [03:03<06:12, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24844/75212 [03:03<06:12, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24858/75212 [03:03<06:12, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24872/75212 [03:03<06:11, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24886/75212 [03:03<06:11, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24900/75212 [03:04<06:11, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24914/75212 [03:04<06:11, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24928/75212 [03:04<06:11, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24942/75212 [03:04<06:11, 135.33it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24956/75212 [03:04<06:11, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24970/75212 [03:04<06:11, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24984/75212 [03:04<06:11, 135.33it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24998/75212 [03:04<06:10, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25012/75212 [03:04<06:10, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25026/75212 [03:04<06:10, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25040/75212 [03:05<06:10, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25054/75212 [03:05<06:10, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25068/75212 [03:05<06:10, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25082/75212 [03:05<06:10, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25096/75212 [03:05<06:10, 135.34it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25110/75212 [03:05<06:10, 135.37it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25124/75212 [03:05<06:10, 135.37it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25138/75212 [03:05<06:09, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25152/75212 [03:05<06:09, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25166/75212 [03:06<06:09, 135.35it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25180/75212 [03:06<06:09, 135.36it/s][A[A

Selecting Coreset Indices.:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25194/75212 [03:06<06:09, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25208/75212 [03:06<06:09, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25222/75212 [03:06<06:09, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25236/75212 [03:06<06:09, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25250/75212 [03:06<06:09, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25264/75212 [03:06<06:08, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25278/75212 [03:06<06:08, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25292/75212 [03:06<06:08, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25306/75212 [03:07<06:08, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25320/75212 [03:07<06:08, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25334/75212 [03:07<06:08, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25348/75212 [03:07<06:08, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25362/75212 [03:07<06:08, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 25376/75212 [03:07<06:08, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25390/75212 [03:07<06:08, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25404/75212 [03:07<06:07, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25418/75212 [03:07<06:07, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25432/75212 [03:07<06:07, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25446/75212 [03:08<06:07, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25460/75212 [03:08<06:07, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25474/75212 [03:08<06:07, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25488/75212 [03:08<06:07, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25502/75212 [03:08<06:07, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25516/75212 [03:08<06:07, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25530/75212 [03:08<06:07, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25544/75212 [03:08<06:06, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25558/75212 [03:08<06:06, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25572/75212 [03:09<06:06, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25586/75212 [03:09<06:06, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25600/75212 [03:09<06:06, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25614/75212 [03:09<06:06, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25628/75212 [03:09<06:06, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25642/75212 [03:09<06:06, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25656/75212 [03:09<06:06, 135.37it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25670/75212 [03:09<06:06, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25684/75212 [03:09<06:05, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25698/75212 [03:09<06:05, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25712/75212 [03:10<06:05, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25726/75212 [03:10<06:05, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25740/75212 [03:10<06:05, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25754/75212 [03:10<06:05, 135.33it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25768/75212 [03:10<06:05, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25782/75212 [03:10<06:05, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25796/75212 [03:10<06:05, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25810/75212 [03:10<06:04, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25824/75212 [03:10<06:04, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25838/75212 [03:10<06:04, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25852/75212 [03:11<06:04, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25866/75212 [03:11<06:04, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25880/75212 [03:11<06:04, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25894/75212 [03:11<06:04, 135.35it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25908/75212 [03:11<06:04, 135.36it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25922/75212 [03:11<06:04, 135.34it/s][A[A

Selecting Coreset Indices.:  34%|â–ˆâ–ˆâ–ˆâ–      | 25936/75212 [03:11<06:04, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 25950/75212 [03:11<06:03, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 25964/75212 [03:11<06:03, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 25978/75212 [03:12<06:03, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 25992/75212 [03:12<06:03, 135.32it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26006/75212 [03:12<06:03, 135.33it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26020/75212 [03:12<06:03, 135.32it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26034/75212 [03:12<06:03, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26048/75212 [03:12<06:03, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26062/75212 [03:12<06:03, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26076/75212 [03:12<06:03, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26090/75212 [03:12<06:02, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26104/75212 [03:12<06:02, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26118/75212 [03:13<06:02, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26132/75212 [03:13<06:02, 135.33it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26146/75212 [03:13<06:02, 135.33it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26160/75212 [03:13<06:02, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26174/75212 [03:13<06:02, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26188/75212 [03:13<06:02, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26202/75212 [03:13<06:02, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26216/75212 [03:13<06:01, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26230/75212 [03:13<06:01, 135.36it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26244/75212 [03:13<06:01, 135.36it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26258/75212 [03:14<06:01, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26272/75212 [03:14<06:01, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26286/75212 [03:14<06:01, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26300/75212 [03:14<06:01, 135.36it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–      | 26314/75212 [03:14<06:01, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26328/75212 [03:14<06:01, 135.36it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26342/75212 [03:14<06:01, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26356/75212 [03:14<06:00, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26370/75212 [03:14<06:00, 135.36it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26384/75212 [03:15<06:00, 135.36it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26398/75212 [03:15<06:00, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26412/75212 [03:15<06:00, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26426/75212 [03:15<06:00, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26440/75212 [03:15<06:00, 135.33it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26454/75212 [03:15<06:00, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26468/75212 [03:15<06:00, 135.33it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26482/75212 [03:15<06:00, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26496/75212 [03:15<05:59, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26510/75212 [03:15<05:59, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26524/75212 [03:16<05:59, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26538/75212 [03:16<05:59, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26552/75212 [03:16<05:59, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26566/75212 [03:16<05:59, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26580/75212 [03:16<05:59, 135.36it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26594/75212 [03:16<05:59, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26608/75212 [03:16<05:59, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26622/75212 [03:16<05:59, 135.34it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26636/75212 [03:16<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26650/75212 [03:16<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26664/75212 [03:17<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26678/75212 [03:17<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 26692/75212 [03:17<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26706/75212 [03:17<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26720/75212 [03:17<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26734/75212 [03:17<05:58, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26748/75212 [03:17<05:58, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26762/75212 [03:17<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26776/75212 [03:17<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26790/75212 [03:18<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26804/75212 [03:18<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26818/75212 [03:18<05:57, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26832/75212 [03:18<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26846/75212 [03:18<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26860/75212 [03:18<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26874/75212 [03:18<05:57, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26888/75212 [03:18<05:57, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26902/75212 [03:18<05:56, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26916/75212 [03:18<05:56, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26930/75212 [03:19<05:56, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26944/75212 [03:19<05:56, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26958/75212 [03:19<05:56, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26972/75212 [03:19<05:56, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26986/75212 [03:19<05:56, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27000/75212 [03:19<05:56, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27014/75212 [03:19<05:56, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27028/75212 [03:19<05:56, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27042/75212 [03:19<05:55, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27056/75212 [03:19<05:55, 135.36it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27070/75212 [03:20<05:55, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27084/75212 [03:20<05:55, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27098/75212 [03:20<05:55, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27112/75212 [03:20<05:55, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27126/75212 [03:20<05:55, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27140/75212 [03:20<05:55, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27154/75212 [03:20<05:55, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27168/75212 [03:20<05:55, 135.33it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27182/75212 [03:20<05:54, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27196/75212 [03:21<05:54, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27210/75212 [03:21<05:54, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27224/75212 [03:21<05:54, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27238/75212 [03:21<05:54, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27252/75212 [03:21<05:54, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27266/75212 [03:21<05:54, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27280/75212 [03:21<05:54, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27294/75212 [03:21<05:54, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27308/75212 [03:21<05:53, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27322/75212 [03:21<05:53, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27336/75212 [03:22<05:53, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27350/75212 [03:22<05:53, 135.34it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27364/75212 [03:22<05:53, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27378/75212 [03:22<05:53, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27392/75212 [03:22<05:53, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27406/75212 [03:22<05:53, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27420/75212 [03:22<05:53, 135.35it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27434/75212 [03:22<05:52, 135.36it/s][A[A

Selecting Coreset Indices.:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 27448/75212 [03:22<05:52, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27462/75212 [03:22<05:52, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27476/75212 [03:23<05:52, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27490/75212 [03:23<05:52, 135.33it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27504/75212 [03:23<05:52, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27518/75212 [03:23<05:52, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27532/75212 [03:23<05:52, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27546/75212 [03:23<05:52, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27560/75212 [03:23<05:52, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27574/75212 [03:23<05:51, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27588/75212 [03:23<05:51, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27602/75212 [03:24<05:51, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27616/75212 [03:24<05:51, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27630/75212 [03:24<05:51, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27644/75212 [03:24<05:51, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27658/75212 [03:24<05:51, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27672/75212 [03:24<05:51, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27686/75212 [03:24<05:51, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27700/75212 [03:24<05:51, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27714/75212 [03:24<05:50, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27728/75212 [03:24<05:50, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27742/75212 [03:25<05:50, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27756/75212 [03:25<05:50, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27770/75212 [03:25<05:50, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27784/75212 [03:25<05:50, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27798/75212 [03:25<05:50, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27812/75212 [03:25<05:50, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27826/75212 [03:25<05:50, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27840/75212 [03:25<05:49, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27854/75212 [03:25<05:49, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27868/75212 [03:25<05:49, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27882/75212 [03:26<05:49, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27896/75212 [03:26<05:49, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27910/75212 [03:26<05:49, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27924/75212 [03:26<05:49, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27938/75212 [03:26<05:49, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27952/75212 [03:26<05:49, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27966/75212 [03:26<05:49, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27980/75212 [03:26<05:48, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 27994/75212 [03:26<05:48, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28008/75212 [03:27<05:48, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28022/75212 [03:27<05:48, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28036/75212 [03:27<05:48, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28050/75212 [03:27<05:48, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28064/75212 [03:27<05:48, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28078/75212 [03:27<05:48, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28092/75212 [03:27<05:48, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28106/75212 [03:27<05:47, 135.37it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28120/75212 [03:27<05:47, 135.37it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28134/75212 [03:27<05:47, 135.36it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28148/75212 [03:28<05:47, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28162/75212 [03:28<05:47, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28176/75212 [03:28<05:47, 135.34it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28190/75212 [03:28<05:47, 135.35it/s][A[A

Selecting Coreset Indices.:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28204/75212 [03:28<05:47, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28218/75212 [03:28<05:47, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28232/75212 [03:28<05:47, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28246/75212 [03:28<05:46, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28260/75212 [03:28<05:46, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28274/75212 [03:28<05:46, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28288/75212 [03:29<05:46, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28302/75212 [03:29<05:46, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28316/75212 [03:29<05:46, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28330/75212 [03:29<05:46, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28344/75212 [03:29<05:46, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28358/75212 [03:29<05:46, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28372/75212 [03:29<05:46, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28386/75212 [03:29<05:46, 135.33it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28400/75212 [03:29<05:45, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28414/75212 [03:30<05:45, 135.33it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28428/75212 [03:30<05:45, 135.33it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28442/75212 [03:30<05:45, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28456/75212 [03:30<05:45, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28470/75212 [03:30<05:45, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28484/75212 [03:30<05:45, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28498/75212 [03:30<05:45, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28512/75212 [03:30<05:45, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28526/75212 [03:30<05:44, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28540/75212 [03:30<05:44, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28554/75212 [03:31<05:44, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28568/75212 [03:31<05:44, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28582/75212 [03:31<05:44, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28596/75212 [03:31<05:44, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28610/75212 [03:31<05:44, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28624/75212 [03:31<05:44, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28638/75212 [03:31<05:44, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28652/75212 [03:31<05:43, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28666/75212 [03:31<05:43, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28680/75212 [03:31<05:43, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28694/75212 [03:32<05:43, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28708/75212 [03:32<05:43, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28722/75212 [03:32<05:43, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28736/75212 [03:32<05:43, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28750/75212 [03:32<05:43, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28764/75212 [03:32<05:43, 135.36it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28778/75212 [03:32<05:43, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28792/75212 [03:32<05:42, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28806/75212 [03:32<05:42, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28820/75212 [03:33<05:42, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28834/75212 [03:33<05:42, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28848/75212 [03:33<05:42, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28862/75212 [03:33<05:42, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28876/75212 [03:33<05:42, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28890/75212 [03:33<05:42, 135.33it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28904/75212 [03:33<05:42, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28918/75212 [03:33<05:42, 135.34it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28932/75212 [03:33<05:41, 135.35it/s][A[A

Selecting Coreset Indices.:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 28946/75212 [03:33<05:41, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 28960/75212 [03:34<05:41, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 28974/75212 [03:34<05:41, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 28988/75212 [03:34<05:41, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29002/75212 [03:34<05:41, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29016/75212 [03:34<05:41, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29030/75212 [03:34<05:41, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29044/75212 [03:34<05:41, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29058/75212 [03:34<05:40, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29072/75212 [03:34<05:40, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29086/75212 [03:34<05:40, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29100/75212 [03:35<05:40, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29114/75212 [03:35<05:40, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29128/75212 [03:35<05:40, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 29142/75212 [03:35<05:40, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29156/75212 [03:35<05:40, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29170/75212 [03:35<05:40, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29184/75212 [03:35<05:40, 135.33it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29198/75212 [03:35<05:39, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29212/75212 [03:35<05:39, 135.33it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29226/75212 [03:36<05:39, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29240/75212 [03:36<05:39, 135.31it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29254/75212 [03:36<05:39, 135.31it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29268/75212 [03:36<05:39, 135.32it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29282/75212 [03:36<05:39, 135.33it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29296/75212 [03:36<05:39, 135.33it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29310/75212 [03:36<05:39, 135.33it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29324/75212 [03:36<05:39, 135.33it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29338/75212 [03:36<05:38, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29352/75212 [03:36<05:38, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29366/75212 [03:37<05:38, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29380/75212 [03:37<05:38, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29394/75212 [03:37<05:38, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29408/75212 [03:37<05:38, 135.37it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29422/75212 [03:37<05:38, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29436/75212 [03:37<05:38, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29450/75212 [03:37<05:38, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29464/75212 [03:37<05:37, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29478/75212 [03:37<05:37, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29492/75212 [03:37<05:37, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29506/75212 [03:38<05:37, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29520/75212 [03:38<05:37, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29534/75212 [03:38<05:37, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29548/75212 [03:38<05:37, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29562/75212 [03:38<05:37, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29576/75212 [03:38<05:37, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29590/75212 [03:38<05:37, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29604/75212 [03:38<05:36, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29618/75212 [03:38<05:36, 135.36it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29632/75212 [03:39<05:36, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29646/75212 [03:39<05:36, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29660/75212 [03:39<05:36, 135.35it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29674/75212 [03:39<05:36, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29688/75212 [03:39<05:36, 135.34it/s][A[A

Selecting Coreset Indices.:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 29702/75212 [03:39<05:36, 135.34it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29716/75212 [03:39<05:36, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29730/75212 [03:39<05:36, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29744/75212 [03:39<05:35, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29758/75212 [03:39<05:35, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29772/75212 [03:40<05:35, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29786/75212 [03:40<05:35, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29800/75212 [03:40<05:35, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29814/75212 [03:40<05:35, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29828/75212 [03:40<05:35, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29842/75212 [03:40<05:35, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29856/75212 [03:40<05:35, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29870/75212 [03:40<05:34, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29884/75212 [03:40<05:34, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29898/75212 [03:40<05:34, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29912/75212 [03:41<05:34, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29926/75212 [03:41<05:34, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29940/75212 [03:41<05:34, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29954/75212 [03:41<05:34, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29968/75212 [03:41<05:34, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29982/75212 [03:41<05:34, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 29996/75212 [03:41<05:34, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 30010/75212 [03:41<05:33, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 30024/75212 [03:41<05:33, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 30038/75212 [03:42<05:33, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 30052/75212 [03:42<05:33, 135.34it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 30066/75212 [03:42<05:33, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 30080/75212 [03:42<05:33, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30094/75212 [03:42<05:33, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30108/75212 [03:42<05:33, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30122/75212 [03:42<05:33, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30136/75212 [03:42<05:33, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30150/75212 [03:42<05:32, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30164/75212 [03:42<05:32, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30178/75212 [03:43<05:32, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30192/75212 [03:43<05:32, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30206/75212 [03:43<05:32, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30220/75212 [03:43<05:32, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30234/75212 [03:43<05:32, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30248/75212 [03:43<05:32, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30262/75212 [03:43<05:32, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30276/75212 [03:43<05:31, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30290/75212 [03:43<05:31, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30304/75212 [03:43<05:31, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30318/75212 [03:44<05:31, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30332/75212 [03:44<05:31, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30346/75212 [03:44<05:31, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30360/75212 [03:44<05:31, 135.37it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30374/75212 [03:44<05:31, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30388/75212 [03:44<05:31, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30402/75212 [03:44<05:31, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30416/75212 [03:44<05:30, 135.36it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30430/75212 [03:44<05:30, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30444/75212 [03:45<05:30, 135.35it/s][A[A

Selecting Coreset Indices.:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30458/75212 [03:45<05:30, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30472/75212 [03:45<05:30, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30486/75212 [03:45<05:30, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30500/75212 [03:45<05:30, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30514/75212 [03:45<05:30, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30528/75212 [03:45<05:30, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30542/75212 [03:45<05:30, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30556/75212 [03:45<05:29, 135.36it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30570/75212 [03:45<05:29, 135.36it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30584/75212 [03:46<05:29, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30598/75212 [03:46<05:29, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30612/75212 [03:46<05:29, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30626/75212 [03:46<05:29, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30640/75212 [03:46<05:29, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30654/75212 [03:46<05:29, 135.36it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30668/75212 [03:46<05:29, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30682/75212 [03:46<05:29, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30696/75212 [03:46<05:28, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30710/75212 [03:46<05:28, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30724/75212 [03:47<05:28, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30738/75212 [03:47<05:28, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30752/75212 [03:47<05:28, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30766/75212 [03:47<05:28, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30780/75212 [03:47<05:28, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30794/75212 [03:47<05:28, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30808/75212 [03:47<05:28, 135.33it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30822/75212 [03:47<05:28, 135.32it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30836/75212 [03:47<05:27, 135.32it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30850/75212 [03:48<05:27, 135.33it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30864/75212 [03:48<05:30, 134.37it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30878/75212 [03:48<05:29, 134.65it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30892/75212 [03:48<05:28, 134.86it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30906/75212 [03:48<05:28, 135.01it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30920/75212 [03:48<05:27, 135.11it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30934/75212 [03:48<05:27, 135.18it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30948/75212 [03:48<05:27, 135.22it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30962/75212 [03:48<05:27, 135.26it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30976/75212 [03:48<05:26, 135.29it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30990/75212 [03:49<05:26, 135.30it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31004/75212 [03:49<05:26, 135.31it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31018/75212 [03:49<05:26, 135.32it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31032/75212 [03:49<05:26, 135.32it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31046/75212 [03:49<05:26, 135.32it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31060/75212 [03:49<05:26, 135.33it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31074/75212 [03:49<05:26, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31088/75212 [03:49<05:26, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31102/75212 [03:49<05:25, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31116/75212 [03:49<05:25, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31130/75212 [03:50<05:25, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31144/75212 [03:50<05:25, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31158/75212 [03:50<05:25, 135.33it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31172/75212 [03:50<05:25, 135.34it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31186/75212 [03:50<05:25, 135.35it/s][A[A

Selecting Coreset Indices.:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31200/75212 [03:50<05:25, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31214/75212 [03:50<05:25, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31228/75212 [03:50<05:24, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31242/75212 [03:50<05:24, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31256/75212 [03:51<05:24, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31270/75212 [03:51<05:24, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31284/75212 [03:51<05:24, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31298/75212 [03:51<05:24, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31312/75212 [03:51<05:24, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31326/75212 [03:51<05:24, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31340/75212 [03:51<05:24, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31354/75212 [03:51<05:24, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31368/75212 [03:51<05:23, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31382/75212 [03:51<05:23, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31396/75212 [03:52<05:23, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31410/75212 [03:52<05:23, 135.33it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31424/75212 [03:52<05:23, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31438/75212 [03:52<05:23, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31452/75212 [03:52<05:23, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31466/75212 [03:52<05:23, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31480/75212 [03:52<05:23, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31494/75212 [03:52<05:22, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31508/75212 [03:52<05:22, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31522/75212 [03:52<05:22, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31536/75212 [03:53<05:22, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31550/75212 [03:53<05:22, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31564/75212 [03:53<05:22, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31578/75212 [03:53<05:22, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31592/75212 [03:53<05:22, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31606/75212 [03:53<05:22, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31620/75212 [03:53<05:22, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31634/75212 [03:53<05:21, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31648/75212 [03:53<05:21, 135.37it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31662/75212 [03:54<05:21, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31676/75212 [03:54<05:21, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31690/75212 [03:54<05:21, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31704/75212 [03:54<05:21, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31718/75212 [03:54<05:21, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31732/75212 [03:54<05:21, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31746/75212 [03:54<05:21, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31760/75212 [03:54<05:21, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31774/75212 [03:54<05:20, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31788/75212 [03:54<05:20, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31802/75212 [03:55<05:20, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31816/75212 [03:55<05:20, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31830/75212 [03:55<05:20, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31844/75212 [03:55<05:20, 135.36it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31858/75212 [03:55<05:20, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31872/75212 [03:55<05:20, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31886/75212 [03:55<05:20, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31900/75212 [03:55<05:20, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31914/75212 [03:55<05:19, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31928/75212 [03:55<05:19, 135.35it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31942/75212 [03:56<05:19, 135.34it/s][A[A

Selecting Coreset Indices.:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31956/75212 [03:56<05:19, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 31970/75212 [03:56<05:19, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 31984/75212 [03:56<05:19, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 31998/75212 [03:56<05:19, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32012/75212 [03:56<05:19, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32026/75212 [03:56<05:19, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32040/75212 [03:56<05:18, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32054/75212 [03:56<05:18, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32068/75212 [03:57<05:18, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32082/75212 [03:57<05:18, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32096/75212 [03:57<05:18, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32110/75212 [03:57<05:18, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32124/75212 [03:57<05:18, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32138/75212 [03:57<05:18, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32152/75212 [03:57<05:18, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32166/75212 [03:57<05:18, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32180/75212 [03:57<05:17, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32194/75212 [03:57<05:17, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32208/75212 [03:58<05:17, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32222/75212 [03:58<05:17, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32236/75212 [03:58<05:17, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32250/75212 [03:58<05:17, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32264/75212 [03:58<05:17, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32278/75212 [03:58<05:17, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32292/75212 [03:58<05:17, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32306/75212 [03:58<05:17, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32320/75212 [03:58<05:16, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32334/75212 [03:58<05:16, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32348/75212 [03:59<05:16, 135.32it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32362/75212 [03:59<05:16, 135.32it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32376/75212 [03:59<05:16, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32390/75212 [03:59<05:16, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32404/75212 [03:59<05:16, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32418/75212 [03:59<05:16, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32432/75212 [03:59<05:16, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32446/75212 [03:59<05:15, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32460/75212 [03:59<05:15, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32474/75212 [04:00<05:15, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32488/75212 [04:00<05:15, 135.30it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32502/75212 [04:00<05:15, 135.28it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32516/75212 [04:00<05:15, 135.30it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32530/75212 [04:00<05:15, 135.31it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32544/75212 [04:00<05:15, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32558/75212 [04:00<05:15, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32572/75212 [04:00<05:15, 135.35it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32586/75212 [04:00<05:14, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32600/75212 [04:00<05:14, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32614/75212 [04:01<05:14, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32628/75212 [04:01<05:14, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32642/75212 [04:01<05:14, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32656/75212 [04:01<05:14, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32670/75212 [04:01<05:14, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32684/75212 [04:01<05:14, 135.34it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32698/75212 [04:01<05:14, 135.33it/s][A[A

Selecting Coreset Indices.:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32712/75212 [04:01<05:14, 135.33it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32726/75212 [04:01<05:13, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32740/75212 [04:01<05:13, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32754/75212 [04:02<05:13, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32768/75212 [04:02<05:13, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32782/75212 [04:02<05:13, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32796/75212 [04:02<05:13, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32810/75212 [04:02<05:13, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32824/75212 [04:02<05:13, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32838/75212 [04:02<05:13, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32852/75212 [04:02<05:12, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32866/75212 [04:02<05:12, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32880/75212 [04:03<05:12, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32894/75212 [04:03<05:12, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32908/75212 [04:03<05:12, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32922/75212 [04:03<05:12, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32936/75212 [04:03<05:12, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32950/75212 [04:03<05:12, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32964/75212 [04:03<05:12, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32978/75212 [04:03<05:12, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32992/75212 [04:03<05:11, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33006/75212 [04:03<05:11, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33020/75212 [04:04<05:11, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33034/75212 [04:04<05:11, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33048/75212 [04:04<05:11, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33062/75212 [04:04<05:11, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33076/75212 [04:04<05:11, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33090/75212 [04:04<05:11, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33104/75212 [04:04<05:11, 135.33it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33118/75212 [04:04<05:11, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33132/75212 [04:04<05:10, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33146/75212 [04:04<05:10, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33160/75212 [04:05<05:10, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33174/75212 [04:05<05:10, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33188/75212 [04:05<05:10, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33202/75212 [04:05<05:10, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33216/75212 [04:05<05:10, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33230/75212 [04:05<05:10, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33244/75212 [04:05<05:10, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33258/75212 [04:05<05:09, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33272/75212 [04:05<05:09, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33286/75212 [04:06<05:09, 135.37it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33300/75212 [04:06<05:09, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33314/75212 [04:06<05:09, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33328/75212 [04:06<05:09, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33342/75212 [04:06<05:09, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33356/75212 [04:06<05:09, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33370/75212 [04:06<05:09, 135.36it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33384/75212 [04:06<05:09, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33398/75212 [04:06<05:08, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33412/75212 [04:06<05:08, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33426/75212 [04:07<05:08, 135.34it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33440/75212 [04:07<05:08, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33454/75212 [04:07<05:08, 135.35it/s][A[A

Selecting Coreset Indices.:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33468/75212 [04:07<05:08, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33482/75212 [04:07<05:08, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33496/75212 [04:07<05:08, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33510/75212 [04:07<05:08, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33524/75212 [04:07<05:08, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33538/75212 [04:07<05:07, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33552/75212 [04:07<05:07, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33566/75212 [04:08<05:07, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33580/75212 [04:08<05:07, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33594/75212 [04:08<05:07, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33608/75212 [04:08<05:07, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33622/75212 [04:08<05:07, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33636/75212 [04:08<05:07, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33650/75212 [04:08<05:07, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33664/75212 [04:08<05:06, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33678/75212 [04:08<05:06, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33692/75212 [04:09<05:06, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33706/75212 [04:09<05:06, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33720/75212 [04:09<05:06, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33734/75212 [04:09<05:06, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33748/75212 [04:09<05:06, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33762/75212 [04:09<05:06, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33776/75212 [04:09<05:06, 135.37it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33790/75212 [04:09<05:06, 135.37it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33804/75212 [04:09<05:05, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33818/75212 [04:09<05:05, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33832/75212 [04:10<05:05, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33846/75212 [04:10<05:05, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33860/75212 [04:10<05:05, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33874/75212 [04:10<05:05, 135.32it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33888/75212 [04:10<05:05, 135.33it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33902/75212 [04:10<05:05, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33916/75212 [04:10<05:05, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33930/75212 [04:10<05:05, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33944/75212 [04:10<05:04, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33958/75212 [04:10<05:04, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33972/75212 [04:11<05:04, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33986/75212 [04:11<05:04, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34000/75212 [04:11<05:04, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34014/75212 [04:11<05:04, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34028/75212 [04:11<05:04, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34042/75212 [04:11<05:04, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34056/75212 [04:11<05:04, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34070/75212 [04:11<05:03, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34084/75212 [04:11<05:03, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34098/75212 [04:12<05:03, 135.36it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34112/75212 [04:12<05:03, 135.35it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34126/75212 [04:12<05:03, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34140/75212 [04:12<05:03, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34154/75212 [04:12<05:03, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34168/75212 [04:12<05:03, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34182/75212 [04:12<05:03, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34196/75212 [04:12<05:03, 135.34it/s][A[A

Selecting Coreset Indices.:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34210/75212 [04:12<05:02, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34224/75212 [04:12<05:02, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34238/75212 [04:13<05:02, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34252/75212 [04:13<05:02, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34266/75212 [04:13<05:02, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34280/75212 [04:13<05:02, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34294/75212 [04:13<05:02, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34308/75212 [04:13<05:02, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34322/75212 [04:13<05:02, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34336/75212 [04:13<05:02, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34350/75212 [04:13<05:01, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34364/75212 [04:13<05:01, 135.37it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34378/75212 [04:14<05:01, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34392/75212 [04:14<05:01, 135.37it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34406/75212 [04:14<05:01, 135.37it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34420/75212 [04:14<05:01, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34434/75212 [04:14<05:01, 135.37it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34448/75212 [04:14<05:01, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34462/75212 [04:14<05:01, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34476/75212 [04:14<05:00, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34490/75212 [04:14<05:00, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34504/75212 [04:15<05:00, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34518/75212 [04:15<05:00, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34532/75212 [04:15<05:00, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34546/75212 [04:15<05:00, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34560/75212 [04:15<05:00, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34574/75212 [04:15<05:00, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34588/75212 [04:15<05:00, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34602/75212 [04:15<05:00, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34616/75212 [04:15<04:59, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34630/75212 [04:15<04:59, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34644/75212 [04:16<04:59, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34658/75212 [04:16<04:59, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34672/75212 [04:16<04:59, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34686/75212 [04:16<04:59, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34700/75212 [04:16<04:59, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34714/75212 [04:16<04:59, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34728/75212 [04:16<04:59, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34742/75212 [04:16<04:58, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34756/75212 [04:16<04:58, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34770/75212 [04:16<04:58, 135.36it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34784/75212 [04:17<04:58, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34798/75212 [04:17<04:58, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34812/75212 [04:17<04:58, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34826/75212 [04:17<04:58, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34840/75212 [04:17<04:58, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34854/75212 [04:17<04:58, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34868/75212 [04:17<04:58, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34882/75212 [04:17<04:57, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34896/75212 [04:17<04:57, 135.34it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34910/75212 [04:18<04:57, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34924/75212 [04:18<04:57, 135.35it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34938/75212 [04:18<04:57, 135.33it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34952/75212 [04:18<04:57, 135.33it/s][A[A

Selecting Coreset Indices.:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34966/75212 [04:18<04:57, 135.33it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34980/75212 [04:18<04:57, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34994/75212 [04:18<04:57, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35008/75212 [04:18<04:57, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35022/75212 [04:18<04:56, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35036/75212 [04:18<04:56, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35050/75212 [04:19<04:56, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35064/75212 [04:19<04:56, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35078/75212 [04:19<04:56, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35092/75212 [04:19<04:56, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35106/75212 [04:19<04:56, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35120/75212 [04:19<04:56, 135.36it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35134/75212 [04:19<04:56, 135.36it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35148/75212 [04:19<04:55, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35162/75212 [04:19<04:55, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35176/75212 [04:19<04:55, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35190/75212 [04:20<04:55, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35204/75212 [04:20<04:55, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35218/75212 [04:20<04:55, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35232/75212 [04:20<04:55, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35246/75212 [04:20<04:55, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35260/75212 [04:20<04:55, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35274/75212 [04:20<04:55, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35288/75212 [04:20<04:54, 135.36it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35302/75212 [04:20<04:54, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35316/75212 [04:21<04:54, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35330/75212 [04:21<04:54, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35344/75212 [04:21<04:54, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35358/75212 [04:21<04:54, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35372/75212 [04:21<04:54, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35386/75212 [04:21<04:54, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35400/75212 [04:21<04:54, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35414/75212 [04:21<04:54, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35428/75212 [04:21<04:53, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35442/75212 [04:21<04:53, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35456/75212 [04:22<04:53, 135.33it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35470/75212 [04:22<04:53, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35484/75212 [04:22<04:53, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35498/75212 [04:22<04:53, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35512/75212 [04:22<04:53, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35526/75212 [04:22<04:53, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35540/75212 [04:22<04:53, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35554/75212 [04:22<04:53, 135.33it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35568/75212 [04:22<04:52, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35582/75212 [04:22<04:52, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35596/75212 [04:23<04:52, 135.33it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35610/75212 [04:23<04:52, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35624/75212 [04:23<04:52, 135.36it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35638/75212 [04:23<04:52, 135.34it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35652/75212 [04:23<04:52, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35666/75212 [04:23<04:52, 135.36it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35680/75212 [04:23<04:52, 135.36it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35694/75212 [04:23<04:51, 135.37it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35708/75212 [04:23<04:51, 135.35it/s][A[A

Selecting Coreset Indices.:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35722/75212 [04:24<04:51, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35736/75212 [04:24<04:51, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35750/75212 [04:24<04:51, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35764/75212 [04:24<04:51, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35778/75212 [04:24<04:51, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35792/75212 [04:24<04:51, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35806/75212 [04:24<04:51, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35820/75212 [04:24<04:51, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35834/75212 [04:24<04:50, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35848/75212 [04:24<04:50, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35862/75212 [04:25<04:50, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35876/75212 [04:25<04:50, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35890/75212 [04:25<04:50, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35904/75212 [04:25<04:50, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35918/75212 [04:25<04:50, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35932/75212 [04:25<04:50, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35946/75212 [04:25<04:50, 135.33it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35960/75212 [04:25<04:50, 135.33it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35974/75212 [04:25<04:49, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35988/75212 [04:25<04:49, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36002/75212 [04:26<04:49, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36016/75212 [04:26<04:49, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36030/75212 [04:26<04:49, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36044/75212 [04:26<04:49, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36058/75212 [04:26<04:49, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36072/75212 [04:26<04:49, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36086/75212 [04:26<04:49, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36100/75212 [04:26<04:48, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36114/75212 [04:26<04:48, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36128/75212 [04:27<04:48, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36142/75212 [04:27<04:48, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36156/75212 [04:27<04:48, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36170/75212 [04:27<04:48, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36184/75212 [04:27<04:48, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36198/75212 [04:27<04:48, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36212/75212 [04:27<04:48, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36226/75212 [04:27<04:48, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36240/75212 [04:27<04:47, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36254/75212 [04:27<04:47, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36268/75212 [04:28<04:47, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36282/75212 [04:28<04:47, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36296/75212 [04:28<04:47, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36310/75212 [04:28<04:47, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36324/75212 [04:28<04:47, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36338/75212 [04:28<04:47, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36352/75212 [04:28<04:47, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36366/75212 [04:28<04:46, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36380/75212 [04:28<04:46, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36394/75212 [04:28<04:46, 135.36it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36408/75212 [04:29<04:46, 135.34it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36422/75212 [04:29<04:46, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36436/75212 [04:29<04:46, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36450/75212 [04:29<04:46, 135.35it/s][A[A

Selecting Coreset Indices.:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36464/75212 [04:29<04:46, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36478/75212 [04:29<04:46, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36492/75212 [04:29<04:46, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36506/75212 [04:29<04:45, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36520/75212 [04:29<04:45, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36534/75212 [04:30<04:45, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36548/75212 [04:30<04:45, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36562/75212 [04:30<04:45, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36576/75212 [04:30<04:45, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36590/75212 [04:30<04:45, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36604/75212 [04:30<04:45, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36618/75212 [04:30<04:45, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36632/75212 [04:30<04:45, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36646/75212 [04:30<04:44, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36660/75212 [04:30<04:44, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36674/75212 [04:31<04:44, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36688/75212 [04:31<04:44, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36702/75212 [04:31<04:44, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36716/75212 [04:31<04:44, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36730/75212 [04:31<04:44, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36744/75212 [04:31<04:44, 135.37it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36758/75212 [04:31<04:44, 135.37it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36772/75212 [04:31<04:43, 135.37it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36786/75212 [04:31<04:43, 135.37it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36800/75212 [04:31<04:43, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36814/75212 [04:32<04:43, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36828/75212 [04:32<04:43, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36842/75212 [04:32<04:43, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36856/75212 [04:32<04:43, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36870/75212 [04:32<04:43, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36884/75212 [04:32<04:43, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36898/75212 [04:32<04:43, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36912/75212 [04:32<04:42, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36926/75212 [04:32<04:42, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36940/75212 [04:33<04:42, 135.37it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36954/75212 [04:33<04:42, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36968/75212 [04:33<04:42, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36982/75212 [04:33<04:42, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36996/75212 [04:33<04:42, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37010/75212 [04:33<04:42, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37024/75212 [04:33<04:42, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37038/75212 [04:33<04:42, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37052/75212 [04:33<04:41, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37066/75212 [04:33<04:41, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37080/75212 [04:34<04:41, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37094/75212 [04:34<04:41, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37108/75212 [04:34<04:41, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37122/75212 [04:34<04:41, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37136/75212 [04:34<04:41, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37150/75212 [04:34<04:41, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37164/75212 [04:34<04:41, 135.36it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37178/75212 [04:34<04:40, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37192/75212 [04:34<04:40, 135.34it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37206/75212 [04:34<04:40, 135.35it/s][A[A

Selecting Coreset Indices.:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37220/75212 [04:35<04:40, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37234/75212 [04:35<04:40, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37248/75212 [04:35<04:40, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37262/75212 [04:35<04:40, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37276/75212 [04:35<04:40, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37290/75212 [04:35<04:40, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37304/75212 [04:35<04:40, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37318/75212 [04:35<04:39, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37332/75212 [04:35<04:39, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37346/75212 [04:36<04:39, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37360/75212 [04:36<04:39, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37374/75212 [04:36<04:39, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37388/75212 [04:36<04:39, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37402/75212 [04:36<04:39, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37416/75212 [04:36<04:39, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37430/75212 [04:36<04:39, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37444/75212 [04:36<04:39, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37458/75212 [04:36<04:38, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37472/75212 [04:36<04:38, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37486/75212 [04:37<04:38, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37500/75212 [04:37<04:38, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37514/75212 [04:37<04:38, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37528/75212 [04:37<04:38, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37542/75212 [04:37<04:38, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37556/75212 [04:37<04:38, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37570/75212 [04:37<04:38, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37584/75212 [04:37<04:38, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37598/75212 [04:37<04:37, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37612/75212 [04:37<04:37, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37626/75212 [04:38<04:37, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37640/75212 [04:38<04:37, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37654/75212 [04:38<04:37, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37668/75212 [04:38<04:37, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37682/75212 [04:38<04:37, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37696/75212 [04:38<04:37, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37710/75212 [04:38<04:37, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37724/75212 [04:38<04:36, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37738/75212 [04:38<04:36, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37752/75212 [04:39<04:36, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37766/75212 [04:39<04:36, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37780/75212 [04:39<04:36, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37794/75212 [04:39<04:36, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37808/75212 [04:39<04:36, 135.37it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37822/75212 [04:39<04:36, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37836/75212 [04:39<04:36, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37850/75212 [04:39<04:36, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37864/75212 [04:39<04:35, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37878/75212 [04:39<04:35, 135.36it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37892/75212 [04:40<04:35, 135.37it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37906/75212 [04:40<04:35, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37920/75212 [04:40<04:35, 135.34it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37934/75212 [04:40<04:35, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37948/75212 [04:40<04:35, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37962/75212 [04:40<04:35, 135.35it/s][A[A

Selecting Coreset Indices.:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37976/75212 [04:40<04:35, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37990/75212 [04:40<04:34, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38004/75212 [04:40<04:34, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38018/75212 [04:40<04:34, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38032/75212 [04:41<04:34, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38046/75212 [04:41<04:34, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38060/75212 [04:41<04:34, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38074/75212 [04:41<04:34, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38088/75212 [04:41<04:34, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38102/75212 [04:41<04:34, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38116/75212 [04:41<04:34, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38130/75212 [04:41<04:33, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38144/75212 [04:41<04:33, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38158/75212 [04:42<04:33, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38172/75212 [04:42<04:33, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38186/75212 [04:42<04:33, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38200/75212 [04:42<04:33, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38214/75212 [04:42<04:33, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38228/75212 [04:42<04:33, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38242/75212 [04:42<04:33, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38256/75212 [04:42<04:33, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38270/75212 [04:42<04:32, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38284/75212 [04:42<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38298/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38312/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38326/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38340/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38354/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38368/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38382/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38396/75212 [04:43<04:32, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38410/75212 [04:43<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38424/75212 [04:43<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38438/75212 [04:44<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38452/75212 [04:44<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38466/75212 [04:44<04:31, 135.36it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38480/75212 [04:44<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38494/75212 [04:44<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38508/75212 [04:44<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38522/75212 [04:44<04:31, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38536/75212 [04:44<04:30, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38550/75212 [04:44<04:30, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38564/75212 [04:45<04:30, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38578/75212 [04:45<04:30, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38592/75212 [04:45<04:30, 135.33it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38606/75212 [04:45<04:30, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38620/75212 [04:45<04:30, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38634/75212 [04:45<04:30, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38648/75212 [04:45<04:30, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38662/75212 [04:45<04:30, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38676/75212 [04:45<04:29, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38690/75212 [04:45<04:29, 135.35it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38704/75212 [04:46<04:29, 135.34it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38718/75212 [04:46<04:29, 135.33it/s][A[A

Selecting Coreset Indices.:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38732/75212 [04:46<04:29, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38746/75212 [04:46<04:29, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38760/75212 [04:46<04:29, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38774/75212 [04:46<04:29, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38788/75212 [04:46<04:29, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38802/75212 [04:46<04:29, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38816/75212 [04:46<04:28, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38830/75212 [04:46<04:28, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38844/75212 [04:47<04:28, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38858/75212 [04:47<04:28, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38872/75212 [04:47<04:28, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38886/75212 [04:47<04:28, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38900/75212 [04:47<04:28, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38914/75212 [04:47<04:28, 135.37it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38928/75212 [04:47<04:28, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38942/75212 [04:47<04:27, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38956/75212 [04:47<04:27, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38970/75212 [04:48<04:27, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38984/75212 [04:48<04:27, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38998/75212 [04:48<04:27, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39012/75212 [04:48<04:27, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39026/75212 [04:48<04:27, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39040/75212 [04:48<04:27, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39054/75212 [04:48<04:27, 135.37it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39068/75212 [04:48<04:26, 135.38it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39082/75212 [04:48<04:26, 135.37it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39096/75212 [04:48<04:26, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39110/75212 [04:49<04:26, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39124/75212 [04:49<04:26, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39138/75212 [04:49<04:26, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39152/75212 [04:49<04:26, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39166/75212 [04:49<04:26, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39180/75212 [04:49<04:26, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39194/75212 [04:49<04:26, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39208/75212 [04:49<04:26, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39222/75212 [04:49<04:25, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39236/75212 [04:49<04:25, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39250/75212 [04:50<04:25, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39264/75212 [04:50<04:25, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39278/75212 [04:50<04:25, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39292/75212 [04:50<04:25, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39306/75212 [04:50<04:25, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39320/75212 [04:50<04:25, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39334/75212 [04:50<04:25, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39348/75212 [04:50<04:24, 135.36it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39362/75212 [04:50<04:24, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39376/75212 [04:51<04:24, 135.35it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39390/75212 [04:51<04:24, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39404/75212 [04:51<04:24, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39418/75212 [04:51<04:24, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39432/75212 [04:51<04:24, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39446/75212 [04:51<04:24, 135.33it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39460/75212 [04:51<04:24, 135.34it/s][A[A

Selecting Coreset Indices.:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39474/75212 [04:51<04:24, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39488/75212 [04:51<04:23, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39502/75212 [04:51<04:23, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39516/75212 [04:52<04:23, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39530/75212 [04:52<04:23, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39544/75212 [04:52<04:23, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39558/75212 [04:52<04:23, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39572/75212 [04:52<04:23, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39586/75212 [04:52<04:23, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39600/75212 [04:52<04:23, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39614/75212 [04:52<04:23, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39628/75212 [04:52<04:22, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39642/75212 [04:52<04:22, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39656/75212 [04:53<04:22, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39670/75212 [04:53<04:22, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39684/75212 [04:53<04:22, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39698/75212 [04:53<04:22, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39712/75212 [04:53<04:22, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39726/75212 [04:53<04:22, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39740/75212 [04:53<04:22, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39754/75212 [04:53<04:21, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39768/75212 [04:53<04:21, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39782/75212 [04:54<04:21, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39796/75212 [04:54<04:21, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39810/75212 [04:54<04:21, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39824/75212 [04:54<04:21, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39838/75212 [04:54<04:21, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39852/75212 [04:54<04:21, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39866/75212 [04:54<04:21, 135.37it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39880/75212 [04:54<04:21, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39894/75212 [04:54<04:20, 135.37it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39908/75212 [04:54<04:20, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39922/75212 [04:55<04:20, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39936/75212 [04:55<04:20, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39950/75212 [04:55<04:20, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39964/75212 [04:55<04:20, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39978/75212 [04:55<04:20, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 39992/75212 [04:55<04:20, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40006/75212 [04:55<04:20, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40020/75212 [04:55<04:20, 135.33it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40034/75212 [04:55<04:19, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40048/75212 [04:55<04:19, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40062/75212 [04:56<04:19, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40076/75212 [04:56<04:19, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40090/75212 [04:56<04:19, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40104/75212 [04:56<04:19, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40118/75212 [04:56<04:19, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40132/75212 [04:56<04:19, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40146/75212 [04:56<04:19, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40160/75212 [04:56<04:18, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40174/75212 [04:56<04:18, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40188/75212 [04:57<04:18, 135.35it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40202/75212 [04:57<04:18, 135.34it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40216/75212 [04:57<04:18, 135.36it/s][A[A

Selecting Coreset Indices.:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40230/75212 [04:57<04:18, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40244/75212 [04:57<04:18, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40258/75212 [04:57<04:18, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40272/75212 [04:57<04:18, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40286/75212 [04:57<04:18, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40300/75212 [04:57<04:17, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40314/75212 [04:57<04:17, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40328/75212 [04:58<04:17, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40342/75212 [04:58<04:17, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40356/75212 [04:58<04:17, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40370/75212 [04:58<04:17, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40384/75212 [04:58<04:17, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40398/75212 [04:58<04:17, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40412/75212 [04:58<04:17, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40426/75212 [04:58<04:17, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40440/75212 [04:58<04:16, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40454/75212 [04:58<04:16, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40468/75212 [04:59<04:16, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40482/75212 [04:59<04:16, 135.33it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40496/75212 [04:59<04:16, 135.32it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40510/75212 [04:59<04:16, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40524/75212 [04:59<04:16, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40538/75212 [04:59<04:16, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40552/75212 [04:59<04:16, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40566/75212 [04:59<04:15, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40580/75212 [04:59<04:15, 135.36it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40594/75212 [05:00<04:15, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40608/75212 [05:00<04:15, 135.36it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40622/75212 [05:00<04:15, 135.36it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40636/75212 [05:00<04:15, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40650/75212 [05:00<04:15, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40664/75212 [05:00<04:15, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40678/75212 [05:00<04:15, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40692/75212 [05:00<04:15, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40706/75212 [05:00<04:14, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40720/75212 [05:00<04:14, 135.36it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40734/75212 [05:01<04:14, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40748/75212 [05:01<04:14, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40762/75212 [05:01<04:14, 135.35it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40776/75212 [05:01<04:14, 135.36it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40790/75212 [05:01<04:14, 135.37it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40804/75212 [05:01<04:14, 135.36it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40818/75212 [05:01<04:14, 135.37it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40832/75212 [05:01<04:14, 135.32it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40846/75212 [05:01<04:13, 135.33it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40860/75212 [05:01<04:13, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40874/75212 [05:02<04:13, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40888/75212 [05:02<04:13, 135.33it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40902/75212 [05:02<04:13, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40916/75212 [05:02<04:13, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40930/75212 [05:02<04:13, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40944/75212 [05:02<04:13, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40958/75212 [05:02<04:13, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40972/75212 [05:02<04:12, 135.34it/s][A[A

Selecting Coreset Indices.:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40986/75212 [05:02<04:12, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41000/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41014/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41028/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41042/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41056/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41070/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41084/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41098/75212 [05:03<04:12, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41112/75212 [05:03<04:11, 135.37it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41126/75212 [05:03<04:11, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41140/75212 [05:04<04:11, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41154/75212 [05:04<04:11, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41168/75212 [05:04<04:11, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41182/75212 [05:04<04:11, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41196/75212 [05:04<04:11, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41210/75212 [05:04<04:11, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41224/75212 [05:04<04:11, 135.32it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41238/75212 [05:04<04:11, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41252/75212 [05:04<04:10, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41266/75212 [05:04<04:10, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41280/75212 [05:05<04:10, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41294/75212 [05:05<04:10, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41308/75212 [05:05<04:10, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41322/75212 [05:05<04:10, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41336/75212 [05:05<04:10, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41350/75212 [05:05<04:10, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41364/75212 [05:05<04:10, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41378/75212 [05:05<04:09, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41392/75212 [05:05<04:09, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41406/75212 [05:06<04:09, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41420/75212 [05:06<04:09, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41434/75212 [05:06<04:09, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41448/75212 [05:06<04:09, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41462/75212 [05:06<04:09, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41476/75212 [05:06<04:09, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41490/75212 [05:06<04:09, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41504/75212 [05:06<04:09, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41518/75212 [05:06<04:08, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41532/75212 [05:06<04:08, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41546/75212 [05:07<04:08, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41560/75212 [05:07<04:08, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41574/75212 [05:07<04:08, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41588/75212 [05:07<04:08, 135.33it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41602/75212 [05:07<04:08, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41616/75212 [05:07<04:08, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41630/75212 [05:07<04:08, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41644/75212 [05:07<04:08, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41658/75212 [05:07<04:07, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41672/75212 [05:07<04:07, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41686/75212 [05:08<04:07, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41700/75212 [05:08<04:07, 135.34it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41714/75212 [05:08<04:07, 135.35it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41728/75212 [05:08<04:07, 135.36it/s][A[A

Selecting Coreset Indices.:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41742/75212 [05:08<04:07, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41756/75212 [05:08<04:07, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41770/75212 [05:08<04:07, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41784/75212 [05:08<04:06, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41798/75212 [05:08<04:06, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41812/75212 [05:09<04:06, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41826/75212 [05:09<04:06, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41840/75212 [05:09<04:06, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41854/75212 [05:09<04:06, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41868/75212 [05:09<04:06, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41882/75212 [05:09<04:06, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41896/75212 [05:09<04:06, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41910/75212 [05:09<04:06, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41924/75212 [05:09<04:05, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41938/75212 [05:09<04:05, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41952/75212 [05:10<04:05, 135.33it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41966/75212 [05:10<04:05, 135.32it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41980/75212 [05:10<04:05, 135.33it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41994/75212 [05:10<04:05, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42008/75212 [05:10<04:05, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42022/75212 [05:10<04:05, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42036/75212 [05:10<04:05, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42050/75212 [05:10<04:05, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42064/75212 [05:10<04:04, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42078/75212 [05:10<04:04, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42092/75212 [05:11<04:04, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42106/75212 [05:11<04:04, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42120/75212 [05:11<04:04, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42134/75212 [05:11<04:04, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42148/75212 [05:11<04:04, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42162/75212 [05:11<04:04, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42176/75212 [05:11<04:04, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42190/75212 [05:11<04:03, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42204/75212 [05:11<04:03, 135.37it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42218/75212 [05:12<04:03, 135.37it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42232/75212 [05:12<04:03, 135.37it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42246/75212 [05:12<04:03, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42260/75212 [05:12<04:03, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42274/75212 [05:12<04:03, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42288/75212 [05:12<04:03, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42302/75212 [05:12<04:03, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42316/75212 [05:12<04:03, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42330/75212 [05:12<04:02, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42344/75212 [05:12<04:02, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42358/75212 [05:13<04:02, 135.34it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42372/75212 [05:13<04:02, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42386/75212 [05:13<04:02, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42400/75212 [05:13<04:02, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42414/75212 [05:13<04:02, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42428/75212 [05:13<04:02, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42442/75212 [05:13<04:02, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42456/75212 [05:13<04:02, 135.35it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42470/75212 [05:13<04:01, 135.36it/s][A[A

Selecting Coreset Indices.:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42484/75212 [05:13<04:01, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42498/75212 [05:14<04:01, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42512/75212 [05:14<04:01, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42526/75212 [05:14<04:01, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42540/75212 [05:14<04:01, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42554/75212 [05:14<04:01, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42568/75212 [05:14<04:01, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42582/75212 [05:14<04:01, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42596/75212 [05:14<04:00, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42610/75212 [05:14<04:00, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42624/75212 [05:15<04:00, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42638/75212 [05:15<04:00, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42652/75212 [05:15<04:00, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42666/75212 [05:15<04:00, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42680/75212 [05:15<04:00, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42694/75212 [05:15<04:00, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42708/75212 [05:15<04:00, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42722/75212 [05:15<04:00, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42736/75212 [05:15<03:59, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42750/75212 [05:15<03:59, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42764/75212 [05:16<03:59, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42778/75212 [05:16<03:59, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42792/75212 [05:16<03:59, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42806/75212 [05:16<03:59, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42820/75212 [05:16<03:59, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42834/75212 [05:16<03:59, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42848/75212 [05:16<03:59, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42862/75212 [05:16<03:59, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42876/75212 [05:16<03:58, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42890/75212 [05:16<03:58, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42904/75212 [05:17<03:58, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42918/75212 [05:17<03:58, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42932/75212 [05:17<03:58, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42946/75212 [05:17<03:58, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42960/75212 [05:17<03:58, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42974/75212 [05:17<03:58, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 42988/75212 [05:17<03:58, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43002/75212 [05:17<03:57, 135.36it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43016/75212 [05:17<03:57, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43030/75212 [05:18<03:57, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43044/75212 [05:18<03:57, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43058/75212 [05:18<03:57, 135.33it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43072/75212 [05:18<03:57, 135.32it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43086/75212 [05:18<03:57, 135.33it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43100/75212 [05:18<03:57, 135.33it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43114/75212 [05:18<03:57, 135.33it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43128/75212 [05:18<03:57, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43142/75212 [05:18<03:56, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43156/75212 [05:18<03:56, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43170/75212 [05:19<03:56, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43184/75212 [05:19<03:56, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43198/75212 [05:19<03:56, 135.34it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43212/75212 [05:19<03:56, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43226/75212 [05:19<03:56, 135.35it/s][A[A

Selecting Coreset Indices.:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43240/75212 [05:19<03:56, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43254/75212 [05:19<03:56, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43268/75212 [05:19<03:56, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43282/75212 [05:19<03:55, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43296/75212 [05:19<03:55, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43310/75212 [05:20<03:55, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43324/75212 [05:20<03:55, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43338/75212 [05:20<03:55, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43352/75212 [05:20<03:55, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43366/75212 [05:20<03:55, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43380/75212 [05:20<03:55, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43394/75212 [05:20<03:55, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43408/75212 [05:20<03:54, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43422/75212 [05:20<03:54, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43436/75212 [05:21<03:54, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43450/75212 [05:21<03:54, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43464/75212 [05:21<03:54, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43478/75212 [05:21<03:54, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43492/75212 [05:21<03:54, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43506/75212 [05:21<03:54, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43520/75212 [05:21<03:54, 135.33it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43534/75212 [05:21<03:54, 135.33it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43548/75212 [05:21<03:53, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43562/75212 [05:21<03:53, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43576/75212 [05:22<03:53, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43590/75212 [05:22<03:53, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43604/75212 [05:22<03:53, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43618/75212 [05:22<03:53, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43632/75212 [05:22<03:53, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43646/75212 [05:22<03:53, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43660/75212 [05:22<03:53, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43674/75212 [05:22<03:53, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43688/75212 [05:22<03:52, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43702/75212 [05:22<03:52, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43716/75212 [05:23<03:52, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43730/75212 [05:23<03:52, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43744/75212 [05:23<03:52, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43758/75212 [05:23<03:52, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43772/75212 [05:23<03:52, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43786/75212 [05:23<03:52, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43800/75212 [05:23<03:52, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43814/75212 [05:23<03:51, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43828/75212 [05:23<03:51, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43842/75212 [05:24<03:51, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43856/75212 [05:24<03:51, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43870/75212 [05:24<03:51, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43884/75212 [05:24<03:51, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43898/75212 [05:24<03:51, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43912/75212 [05:24<03:51, 135.35it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43926/75212 [05:24<03:51, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43940/75212 [05:24<03:51, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43954/75212 [05:24<03:50, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43968/75212 [05:24<03:50, 135.34it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43982/75212 [05:25<03:50, 135.36it/s][A[A

Selecting Coreset Indices.:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 43996/75212 [05:25<03:50, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44010/75212 [05:25<03:50, 135.26it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44024/75212 [05:25<03:50, 135.30it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44038/75212 [05:25<03:50, 135.32it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44052/75212 [05:25<03:50, 135.32it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44066/75212 [05:25<03:50, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44080/75212 [05:25<03:50, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44094/75212 [05:25<03:49, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44108/75212 [05:25<03:49, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44122/75212 [05:26<03:49, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44136/75212 [05:26<03:49, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44150/75212 [05:26<03:49, 135.32it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44164/75212 [05:26<03:49, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44178/75212 [05:26<03:49, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44192/75212 [05:26<03:49, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44206/75212 [05:26<03:49, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44220/75212 [05:26<03:48, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44234/75212 [05:26<03:48, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44248/75212 [05:27<03:48, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44262/75212 [05:27<03:48, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44276/75212 [05:27<03:48, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44290/75212 [05:27<03:48, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44304/75212 [05:27<03:48, 135.33it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44318/75212 [05:27<03:48, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44332/75212 [05:27<03:48, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44346/75212 [05:27<03:48, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44360/75212 [05:27<03:47, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44374/75212 [05:27<03:47, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44388/75212 [05:28<03:47, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44402/75212 [05:28<03:47, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44416/75212 [05:28<03:47, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44430/75212 [05:28<03:47, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44444/75212 [05:28<03:47, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44458/75212 [05:28<03:47, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44472/75212 [05:28<03:47, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44486/75212 [05:28<03:47, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44500/75212 [05:28<03:46, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44514/75212 [05:28<03:46, 135.36it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44528/75212 [05:29<03:46, 135.36it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44542/75212 [05:29<03:46, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44556/75212 [05:29<03:46, 135.36it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44570/75212 [05:29<03:46, 135.36it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44584/75212 [05:29<03:46, 135.36it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44598/75212 [05:29<03:46, 135.36it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44612/75212 [05:29<03:46, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44626/75212 [05:29<03:45, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44640/75212 [05:29<03:45, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44654/75212 [05:30<03:45, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44668/75212 [05:30<03:45, 135.35it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44682/75212 [05:30<03:45, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44696/75212 [05:30<03:45, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44710/75212 [05:30<03:45, 135.36it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44724/75212 [05:30<03:45, 135.34it/s][A[A

Selecting Coreset Indices.:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44738/75212 [05:30<03:45, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44752/75212 [05:30<03:45, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44766/75212 [05:30<03:44, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44780/75212 [05:30<03:44, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44794/75212 [05:31<03:44, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44808/75212 [05:31<03:44, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44822/75212 [05:31<03:44, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44836/75212 [05:31<03:44, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44850/75212 [05:31<03:44, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44864/75212 [05:31<03:44, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44878/75212 [05:31<03:44, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44892/75212 [05:31<03:44, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44906/75212 [05:31<03:43, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44920/75212 [05:31<03:43, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44934/75212 [05:32<03:43, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44948/75212 [05:32<03:43, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44962/75212 [05:32<03:43, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44976/75212 [05:32<03:43, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 44990/75212 [05:32<03:43, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45004/75212 [05:32<03:43, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45018/75212 [05:32<03:43, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45032/75212 [05:32<03:42, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45046/75212 [05:32<03:42, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45060/75212 [05:33<03:42, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45074/75212 [05:33<03:42, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45088/75212 [05:33<03:42, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45102/75212 [05:33<03:42, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45116/75212 [05:33<03:42, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45130/75212 [05:33<03:42, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45144/75212 [05:33<03:42, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45158/75212 [05:33<03:42, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45172/75212 [05:33<03:41, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45186/75212 [05:33<03:41, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45200/75212 [05:34<03:41, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45214/75212 [05:34<03:41, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45228/75212 [05:34<03:41, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45242/75212 [05:34<03:41, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45256/75212 [05:34<03:41, 135.33it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45270/75212 [05:34<03:41, 135.32it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45284/75212 [05:34<03:41, 135.33it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45298/75212 [05:34<03:41, 135.33it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45312/75212 [05:34<03:40, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45326/75212 [05:34<03:40, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45340/75212 [05:35<03:40, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45354/75212 [05:35<03:40, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45368/75212 [05:35<03:40, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45382/75212 [05:35<03:40, 135.37it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45396/75212 [05:35<03:40, 135.37it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45410/75212 [05:35<03:40, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45424/75212 [05:35<03:40, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45438/75212 [05:35<03:39, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45452/75212 [05:35<03:39, 135.36it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45466/75212 [05:36<03:39, 135.35it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45480/75212 [05:36<03:39, 135.34it/s][A[A

Selecting Coreset Indices.:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45494/75212 [05:36<03:39, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45508/75212 [05:36<03:39, 135.33it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45522/75212 [05:36<03:39, 135.32it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45536/75212 [05:36<03:39, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45550/75212 [05:36<03:39, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45564/75212 [05:36<03:39, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45578/75212 [05:36<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45592/75212 [05:36<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45606/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45620/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45634/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45648/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45662/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45676/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45690/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45704/75212 [05:37<03:38, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45718/75212 [05:37<03:37, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45732/75212 [05:37<03:37, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45746/75212 [05:38<03:37, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45760/75212 [05:38<03:37, 135.33it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45774/75212 [05:38<03:37, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45788/75212 [05:38<03:37, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45802/75212 [05:38<03:37, 135.33it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45816/75212 [05:38<03:37, 135.33it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45830/75212 [05:38<03:37, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45844/75212 [05:38<03:36, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45858/75212 [05:38<03:36, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45872/75212 [05:39<03:36, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45886/75212 [05:39<03:36, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45900/75212 [05:39<03:36, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45914/75212 [05:39<03:36, 135.34it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45928/75212 [05:39<03:36, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45942/75212 [05:39<03:36, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45956/75212 [05:39<03:36, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45970/75212 [05:39<03:36, 135.37it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45984/75212 [05:39<03:35, 135.37it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45998/75212 [05:39<03:35, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46012/75212 [05:40<03:35, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46026/75212 [05:40<03:35, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46040/75212 [05:40<03:35, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46054/75212 [05:40<03:35, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46068/75212 [05:40<03:35, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46082/75212 [05:40<03:35, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46096/75212 [05:40<03:35, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46110/75212 [05:40<03:34, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46124/75212 [05:40<03:34, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46138/75212 [05:40<03:34, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46152/75212 [05:41<03:34, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46166/75212 [05:41<03:34, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46180/75212 [05:41<03:34, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46194/75212 [05:41<03:34, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46208/75212 [05:41<03:34, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46222/75212 [05:41<03:34, 135.36it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46236/75212 [05:41<03:34, 135.35it/s][A[A

Selecting Coreset Indices.:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46250/75212 [05:41<03:33, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46264/75212 [05:41<03:33, 135.34it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46278/75212 [05:42<03:33, 135.33it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46292/75212 [05:42<03:33, 135.34it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46306/75212 [05:42<03:33, 135.33it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46320/75212 [05:42<03:33, 135.34it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46334/75212 [05:42<03:33, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46348/75212 [05:42<03:33, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46362/75212 [05:42<03:33, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46376/75212 [05:42<03:33, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46390/75212 [05:42<03:32, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46404/75212 [05:42<03:32, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46418/75212 [05:43<03:32, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46432/75212 [05:43<03:32, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46446/75212 [05:43<03:32, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46460/75212 [05:43<03:32, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46474/75212 [05:43<03:32, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46488/75212 [05:43<03:32, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46502/75212 [05:43<03:32, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46516/75212 [05:43<03:31, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46530/75212 [05:43<03:31, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46544/75212 [05:43<03:31, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46558/75212 [05:44<03:31, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46572/75212 [05:44<03:31, 135.34it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46586/75212 [05:44<03:31, 135.34it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46600/75212 [05:44<03:31, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46614/75212 [05:44<03:31, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46628/75212 [05:44<03:31, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46642/75212 [05:44<03:31, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46656/75212 [05:44<03:30, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46670/75212 [05:44<03:30, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46684/75212 [05:45<03:30, 135.37it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46698/75212 [05:45<03:30, 135.37it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46712/75212 [05:45<03:30, 135.37it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46726/75212 [05:45<03:30, 135.37it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46740/75212 [05:45<03:30, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46754/75212 [05:45<03:30, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46768/75212 [05:45<03:30, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46782/75212 [05:45<03:30, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46796/75212 [05:45<03:29, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46810/75212 [05:45<03:29, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46824/75212 [05:46<03:29, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46838/75212 [05:46<03:29, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46852/75212 [05:46<03:29, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46866/75212 [05:46<03:29, 135.34it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46880/75212 [05:46<03:29, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46894/75212 [05:46<03:29, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46908/75212 [05:46<03:29, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46922/75212 [05:46<03:28, 135.37it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46936/75212 [05:46<03:28, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46950/75212 [05:46<03:28, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46964/75212 [05:47<03:28, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46978/75212 [05:47<03:28, 135.36it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46992/75212 [05:47<03:28, 135.35it/s][A[A

Selecting Coreset Indices.:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47006/75212 [05:47<03:28, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47020/75212 [05:47<03:28, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47034/75212 [05:47<03:28, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47048/75212 [05:47<03:28, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47062/75212 [05:47<03:27, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47076/75212 [05:47<03:27, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47090/75212 [05:48<03:27, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47104/75212 [05:48<03:27, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47118/75212 [05:48<03:27, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47132/75212 [05:48<03:27, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47146/75212 [05:48<03:27, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47160/75212 [05:48<03:27, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47174/75212 [05:48<03:27, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47188/75212 [05:48<03:27, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47202/75212 [05:48<03:26, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47216/75212 [05:48<03:26, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47230/75212 [05:49<03:26, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47244/75212 [05:49<03:26, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47258/75212 [05:49<03:26, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47272/75212 [05:49<03:26, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47286/75212 [05:49<03:26, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47300/75212 [05:49<03:26, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47314/75212 [05:49<03:26, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47328/75212 [05:49<03:25, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47342/75212 [05:49<03:25, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47356/75212 [05:49<03:25, 135.38it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47370/75212 [05:50<03:25, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47384/75212 [05:50<03:25, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47398/75212 [05:50<03:25, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47412/75212 [05:50<03:25, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47426/75212 [05:50<03:25, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47440/75212 [05:50<03:25, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47454/75212 [05:50<03:25, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47468/75212 [05:50<03:24, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47482/75212 [05:50<03:24, 135.38it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47496/75212 [05:51<03:24, 135.37it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47510/75212 [05:51<03:24, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47524/75212 [05:51<03:24, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47538/75212 [05:51<03:24, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47552/75212 [05:51<03:24, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47566/75212 [05:51<03:24, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47580/75212 [05:51<03:24, 135.36it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47594/75212 [05:51<03:24, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47608/75212 [05:51<03:23, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47622/75212 [05:51<03:23, 135.34it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47636/75212 [05:52<03:23, 135.33it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47650/75212 [05:52<03:23, 135.33it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47664/75212 [05:52<03:23, 135.33it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47678/75212 [05:52<03:23, 135.33it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47692/75212 [05:52<03:23, 135.33it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47706/75212 [05:52<03:23, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47720/75212 [05:52<03:23, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47734/75212 [05:52<03:23, 135.35it/s][A[A

Selecting Coreset Indices.:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47748/75212 [05:52<03:22, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47762/75212 [05:52<03:22, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47776/75212 [05:53<03:22, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47790/75212 [05:53<03:22, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47804/75212 [05:53<03:22, 135.37it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47818/75212 [05:53<03:22, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47832/75212 [05:53<03:22, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47846/75212 [05:53<03:22, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47860/75212 [05:53<03:22, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47874/75212 [05:53<03:21, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47888/75212 [05:53<03:21, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47902/75212 [05:54<03:21, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47916/75212 [05:54<03:21, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47930/75212 [05:54<03:21, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47944/75212 [05:54<03:21, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47958/75212 [05:54<03:21, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47972/75212 [05:54<03:21, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47986/75212 [05:54<03:21, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48000/75212 [05:54<03:21, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48014/75212 [05:54<03:20, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48028/75212 [05:54<03:20, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48042/75212 [05:55<03:20, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48056/75212 [05:55<03:20, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48070/75212 [05:55<03:20, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48084/75212 [05:55<03:20, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48098/75212 [05:55<03:20, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48112/75212 [05:55<03:20, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48126/75212 [05:55<03:20, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48140/75212 [05:55<03:19, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48154/75212 [05:55<03:19, 135.37it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48168/75212 [05:55<03:19, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48182/75212 [05:56<03:19, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48196/75212 [05:56<03:19, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48210/75212 [05:56<03:19, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48224/75212 [05:56<03:19, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48238/75212 [05:56<03:19, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48252/75212 [05:56<03:19, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48266/75212 [05:56<03:19, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48280/75212 [05:56<03:18, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48294/75212 [05:56<03:18, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48308/75212 [05:57<03:18, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48322/75212 [05:57<03:18, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48336/75212 [05:57<03:18, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48350/75212 [05:57<03:18, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48364/75212 [05:57<03:18, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48378/75212 [05:57<03:18, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48392/75212 [05:57<03:18, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48406/75212 [05:57<03:18, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48420/75212 [05:57<03:17, 135.34it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48434/75212 [05:57<03:17, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48448/75212 [05:58<03:17, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48462/75212 [05:58<03:17, 135.35it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48476/75212 [05:58<03:17, 135.36it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48490/75212 [05:58<03:17, 135.37it/s][A[A

Selecting Coreset Indices.:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48504/75212 [05:58<03:17, 135.36it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48518/75212 [05:58<03:17, 135.36it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48532/75212 [05:58<03:17, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48546/75212 [05:58<03:17, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48560/75212 [05:58<03:16, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48574/75212 [05:58<03:16, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48588/75212 [05:59<03:16, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48602/75212 [05:59<03:16, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48616/75212 [05:59<03:16, 135.33it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48630/75212 [05:59<03:16, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48644/75212 [05:59<03:16, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48658/75212 [05:59<03:16, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48672/75212 [05:59<03:16, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48686/75212 [05:59<03:15, 135.36it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48700/75212 [05:59<03:15, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48714/75212 [06:00<03:15, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48728/75212 [06:00<03:15, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48742/75212 [06:00<03:15, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48756/75212 [06:00<03:16, 134.82it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48770/75212 [06:00<03:15, 134.97it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48784/75212 [06:00<03:15, 135.08it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48798/75212 [06:00<03:15, 135.16it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48812/75212 [06:00<03:15, 135.22it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48826/75212 [06:00<03:15, 135.25it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48840/75212 [06:00<03:14, 135.28it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48854/75212 [06:01<03:14, 135.30it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48868/75212 [06:01<03:14, 135.32it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48882/75212 [06:01<03:14, 135.33it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48896/75212 [06:01<03:14, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48910/75212 [06:01<03:14, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48924/75212 [06:01<03:14, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48938/75212 [06:01<03:14, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48952/75212 [06:01<03:14, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48966/75212 [06:01<03:13, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48980/75212 [06:01<03:13, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48994/75212 [06:02<03:13, 135.36it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49008/75212 [06:02<03:13, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49022/75212 [06:02<03:13, 135.36it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49036/75212 [06:02<03:13, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49050/75212 [06:02<03:13, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49064/75212 [06:02<03:13, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49078/75212 [06:02<03:13, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49092/75212 [06:02<03:12, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49106/75212 [06:02<03:12, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49120/75212 [06:03<03:12, 135.33it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49134/75212 [06:03<03:12, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49148/75212 [06:03<03:12, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49162/75212 [06:03<03:12, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49176/75212 [06:03<03:12, 135.35it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49190/75212 [06:03<03:12, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49204/75212 [06:03<03:12, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49218/75212 [06:03<03:12, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49232/75212 [06:03<03:11, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49246/75212 [06:03<03:11, 135.34it/s][A[A

Selecting Coreset Indices.:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49260/75212 [06:04<03:11, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49274/75212 [06:04<03:11, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49288/75212 [06:04<03:11, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49302/75212 [06:04<03:11, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49316/75212 [06:04<03:11, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49330/75212 [06:04<03:11, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49344/75212 [06:04<03:11, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49358/75212 [06:04<03:11, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49372/75212 [06:04<03:10, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49386/75212 [06:04<03:10, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49400/75212 [06:05<03:10, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49414/75212 [06:05<03:10, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49428/75212 [06:05<03:10, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49442/75212 [06:05<03:10, 135.33it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49456/75212 [06:05<03:10, 135.33it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49470/75212 [06:05<03:10, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49484/75212 [06:05<03:10, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49498/75212 [06:05<03:09, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49512/75212 [06:05<03:09, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49526/75212 [06:06<03:09, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49540/75212 [06:06<03:09, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49554/75212 [06:06<03:09, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49568/75212 [06:06<03:09, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49582/75212 [06:06<03:09, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49596/75212 [06:06<03:09, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49610/75212 [06:06<03:09, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49624/75212 [06:06<03:09, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49638/75212 [06:06<03:08, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49652/75212 [06:06<03:08, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49666/75212 [06:07<03:08, 135.37it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49680/75212 [06:07<03:08, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49694/75212 [06:07<03:08, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49708/75212 [06:07<03:08, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49722/75212 [06:07<03:08, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49736/75212 [06:07<03:08, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49750/75212 [06:07<03:08, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49764/75212 [06:07<03:08, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49778/75212 [06:07<03:07, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49792/75212 [06:07<03:07, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49806/75212 [06:08<03:07, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49820/75212 [06:08<03:07, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49834/75212 [06:08<03:07, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49848/75212 [06:08<03:07, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49862/75212 [06:08<03:07, 135.34it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49876/75212 [06:08<03:07, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49890/75212 [06:08<03:07, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49904/75212 [06:08<03:06, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49918/75212 [06:08<03:06, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49932/75212 [06:09<03:06, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49946/75212 [06:09<03:06, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49960/75212 [06:09<03:06, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49974/75212 [06:09<03:06, 135.35it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49988/75212 [06:09<03:06, 135.36it/s][A[A

Selecting Coreset Indices.:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50002/75212 [06:09<03:06, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50016/75212 [06:09<03:06, 135.37it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50030/75212 [06:09<03:06, 135.37it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50044/75212 [06:09<03:05, 135.37it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50058/75212 [06:09<03:05, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50072/75212 [06:10<03:05, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50086/75212 [06:10<03:05, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50100/75212 [06:10<03:05, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50114/75212 [06:10<03:05, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50128/75212 [06:10<03:05, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50142/75212 [06:10<03:05, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50156/75212 [06:10<03:05, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50170/75212 [06:10<03:05, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50184/75212 [06:10<03:04, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50198/75212 [06:10<03:04, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50212/75212 [06:11<03:04, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50226/75212 [06:11<03:04, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50240/75212 [06:11<03:04, 135.33it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50254/75212 [06:11<03:04, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50268/75212 [06:11<03:04, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50282/75212 [06:11<03:04, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50296/75212 [06:11<03:04, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50310/75212 [06:11<03:03, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50324/75212 [06:11<03:03, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50338/75212 [06:12<03:03, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50352/75212 [06:12<03:03, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50366/75212 [06:12<03:03, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50380/75212 [06:12<03:04, 134.52it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50394/75212 [06:12<03:04, 134.75it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50408/75212 [06:12<03:03, 134.93it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50422/75212 [06:12<03:03, 135.06it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50436/75212 [06:12<03:03, 135.13it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50450/75212 [06:12<03:03, 135.19it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50464/75212 [06:12<03:02, 135.24it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50478/75212 [06:13<03:02, 135.27it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50492/75212 [06:13<03:02, 135.29it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50506/75212 [06:13<03:02, 135.31it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50520/75212 [06:13<03:02, 135.32it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50534/75212 [06:13<03:02, 135.33it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50548/75212 [06:13<03:02, 135.33it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50562/75212 [06:13<03:02, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50576/75212 [06:13<03:02, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50590/75212 [06:13<03:01, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50604/75212 [06:13<03:01, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50618/75212 [06:14<03:01, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50632/75212 [06:14<03:01, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50646/75212 [06:14<03:01, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50660/75212 [06:14<03:01, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50674/75212 [06:14<03:01, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50688/75212 [06:14<03:01, 135.35it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50702/75212 [06:14<03:01, 135.36it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50716/75212 [06:14<03:00, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50730/75212 [06:14<03:00, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50744/75212 [06:15<03:00, 135.34it/s][A[A

Selecting Coreset Indices.:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50758/75212 [06:15<03:00, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50772/75212 [06:15<03:00, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50786/75212 [06:15<03:00, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50800/75212 [06:15<03:00, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50814/75212 [06:15<03:00, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50828/75212 [06:15<03:00, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50842/75212 [06:15<03:00, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50856/75212 [06:15<02:59, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50870/75212 [06:15<02:59, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50884/75212 [06:16<02:59, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50898/75212 [06:16<02:59, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50912/75212 [06:16<02:59, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50926/75212 [06:16<02:59, 135.33it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50940/75212 [06:16<02:59, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50954/75212 [06:16<02:59, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50968/75212 [06:16<02:59, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50982/75212 [06:16<02:59, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50996/75212 [06:16<02:58, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51010/75212 [06:16<02:58, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51024/75212 [06:17<02:58, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51038/75212 [06:17<02:58, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51052/75212 [06:17<02:58, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51066/75212 [06:17<02:58, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51080/75212 [06:17<02:58, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51094/75212 [06:17<02:58, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51108/75212 [06:17<02:58, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51122/75212 [06:17<02:57, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51136/75212 [06:17<02:57, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51150/75212 [06:18<02:57, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51164/75212 [06:18<02:57, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51178/75212 [06:18<02:57, 135.34it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51192/75212 [06:18<02:57, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51206/75212 [06:18<02:57, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51220/75212 [06:18<02:57, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51234/75212 [06:18<02:57, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51248/75212 [06:18<02:57, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51262/75212 [06:18<02:56, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51276/75212 [06:18<02:56, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51290/75212 [06:19<02:56, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51304/75212 [06:19<02:56, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51318/75212 [06:19<02:56, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51332/75212 [06:19<02:56, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51346/75212 [06:19<02:56, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51360/75212 [06:19<02:56, 135.37it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51374/75212 [06:19<02:56, 135.37it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51388/75212 [06:19<02:56, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51402/75212 [06:19<02:55, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51416/75212 [06:19<02:55, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51430/75212 [06:20<02:55, 135.37it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51444/75212 [06:20<02:55, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51458/75212 [06:20<02:55, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51472/75212 [06:20<02:55, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51486/75212 [06:20<02:55, 135.35it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51500/75212 [06:20<02:55, 135.36it/s][A[A

Selecting Coreset Indices.:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51514/75212 [06:20<02:55, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51528/75212 [06:20<02:54, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51542/75212 [06:20<02:54, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51556/75212 [06:21<02:54, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51570/75212 [06:21<02:54, 135.37it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51584/75212 [06:21<02:54, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51598/75212 [06:21<02:54, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51612/75212 [06:21<02:54, 135.33it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51626/75212 [06:21<02:54, 135.33it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51640/75212 [06:21<02:54, 135.33it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51654/75212 [06:21<02:54, 135.33it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51668/75212 [06:21<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51682/75212 [06:21<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51696/75212 [06:22<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51710/75212 [06:22<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51724/75212 [06:22<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51738/75212 [06:22<02:53, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51752/75212 [06:22<02:53, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51766/75212 [06:22<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51780/75212 [06:22<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51794/75212 [06:22<02:53, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51808/75212 [06:22<02:52, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51822/75212 [06:22<02:52, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51836/75212 [06:23<02:52, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51850/75212 [06:23<02:52, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51864/75212 [06:23<02:52, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51878/75212 [06:23<02:52, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51892/75212 [06:23<02:52, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51906/75212 [06:23<02:52, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51920/75212 [06:23<02:52, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51934/75212 [06:23<02:51, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51948/75212 [06:23<02:51, 135.37it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51962/75212 [06:24<02:51, 135.37it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51976/75212 [06:24<02:51, 135.37it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51990/75212 [06:24<02:51, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52004/75212 [06:24<02:51, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52018/75212 [06:24<02:51, 135.32it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52032/75212 [06:24<02:51, 135.30it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52046/75212 [06:24<02:51, 135.30it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52060/75212 [06:24<02:51, 135.33it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52074/75212 [06:24<02:50, 135.33it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52088/75212 [06:24<02:50, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52102/75212 [06:25<02:50, 135.36it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52116/75212 [06:25<02:50, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52130/75212 [06:25<02:50, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52144/75212 [06:25<02:50, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52158/75212 [06:25<02:50, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52172/75212 [06:25<02:50, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52186/75212 [06:25<02:50, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52200/75212 [06:25<02:50, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52214/75212 [06:25<02:49, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52228/75212 [06:25<02:49, 135.34it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52242/75212 [06:26<02:49, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52256/75212 [06:26<02:49, 135.35it/s][A[A

Selecting Coreset Indices.:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52270/75212 [06:26<02:49, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52284/75212 [06:26<02:49, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52298/75212 [06:26<02:49, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52312/75212 [06:26<02:49, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52326/75212 [06:26<02:49, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52340/75212 [06:26<02:48, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52354/75212 [06:26<02:48, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52368/75212 [06:27<02:48, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52382/75212 [06:27<02:48, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52396/75212 [06:27<02:48, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52410/75212 [06:27<02:48, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52424/75212 [06:27<02:48, 135.37it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52438/75212 [06:27<02:48, 135.37it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52452/75212 [06:27<02:48, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52466/75212 [06:27<02:48, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52480/75212 [06:27<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52494/75212 [06:27<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52508/75212 [06:28<02:47, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52522/75212 [06:28<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52536/75212 [06:28<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52550/75212 [06:28<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52564/75212 [06:28<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52578/75212 [06:28<02:47, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52592/75212 [06:28<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52606/75212 [06:28<02:47, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52620/75212 [06:28<02:46, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52634/75212 [06:28<02:46, 135.34it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52648/75212 [06:29<02:46, 135.34it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52662/75212 [06:29<02:46, 135.34it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52676/75212 [06:29<02:46, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52690/75212 [06:29<02:46, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52704/75212 [06:29<02:46, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52718/75212 [06:29<02:46, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52732/75212 [06:29<02:46, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52746/75212 [06:29<02:45, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52760/75212 [06:29<02:45, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52774/75212 [06:30<02:45, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52788/75212 [06:30<02:45, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52802/75212 [06:30<02:45, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52816/75212 [06:30<02:45, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52830/75212 [06:30<02:45, 135.34it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52844/75212 [06:30<02:45, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52858/75212 [06:30<02:45, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52872/75212 [06:30<02:45, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52886/75212 [06:30<02:44, 135.36it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52900/75212 [06:30<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52914/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52928/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52942/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52956/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52970/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52984/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52998/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53012/75212 [06:31<02:44, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53026/75212 [06:31<02:43, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53040/75212 [06:31<02:43, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53054/75212 [06:32<02:43, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53068/75212 [06:32<02:43, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53082/75212 [06:32<02:43, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53096/75212 [06:32<02:43, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53110/75212 [06:32<02:43, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53124/75212 [06:32<02:43, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53138/75212 [06:32<02:43, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53152/75212 [06:32<02:42, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53166/75212 [06:32<02:42, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53180/75212 [06:33<02:42, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53194/75212 [06:33<02:42, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53208/75212 [06:33<02:42, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53222/75212 [06:33<02:42, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53236/75212 [06:33<02:42, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53250/75212 [06:33<02:42, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53264/75212 [06:33<02:42, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53278/75212 [06:33<02:42, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53292/75212 [06:33<02:41, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53306/75212 [06:33<02:41, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53320/75212 [06:34<02:41, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53334/75212 [06:34<02:41, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53348/75212 [06:34<02:41, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53362/75212 [06:34<02:41, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53376/75212 [06:34<02:41, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53390/75212 [06:34<02:41, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53404/75212 [06:34<02:41, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53418/75212 [06:34<02:41, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53432/75212 [06:34<02:40, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53446/75212 [06:34<02:40, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53460/75212 [06:35<02:40, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53474/75212 [06:35<02:40, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53488/75212 [06:35<02:40, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53502/75212 [06:35<02:40, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53516/75212 [06:35<02:40, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53530/75212 [06:35<02:40, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53544/75212 [06:35<02:40, 135.34it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53558/75212 [06:35<02:39, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53572/75212 [06:35<02:39, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53586/75212 [06:36<02:39, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53600/75212 [06:36<02:39, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53614/75212 [06:36<02:39, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53628/75212 [06:36<02:39, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53642/75212 [06:36<02:39, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53656/75212 [06:36<02:39, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53670/75212 [06:36<02:39, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53684/75212 [06:36<02:39, 135.36it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53698/75212 [06:36<02:38, 135.37it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53712/75212 [06:36<02:38, 135.37it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53726/75212 [06:37<02:38, 135.37it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53740/75212 [06:37<02:38, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53754/75212 [06:37<02:38, 135.35it/s][A[A

Selecting Coreset Indices.:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53768/75212 [06:37<02:38, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53782/75212 [06:37<02:38, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53796/75212 [06:37<02:38, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53810/75212 [06:37<02:38, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53824/75212 [06:37<02:38, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53838/75212 [06:37<02:37, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53852/75212 [06:37<02:37, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53866/75212 [06:38<02:37, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53880/75212 [06:38<02:37, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53894/75212 [06:38<02:37, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53908/75212 [06:38<02:37, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53922/75212 [06:38<02:37, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53936/75212 [06:38<02:37, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53950/75212 [06:38<02:37, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53964/75212 [06:38<02:36, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53978/75212 [06:38<02:36, 135.37it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53992/75212 [06:39<02:36, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54006/75212 [06:39<02:36, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54020/75212 [06:39<02:36, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54034/75212 [06:39<02:36, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54048/75212 [06:39<02:36, 135.34it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54062/75212 [06:39<02:36, 135.34it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54076/75212 [06:39<02:36, 135.34it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54090/75212 [06:39<02:36, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54104/75212 [06:39<02:35, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54118/75212 [06:39<02:35, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54132/75212 [06:40<02:35, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54146/75212 [06:40<02:35, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54160/75212 [06:40<02:35, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54174/75212 [06:40<02:35, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54188/75212 [06:40<02:35, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54202/75212 [06:40<02:35, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54216/75212 [06:40<02:35, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54230/75212 [06:40<02:35, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54244/75212 [06:40<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54258/75212 [06:40<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54272/75212 [06:41<02:34, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54286/75212 [06:41<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54300/75212 [06:41<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54314/75212 [06:41<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54328/75212 [06:41<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54342/75212 [06:41<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54356/75212 [06:41<02:34, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54370/75212 [06:41<02:33, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54384/75212 [06:41<02:33, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54398/75212 [06:42<02:33, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54412/75212 [06:42<02:33, 135.36it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54426/75212 [06:42<02:33, 135.34it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54440/75212 [06:42<02:33, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54454/75212 [06:42<02:33, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54468/75212 [06:42<02:33, 135.34it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54482/75212 [06:42<02:33, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54496/75212 [06:42<02:33, 135.34it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54510/75212 [06:42<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54524/75212 [06:42<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54538/75212 [06:43<02:32, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54552/75212 [06:43<02:32, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54566/75212 [06:43<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54580/75212 [06:43<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54594/75212 [06:43<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54608/75212 [06:43<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54622/75212 [06:43<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54636/75212 [06:43<02:32, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54650/75212 [06:43<02:31, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54664/75212 [06:43<02:31, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54678/75212 [06:44<02:31, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54692/75212 [06:44<02:31, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54706/75212 [06:44<02:31, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54720/75212 [06:44<02:31, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54734/75212 [06:44<02:31, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54748/75212 [06:44<02:31, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54762/75212 [06:44<02:31, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54776/75212 [06:44<02:30, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54790/75212 [06:44<02:30, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54804/75212 [06:45<02:30, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54818/75212 [06:45<02:30, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54832/75212 [06:45<02:30, 135.37it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54846/75212 [06:45<02:30, 135.37it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54860/75212 [06:45<02:30, 135.37it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54874/75212 [06:45<02:30, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54888/75212 [06:45<02:30, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54902/75212 [06:45<02:30, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54916/75212 [06:45<02:29, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54930/75212 [06:45<02:29, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54944/75212 [06:46<02:29, 135.34it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54958/75212 [06:46<02:29, 135.33it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54972/75212 [06:46<02:29, 135.33it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54986/75212 [06:46<02:29, 135.34it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55000/75212 [06:46<02:29, 135.34it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55014/75212 [06:46<02:29, 135.34it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55028/75212 [06:46<02:29, 135.34it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55042/75212 [06:46<02:29, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55056/75212 [06:46<02:28, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55070/75212 [06:46<02:28, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55084/75212 [06:47<02:28, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55098/75212 [06:47<02:28, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55112/75212 [06:47<02:28, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55126/75212 [06:47<02:28, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55140/75212 [06:47<02:28, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55154/75212 [06:47<02:28, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55168/75212 [06:47<02:28, 135.37it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55182/75212 [06:47<02:27, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55196/75212 [06:47<02:27, 135.37it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55210/75212 [06:48<02:27, 135.36it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55224/75212 [06:48<02:27, 135.35it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55238/75212 [06:48<02:27, 135.34it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55252/75212 [06:48<02:27, 135.33it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55266/75212 [06:48<02:27, 135.34it/s][A[A

Selecting Coreset Indices.:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55280/75212 [06:48<02:27, 135.33it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55294/75212 [06:48<02:27, 135.33it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55308/75212 [06:48<02:27, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55322/75212 [06:48<02:26, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55336/75212 [06:48<02:26, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55350/75212 [06:49<02:26, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55364/75212 [06:49<02:26, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55378/75212 [06:49<02:26, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55392/75212 [06:49<02:26, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55406/75212 [06:49<02:26, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55420/75212 [06:49<02:26, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55434/75212 [06:49<02:26, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55448/75212 [06:49<02:26, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55462/75212 [06:49<02:25, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55476/75212 [06:49<02:25, 135.37it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55490/75212 [06:50<02:25, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55504/75212 [06:50<02:25, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55518/75212 [06:50<02:25, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55532/75212 [06:50<02:25, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55546/75212 [06:50<02:25, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55560/75212 [06:50<02:25, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55574/75212 [06:50<02:25, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55588/75212 [06:50<02:24, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55602/75212 [06:50<02:24, 135.33it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55616/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55630/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55644/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55658/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55672/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55686/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55700/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55714/75212 [06:51<02:24, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55728/75212 [06:51<02:23, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55742/75212 [06:51<02:23, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55756/75212 [06:52<02:23, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55770/75212 [06:52<02:23, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55784/75212 [06:52<02:23, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55798/75212 [06:52<02:23, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55812/75212 [06:52<02:23, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55826/75212 [06:52<02:23, 135.37it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55840/75212 [06:52<02:23, 135.37it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55854/75212 [06:52<02:23, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55868/75212 [06:52<02:22, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55882/75212 [06:52<02:22, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55896/75212 [06:53<02:22, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55910/75212 [06:53<02:22, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55924/75212 [06:53<02:22, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55938/75212 [06:53<02:22, 135.34it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55952/75212 [06:53<02:22, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55966/75212 [06:53<02:22, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55980/75212 [06:53<02:22, 135.36it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55994/75212 [06:53<02:21, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56008/75212 [06:53<02:21, 135.35it/s][A[A

Selecting Coreset Indices.:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56022/75212 [06:54<02:21, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56036/75212 [06:54<02:21, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56050/75212 [06:54<02:21, 135.33it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56064/75212 [06:54<02:21, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56078/75212 [06:54<02:21, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56092/75212 [06:54<02:21, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56106/75212 [06:54<02:21, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56120/75212 [06:54<02:21, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56134/75212 [06:54<02:20, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56148/75212 [06:54<02:20, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56162/75212 [06:55<02:20, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56176/75212 [06:55<02:20, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56190/75212 [06:55<02:20, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56204/75212 [06:55<02:20, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56218/75212 [06:55<02:20, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56232/75212 [06:55<02:20, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56246/75212 [06:55<02:20, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56260/75212 [06:55<02:20, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56274/75212 [06:55<02:19, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56288/75212 [06:55<02:19, 135.37it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56302/75212 [06:56<02:19, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56316/75212 [06:56<02:19, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56330/75212 [06:56<02:19, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56344/75212 [06:56<02:19, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56358/75212 [06:56<02:19, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56372/75212 [06:56<02:19, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56386/75212 [06:56<02:19, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56400/75212 [06:56<02:18, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56414/75212 [06:56<02:18, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56428/75212 [06:57<02:18, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56442/75212 [06:57<02:18, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56456/75212 [06:57<02:18, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56470/75212 [06:57<02:18, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56484/75212 [06:57<02:18, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56498/75212 [06:57<02:18, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56512/75212 [06:57<02:18, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56526/75212 [06:57<02:18, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56540/75212 [06:57<02:17, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56554/75212 [06:57<02:17, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56568/75212 [06:58<02:17, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56582/75212 [06:58<02:17, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56596/75212 [06:58<02:17, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56610/75212 [06:58<02:17, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56624/75212 [06:58<02:17, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56638/75212 [06:58<02:17, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56652/75212 [06:58<02:17, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56666/75212 [06:58<02:17, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56680/75212 [06:58<02:16, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56694/75212 [06:58<02:16, 135.36it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56708/75212 [06:59<02:16, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56722/75212 [06:59<02:16, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56736/75212 [06:59<02:16, 135.34it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56750/75212 [06:59<02:16, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56764/75212 [06:59<02:16, 135.35it/s][A[A

Selecting Coreset Indices.:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56778/75212 [06:59<02:16, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56792/75212 [06:59<02:16, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56806/75212 [06:59<02:15, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56820/75212 [06:59<02:15, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56834/75212 [07:00<02:15, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56848/75212 [07:00<02:15, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56862/75212 [07:00<02:15, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56876/75212 [07:00<02:15, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56890/75212 [07:00<02:15, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56904/75212 [07:00<02:15, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56918/75212 [07:00<02:15, 135.33it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56932/75212 [07:00<02:15, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56946/75212 [07:00<02:14, 135.33it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56960/75212 [07:00<02:14, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56974/75212 [07:01<02:14, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 56988/75212 [07:01<02:14, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57002/75212 [07:01<02:14, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57016/75212 [07:01<02:14, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57030/75212 [07:01<02:14, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57044/75212 [07:01<02:14, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57058/75212 [07:01<02:14, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57072/75212 [07:01<02:14, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57086/75212 [07:01<02:13, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57100/75212 [07:01<02:13, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57114/75212 [07:02<02:13, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57128/75212 [07:02<02:13, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57142/75212 [07:02<02:13, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57156/75212 [07:02<02:13, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57170/75212 [07:02<02:13, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57184/75212 [07:02<02:13, 135.37it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57198/75212 [07:02<02:13, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57212/75212 [07:02<02:12, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57226/75212 [07:02<02:12, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57240/75212 [07:03<02:12, 135.37it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57254/75212 [07:03<02:12, 135.37it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57268/75212 [07:03<02:12, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57282/75212 [07:03<02:12, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57296/75212 [07:03<02:12, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57310/75212 [07:03<02:12, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57324/75212 [07:03<02:12, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57338/75212 [07:03<02:12, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57352/75212 [07:03<02:11, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57366/75212 [07:03<02:11, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57380/75212 [07:04<02:11, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57394/75212 [07:04<02:11, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57408/75212 [07:04<02:11, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57422/75212 [07:04<02:11, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57436/75212 [07:04<02:11, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57450/75212 [07:04<02:11, 135.36it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57464/75212 [07:04<02:11, 135.37it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57478/75212 [07:04<02:11, 135.35it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57492/75212 [07:04<02:10, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57506/75212 [07:04<02:10, 135.34it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57520/75212 [07:05<02:10, 135.33it/s][A[A

Selecting Coreset Indices.:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57534/75212 [07:05<02:10, 135.33it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57548/75212 [07:05<02:10, 135.33it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57562/75212 [07:05<02:10, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57576/75212 [07:05<02:10, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57590/75212 [07:05<02:10, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57604/75212 [07:05<02:10, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57618/75212 [07:05<02:09, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57632/75212 [07:05<02:09, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57646/75212 [07:06<02:09, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57660/75212 [07:06<02:09, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57674/75212 [07:06<02:09, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57688/75212 [07:06<02:09, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57702/75212 [07:06<02:09, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57716/75212 [07:06<02:09, 135.37it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57730/75212 [07:06<02:09, 135.37it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57744/75212 [07:06<02:09, 135.38it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57758/75212 [07:06<02:08, 135.37it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57772/75212 [07:06<02:08, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57786/75212 [07:07<02:08, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57800/75212 [07:07<02:08, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57814/75212 [07:07<02:08, 135.37it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57828/75212 [07:07<02:08, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57842/75212 [07:07<02:08, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57856/75212 [07:07<02:08, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57870/75212 [07:07<02:08, 135.37it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57884/75212 [07:07<02:08, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57898/75212 [07:07<02:07, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57912/75212 [07:07<02:07, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57926/75212 [07:08<02:07, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57940/75212 [07:08<02:07, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57954/75212 [07:08<02:07, 135.34it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57968/75212 [07:08<02:07, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57982/75212 [07:08<02:07, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 57996/75212 [07:08<02:07, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58010/75212 [07:08<02:07, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58024/75212 [07:08<02:06, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58038/75212 [07:08<02:06, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58052/75212 [07:09<02:06, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58066/75212 [07:09<02:06, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58080/75212 [07:09<02:06, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58094/75212 [07:09<02:06, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58108/75212 [07:09<02:06, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58122/75212 [07:09<02:06, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58136/75212 [07:09<02:06, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58150/75212 [07:09<02:06, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58164/75212 [07:09<02:05, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58178/75212 [07:09<02:05, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58192/75212 [07:10<02:05, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58206/75212 [07:10<02:05, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58220/75212 [07:10<02:05, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58234/75212 [07:10<02:05, 135.36it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58248/75212 [07:10<02:05, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58262/75212 [07:10<02:05, 135.35it/s][A[A

Selecting Coreset Indices.:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58276/75212 [07:10<02:05, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58290/75212 [07:10<02:05, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58304/75212 [07:10<02:04, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58318/75212 [07:10<02:04, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58332/75212 [07:11<02:04, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58346/75212 [07:11<02:04, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58360/75212 [07:11<02:04, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58374/75212 [07:11<02:04, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58388/75212 [07:11<02:04, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58402/75212 [07:11<02:04, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58416/75212 [07:11<02:04, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58430/75212 [07:11<02:03, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58444/75212 [07:11<02:03, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58458/75212 [07:12<02:03, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58472/75212 [07:12<02:03, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58486/75212 [07:12<02:03, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58500/75212 [07:12<02:03, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58514/75212 [07:12<02:03, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58528/75212 [07:12<02:03, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58542/75212 [07:12<02:03, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58556/75212 [07:12<02:03, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58570/75212 [07:12<02:02, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58584/75212 [07:12<02:02, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58598/75212 [07:13<02:02, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58612/75212 [07:13<02:02, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58626/75212 [07:13<02:02, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58640/75212 [07:13<02:02, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58654/75212 [07:13<02:02, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58668/75212 [07:13<02:02, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58682/75212 [07:13<02:02, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58696/75212 [07:13<02:02, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58710/75212 [07:13<02:01, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58724/75212 [07:13<02:01, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58738/75212 [07:14<02:01, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58752/75212 [07:14<02:01, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58766/75212 [07:14<02:01, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58780/75212 [07:14<02:01, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58794/75212 [07:14<02:01, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58808/75212 [07:14<02:01, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58822/75212 [07:14<02:01, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58836/75212 [07:14<02:00, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58850/75212 [07:14<02:00, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58864/75212 [07:15<02:00, 135.36it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58878/75212 [07:15<02:00, 135.37it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58892/75212 [07:15<02:00, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58906/75212 [07:15<02:00, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58920/75212 [07:15<02:00, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58934/75212 [07:15<02:00, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58948/75212 [07:15<02:00, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58962/75212 [07:15<02:00, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58976/75212 [07:15<01:59, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 58990/75212 [07:15<01:59, 135.35it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59004/75212 [07:16<01:59, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59018/75212 [07:16<01:59, 135.34it/s][A[A

Selecting Coreset Indices.:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59032/75212 [07:16<01:59, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59046/75212 [07:16<01:59, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59060/75212 [07:16<01:59, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59074/75212 [07:16<01:59, 135.36it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59088/75212 [07:16<01:59, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59102/75212 [07:16<01:59, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59116/75212 [07:16<01:58, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59130/75212 [07:16<01:58, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59144/75212 [07:17<01:58, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59158/75212 [07:17<01:58, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59172/75212 [07:17<01:58, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59186/75212 [07:17<01:58, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59200/75212 [07:17<01:58, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59214/75212 [07:17<01:58, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59228/75212 [07:17<01:58, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59242/75212 [07:17<01:57, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59256/75212 [07:17<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59270/75212 [07:18<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59284/75212 [07:18<01:57, 135.36it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59298/75212 [07:18<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59312/75212 [07:18<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59326/75212 [07:18<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59340/75212 [07:18<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59354/75212 [07:18<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59368/75212 [07:18<01:57, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59382/75212 [07:18<01:56, 135.36it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59396/75212 [07:18<01:56, 135.36it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59410/75212 [07:19<01:56, 135.37it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59424/75212 [07:19<01:56, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59438/75212 [07:19<01:56, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59452/75212 [07:19<01:56, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59466/75212 [07:19<01:56, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59480/75212 [07:19<01:56, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59494/75212 [07:19<01:56, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59508/75212 [07:19<01:56, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59522/75212 [07:19<01:55, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59536/75212 [07:19<01:55, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59550/75212 [07:20<01:55, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59564/75212 [07:20<01:55, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59578/75212 [07:20<01:55, 135.36it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59592/75212 [07:20<01:55, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59606/75212 [07:20<01:55, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59620/75212 [07:20<01:55, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59634/75212 [07:20<01:55, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59648/75212 [07:20<01:54, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59662/75212 [07:20<01:54, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59676/75212 [07:21<01:54, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59690/75212 [07:21<01:54, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59704/75212 [07:21<01:54, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59718/75212 [07:21<01:54, 135.35it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59732/75212 [07:21<01:54, 135.36it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59746/75212 [07:21<01:54, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59760/75212 [07:21<01:54, 135.34it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59774/75212 [07:21<01:54, 135.36it/s][A[A

Selecting Coreset Indices.:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59788/75212 [07:21<01:53, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59802/75212 [07:21<01:53, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59816/75212 [07:22<01:53, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59830/75212 [07:22<01:53, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59844/75212 [07:22<01:53, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59858/75212 [07:22<01:53, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59872/75212 [07:22<01:53, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59886/75212 [07:22<01:53, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59900/75212 [07:22<01:53, 135.37it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59914/75212 [07:22<01:53, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59928/75212 [07:22<01:52, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59942/75212 [07:22<01:52, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59956/75212 [07:23<01:52, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59970/75212 [07:23<01:52, 135.37it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59984/75212 [07:23<01:52, 135.37it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 59998/75212 [07:23<01:52, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60012/75212 [07:23<01:52, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60026/75212 [07:23<01:52, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60040/75212 [07:23<01:52, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60054/75212 [07:23<01:51, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60068/75212 [07:23<01:51, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60082/75212 [07:24<01:51, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60096/75212 [07:24<01:51, 135.34it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60110/75212 [07:24<01:51, 135.34it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60124/75212 [07:24<01:51, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60138/75212 [07:24<01:51, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60152/75212 [07:24<01:51, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60166/75212 [07:24<01:51, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60180/75212 [07:24<01:51, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60194/75212 [07:24<01:50, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60208/75212 [07:24<01:50, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60222/75212 [07:25<01:50, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60236/75212 [07:25<01:50, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60250/75212 [07:25<01:50, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60264/75212 [07:25<01:50, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60278/75212 [07:25<01:50, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60292/75212 [07:25<01:50, 135.34it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60306/75212 [07:25<01:50, 135.34it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60320/75212 [07:25<01:50, 135.34it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60334/75212 [07:25<01:49, 135.34it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60348/75212 [07:25<01:49, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60362/75212 [07:26<01:49, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60376/75212 [07:26<01:49, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60390/75212 [07:26<01:49, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60404/75212 [07:26<01:49, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60418/75212 [07:26<01:49, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60432/75212 [07:26<01:49, 135.37it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60446/75212 [07:26<01:49, 135.37it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60460/75212 [07:26<01:48, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60474/75212 [07:26<01:48, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60488/75212 [07:27<01:48, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60502/75212 [07:27<01:48, 135.36it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60516/75212 [07:27<01:48, 135.35it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60530/75212 [07:27<01:48, 135.34it/s][A[A

Selecting Coreset Indices.:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60544/75212 [07:27<01:48, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60558/75212 [07:27<01:48, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60572/75212 [07:27<01:48, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60586/75212 [07:27<01:48, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60600/75212 [07:27<01:47, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60614/75212 [07:27<01:47, 135.33it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60628/75212 [07:28<01:47, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60642/75212 [07:28<01:47, 135.33it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60656/75212 [07:28<01:47, 135.33it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60670/75212 [07:28<01:47, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60684/75212 [07:28<01:47, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60698/75212 [07:28<01:47, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60712/75212 [07:28<01:47, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60726/75212 [07:28<01:47, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60740/75212 [07:28<01:46, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60754/75212 [07:28<01:46, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60768/75212 [07:29<01:46, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60782/75212 [07:29<01:46, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60796/75212 [07:29<01:46, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60810/75212 [07:29<01:46, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60824/75212 [07:29<01:46, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60838/75212 [07:29<01:46, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60852/75212 [07:29<01:46, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60866/75212 [07:29<01:45, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60880/75212 [07:29<01:45, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60894/75212 [07:30<01:45, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60908/75212 [07:30<01:45, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60922/75212 [07:30<01:45, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60936/75212 [07:30<01:45, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60950/75212 [07:30<01:45, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60964/75212 [07:30<01:45, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60978/75212 [07:30<01:45, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60992/75212 [07:30<01:45, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61006/75212 [07:30<01:44, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61020/75212 [07:30<01:44, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61034/75212 [07:31<01:44, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61048/75212 [07:31<01:44, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61062/75212 [07:31<01:44, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61076/75212 [07:31<01:44, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61090/75212 [07:31<01:44, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61104/75212 [07:31<01:44, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61118/75212 [07:31<01:44, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61132/75212 [07:31<01:44, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61146/75212 [07:31<01:43, 135.36it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61160/75212 [07:31<01:43, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61174/75212 [07:32<01:43, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61188/75212 [07:32<01:43, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61202/75212 [07:32<01:43, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61216/75212 [07:32<01:43, 135.35it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61230/75212 [07:32<01:43, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61244/75212 [07:32<01:43, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61258/75212 [07:32<01:43, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61272/75212 [07:32<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61286/75212 [07:32<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61300/75212 [07:32<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61314/75212 [07:33<01:42, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61328/75212 [07:33<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61342/75212 [07:33<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61356/75212 [07:33<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61370/75212 [07:33<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61384/75212 [07:33<01:42, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61398/75212 [07:33<01:42, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61412/75212 [07:33<01:41, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61426/75212 [07:33<01:41, 135.33it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61440/75212 [07:34<01:41, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61454/75212 [07:34<01:41, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61468/75212 [07:34<01:41, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61482/75212 [07:34<01:41, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61496/75212 [07:34<01:41, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61510/75212 [07:34<01:41, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61524/75212 [07:34<01:41, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61538/75212 [07:34<01:41, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61552/75212 [07:34<01:40, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61566/75212 [07:34<01:40, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61580/75212 [07:35<01:40, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61594/75212 [07:35<01:40, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61608/75212 [07:35<01:40, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61622/75212 [07:35<01:40, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61636/75212 [07:35<01:40, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61650/75212 [07:35<01:40, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61664/75212 [07:35<01:40, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61678/75212 [07:35<01:40, 135.33it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61692/75212 [07:35<01:39, 135.33it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61706/75212 [07:35<01:39, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61720/75212 [07:36<01:39, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61734/75212 [07:36<01:39, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61748/75212 [07:36<01:39, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61762/75212 [07:36<01:39, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61776/75212 [07:36<01:39, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61790/75212 [07:36<01:39, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61804/75212 [07:36<01:39, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61818/75212 [07:36<01:38, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61832/75212 [07:36<01:38, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61846/75212 [07:37<01:38, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61860/75212 [07:37<01:38, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61874/75212 [07:37<01:38, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61888/75212 [07:37<01:38, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61902/75212 [07:37<01:38, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61916/75212 [07:37<01:38, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61930/75212 [07:37<01:38, 135.34it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61944/75212 [07:37<01:38, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61958/75212 [07:37<01:37, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61972/75212 [07:37<01:37, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61986/75212 [07:38<01:37, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62000/75212 [07:38<01:37, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62014/75212 [07:38<01:37, 135.35it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62028/75212 [07:38<01:37, 135.36it/s][A[A

Selecting Coreset Indices.:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62042/75212 [07:38<01:37, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62056/75212 [07:38<01:37, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62070/75212 [07:38<01:37, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62084/75212 [07:38<01:36, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62098/75212 [07:38<01:36, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62112/75212 [07:38<01:36, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62126/75212 [07:39<01:36, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62140/75212 [07:39<01:36, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62154/75212 [07:39<01:36, 135.37it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62168/75212 [07:39<01:36, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62182/75212 [07:39<01:36, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62196/75212 [07:39<01:36, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62210/75212 [07:39<01:36, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62224/75212 [07:39<01:35, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62238/75212 [07:39<01:35, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62252/75212 [07:40<01:35, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62266/75212 [07:40<01:35, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62280/75212 [07:40<01:35, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62294/75212 [07:40<01:35, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62308/75212 [07:40<01:35, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62322/75212 [07:40<01:35, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62336/75212 [07:40<01:35, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62350/75212 [07:40<01:35, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62364/75212 [07:40<01:34, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62378/75212 [07:40<01:34, 135.37it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62392/75212 [07:41<01:34, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62406/75212 [07:41<01:34, 135.37it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62420/75212 [07:41<01:34, 135.37it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62434/75212 [07:41<01:34, 135.36it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62448/75212 [07:41<01:34, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62462/75212 [07:41<01:34, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62476/75212 [07:41<01:34, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62490/75212 [07:41<01:34, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62504/75212 [07:41<01:33, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62518/75212 [07:41<01:33, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62532/75212 [07:42<01:33, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62546/75212 [07:42<01:33, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62560/75212 [07:42<01:33, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62574/75212 [07:42<01:33, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62588/75212 [07:42<01:33, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62602/75212 [07:42<01:33, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62616/75212 [07:42<01:33, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62630/75212 [07:42<01:32, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62644/75212 [07:42<01:32, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62658/75212 [07:43<01:32, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62672/75212 [07:43<01:32, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62686/75212 [07:43<01:32, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62700/75212 [07:43<01:32, 135.33it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62714/75212 [07:43<01:32, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62728/75212 [07:43<01:32, 135.34it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62742/75212 [07:43<01:32, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62756/75212 [07:43<01:32, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62770/75212 [07:43<01:31, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62784/75212 [07:43<01:31, 135.35it/s][A[A

Selecting Coreset Indices.:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62798/75212 [07:44<01:31, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62812/75212 [07:44<01:31, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62826/75212 [07:44<01:31, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62840/75212 [07:44<01:31, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62854/75212 [07:44<01:31, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62868/75212 [07:44<01:31, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62882/75212 [07:44<01:31, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62896/75212 [07:44<01:30, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62910/75212 [07:44<01:30, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62924/75212 [07:44<01:30, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62938/75212 [07:45<01:30, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62952/75212 [07:45<01:30, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62966/75212 [07:45<01:30, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62980/75212 [07:45<01:30, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62994/75212 [07:45<01:30, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63008/75212 [07:45<01:30, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63022/75212 [07:45<01:30, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63036/75212 [07:45<01:29, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63050/75212 [07:45<01:29, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63064/75212 [07:46<01:29, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63078/75212 [07:46<01:29, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63092/75212 [07:46<01:29, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63106/75212 [07:46<01:29, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63120/75212 [07:46<01:29, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63134/75212 [07:46<01:29, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63148/75212 [07:46<01:29, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63162/75212 [07:46<01:29, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63176/75212 [07:46<01:28, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63190/75212 [07:46<01:28, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63204/75212 [07:47<01:28, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63218/75212 [07:47<01:28, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63232/75212 [07:47<01:28, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63246/75212 [07:47<01:28, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63260/75212 [07:47<01:28, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63274/75212 [07:47<01:28, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63288/75212 [07:47<01:28, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63302/75212 [07:47<01:27, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63316/75212 [07:47<01:27, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63330/75212 [07:47<01:27, 135.36it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63344/75212 [07:48<01:27, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63358/75212 [07:48<01:27, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63372/75212 [07:48<01:27, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63386/75212 [07:48<01:27, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63400/75212 [07:48<01:27, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63414/75212 [07:48<01:27, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63428/75212 [07:48<01:27, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63442/75212 [07:48<01:26, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63456/75212 [07:48<01:26, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63470/75212 [07:49<01:26, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63484/75212 [07:49<01:26, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63498/75212 [07:49<01:26, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63512/75212 [07:49<01:26, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63526/75212 [07:49<01:26, 135.34it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63540/75212 [07:49<01:26, 135.35it/s][A[A

Selecting Coreset Indices.:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63554/75212 [07:49<01:26, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63568/75212 [07:49<01:26, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63582/75212 [07:49<01:25, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63596/75212 [07:49<01:25, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63610/75212 [07:50<01:25, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63624/75212 [07:50<01:25, 135.37it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63638/75212 [07:50<01:25, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63652/75212 [07:50<01:25, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63666/75212 [07:50<01:25, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63680/75212 [07:50<01:25, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63694/75212 [07:50<01:25, 135.37it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63708/75212 [07:50<01:24, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63722/75212 [07:50<01:24, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63736/75212 [07:50<01:24, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63750/75212 [07:51<01:24, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63764/75212 [07:51<01:24, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63778/75212 [07:51<01:24, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63792/75212 [07:51<01:24, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63806/75212 [07:51<01:24, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63820/75212 [07:51<01:24, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63834/75212 [07:51<01:24, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63848/75212 [07:51<01:23, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63862/75212 [07:51<01:23, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63876/75212 [07:52<01:23, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63890/75212 [07:52<01:23, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63904/75212 [07:52<01:23, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63918/75212 [07:52<01:23, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 63932/75212 [07:52<01:23, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 63946/75212 [07:52<01:23, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 63960/75212 [07:52<01:23, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 63974/75212 [07:52<01:23, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 63988/75212 [07:52<01:22, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64002/75212 [07:52<01:22, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64016/75212 [07:53<01:22, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64030/75212 [07:53<01:22, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64044/75212 [07:53<01:22, 135.33it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64058/75212 [07:53<01:22, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64072/75212 [07:53<01:22, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64086/75212 [07:53<01:22, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64100/75212 [07:53<01:22, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64114/75212 [07:53<01:21, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64128/75212 [07:53<01:21, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64142/75212 [07:53<01:21, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64156/75212 [07:54<01:21, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64170/75212 [07:54<01:21, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64184/75212 [07:54<01:21, 135.35it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64198/75212 [07:54<01:21, 135.36it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64212/75212 [07:54<01:21, 135.34it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64226/75212 [07:54<01:21, 135.27it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64240/75212 [07:54<01:21, 135.30it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64254/75212 [07:54<01:20, 135.29it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64268/75212 [07:54<01:20, 135.32it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64282/75212 [07:55<01:20, 135.33it/s][A[A

Selecting Coreset Indices.:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64296/75212 [07:55<01:20, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64310/75212 [07:55<01:20, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64324/75212 [07:55<01:20, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64338/75212 [07:55<01:20, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64352/75212 [07:55<01:20, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64366/75212 [07:55<01:20, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64380/75212 [07:55<01:20, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64394/75212 [07:55<01:19, 135.37it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64408/75212 [07:55<01:19, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64422/75212 [07:56<01:19, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64436/75212 [07:56<01:19, 135.37it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64450/75212 [07:56<01:19, 135.37it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64464/75212 [07:56<01:19, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64478/75212 [07:56<01:19, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64492/75212 [07:56<01:19, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64506/75212 [07:56<01:19, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64520/75212 [07:56<01:18, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64534/75212 [07:56<01:18, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64548/75212 [07:56<01:18, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64562/75212 [07:57<01:18, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64576/75212 [07:57<01:18, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64590/75212 [07:57<01:18, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64604/75212 [07:57<01:18, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64618/75212 [07:57<01:18, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64632/75212 [07:57<01:18, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64646/75212 [07:57<01:18, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64660/75212 [07:57<01:17, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64674/75212 [07:57<01:17, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64688/75212 [07:58<01:17, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64702/75212 [07:58<01:17, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64716/75212 [07:58<01:17, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64730/75212 [07:58<01:17, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64744/75212 [07:58<01:17, 135.36it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64758/75212 [07:58<01:17, 135.37it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64772/75212 [07:58<01:17, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64786/75212 [07:58<01:17, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64800/75212 [07:58<01:16, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64814/75212 [07:58<01:16, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64828/75212 [07:59<01:16, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64842/75212 [07:59<01:16, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64856/75212 [07:59<01:16, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64870/75212 [07:59<01:16, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64884/75212 [07:59<01:16, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64898/75212 [07:59<01:16, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64912/75212 [07:59<01:16, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64926/75212 [07:59<01:15, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64940/75212 [07:59<01:15, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64954/75212 [07:59<01:15, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64968/75212 [08:00<01:15, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64982/75212 [08:00<01:15, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 64996/75212 [08:00<01:15, 135.34it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65010/75212 [08:00<01:15, 135.35it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65024/75212 [08:00<01:15, 135.31it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65038/75212 [08:00<01:15, 135.23it/s][A[A

Selecting Coreset Indices.:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65052/75212 [08:00<01:15, 135.25it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65066/75212 [08:00<01:14, 135.28it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65080/75212 [08:00<01:14, 135.30it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65094/75212 [08:01<01:14, 135.31it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65108/75212 [08:01<01:14, 135.32it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65122/75212 [08:01<01:14, 135.33it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65136/75212 [08:01<01:14, 135.33it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65150/75212 [08:01<01:14, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65164/75212 [08:01<01:14, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65178/75212 [08:01<01:14, 135.33it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65192/75212 [08:01<01:14, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65206/75212 [08:01<01:13, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65220/75212 [08:01<01:13, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65234/75212 [08:02<01:13, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65248/75212 [08:02<01:13, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65262/75212 [08:02<01:13, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65276/75212 [08:02<01:13, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65290/75212 [08:02<01:13, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65304/75212 [08:02<01:13, 135.37it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65318/75212 [08:02<01:13, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65332/75212 [08:02<01:12, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65346/75212 [08:02<01:12, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65360/75212 [08:02<01:12, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65374/75212 [08:03<01:12, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65388/75212 [08:03<01:12, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65402/75212 [08:03<01:12, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65416/75212 [08:03<01:12, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65430/75212 [08:03<01:12, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65444/75212 [08:03<01:12, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65458/75212 [08:03<01:12, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65472/75212 [08:03<01:11, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65486/75212 [08:03<01:11, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65500/75212 [08:04<01:11, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65514/75212 [08:04<01:11, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65528/75212 [08:04<01:11, 135.37it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65542/75212 [08:04<01:11, 135.37it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65556/75212 [08:04<01:11, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65570/75212 [08:04<01:11, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65584/75212 [08:04<01:11, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65598/75212 [08:04<01:11, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65612/75212 [08:04<01:10, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65626/75212 [08:04<01:10, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65640/75212 [08:05<01:10, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65654/75212 [08:05<01:10, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65668/75212 [08:05<01:10, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65682/75212 [08:05<01:10, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65696/75212 [08:05<01:10, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65710/75212 [08:05<01:10, 135.36it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65724/75212 [08:05<01:10, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65738/75212 [08:05<01:09, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65752/75212 [08:05<01:09, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65766/75212 [08:05<01:09, 135.35it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65780/75212 [08:06<01:09, 135.34it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65794/75212 [08:06<01:09, 135.33it/s][A[A

Selecting Coreset Indices.:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65808/75212 [08:06<01:09, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65822/75212 [08:06<01:09, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65836/75212 [08:06<01:09, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65850/75212 [08:06<01:09, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65864/75212 [08:06<01:09, 135.33it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65878/75212 [08:06<01:08, 135.33it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65892/75212 [08:06<01:08, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65906/75212 [08:07<01:08, 135.32it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65920/75212 [08:07<01:08, 135.33it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65934/75212 [08:07<01:08, 135.33it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65948/75212 [08:07<01:08, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65962/75212 [08:07<01:08, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65976/75212 [08:07<01:08, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 65990/75212 [08:07<01:08, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66004/75212 [08:07<01:08, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66018/75212 [08:07<01:07, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66032/75212 [08:07<01:07, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66046/75212 [08:08<01:07, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66060/75212 [08:08<01:07, 135.33it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66074/75212 [08:08<01:07, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66088/75212 [08:08<01:07, 135.33it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66102/75212 [08:08<01:07, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66116/75212 [08:08<01:07, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66130/75212 [08:08<01:07, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66144/75212 [08:08<01:07, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66158/75212 [08:08<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66172/75212 [08:08<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66186/75212 [08:09<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66200/75212 [08:09<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66214/75212 [08:09<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66228/75212 [08:09<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66242/75212 [08:09<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66256/75212 [08:09<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66270/75212 [08:09<01:06, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66284/75212 [08:09<01:05, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66298/75212 [08:09<01:05, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66312/75212 [08:10<01:05, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66326/75212 [08:10<01:05, 135.33it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66340/75212 [08:10<01:05, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66354/75212 [08:10<01:05, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66368/75212 [08:10<01:05, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66382/75212 [08:10<01:05, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66396/75212 [08:10<01:05, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66410/75212 [08:10<01:05, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66424/75212 [08:10<01:04, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66438/75212 [08:10<01:04, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66452/75212 [08:11<01:04, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66466/75212 [08:11<01:04, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66480/75212 [08:11<01:04, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66494/75212 [08:11<01:04, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66508/75212 [08:11<01:04, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66522/75212 [08:11<01:04, 135.34it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66536/75212 [08:11<01:04, 135.35it/s][A[A

Selecting Coreset Indices.:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66550/75212 [08:11<01:03, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66564/75212 [08:11<01:03, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66578/75212 [08:11<01:03, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66592/75212 [08:12<01:03, 135.37it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66606/75212 [08:12<01:03, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66620/75212 [08:12<01:03, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66634/75212 [08:12<01:03, 135.34it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66648/75212 [08:12<01:03, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66662/75212 [08:12<01:03, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66676/75212 [08:12<01:03, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66690/75212 [08:12<01:02, 135.34it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66704/75212 [08:12<01:02, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66718/75212 [08:13<01:02, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66732/75212 [08:13<01:02, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66746/75212 [08:13<01:02, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66760/75212 [08:13<01:02, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66774/75212 [08:13<01:02, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66788/75212 [08:13<01:02, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66802/75212 [08:13<01:02, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66816/75212 [08:13<01:02, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66830/75212 [08:13<01:01, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66844/75212 [08:13<01:01, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66858/75212 [08:14<01:01, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66872/75212 [08:14<01:01, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66886/75212 [08:14<01:01, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66900/75212 [08:14<01:01, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66914/75212 [08:14<01:01, 135.34it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66928/75212 [08:14<01:01, 135.34it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66942/75212 [08:14<01:01, 135.34it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66956/75212 [08:14<01:00, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66970/75212 [08:14<01:00, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66984/75212 [08:14<01:00, 135.34it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 66998/75212 [08:15<01:00, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67012/75212 [08:15<01:00, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67026/75212 [08:15<01:00, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67040/75212 [08:15<01:00, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67054/75212 [08:15<01:00, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67068/75212 [08:15<01:00, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67082/75212 [08:15<01:00, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67096/75212 [08:15<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67110/75212 [08:15<00:59, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67124/75212 [08:16<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67138/75212 [08:16<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67152/75212 [08:16<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67166/75212 [08:16<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67180/75212 [08:16<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67194/75212 [08:16<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67208/75212 [08:16<00:59, 135.34it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67222/75212 [08:16<00:59, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67236/75212 [08:16<00:58, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67250/75212 [08:16<00:58, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67264/75212 [08:17<00:58, 135.36it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67278/75212 [08:17<00:58, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67292/75212 [08:17<00:58, 135.35it/s][A[A

Selecting Coreset Indices.:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67306/75212 [08:17<00:58, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67320/75212 [08:17<00:58, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67334/75212 [08:17<00:58, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67348/75212 [08:17<00:58, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67362/75212 [08:17<00:57, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67376/75212 [08:17<00:57, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67390/75212 [08:17<00:57, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67404/75212 [08:18<00:57, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67418/75212 [08:18<00:57, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67432/75212 [08:18<00:57, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67446/75212 [08:18<00:57, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67460/75212 [08:18<00:57, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67474/75212 [08:18<00:57, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67488/75212 [08:18<00:57, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67502/75212 [08:18<00:56, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67516/75212 [08:18<00:56, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67530/75212 [08:19<00:56, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67544/75212 [08:19<00:56, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67558/75212 [08:19<00:56, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67572/75212 [08:19<00:56, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67586/75212 [08:19<00:56, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67600/75212 [08:19<00:56, 135.33it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67614/75212 [08:19<00:56, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67628/75212 [08:19<00:56, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67642/75212 [08:19<00:55, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67656/75212 [08:19<00:55, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67670/75212 [08:20<00:55, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67684/75212 [08:20<00:55, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67698/75212 [08:20<00:55, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67712/75212 [08:20<00:55, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67726/75212 [08:20<00:55, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67740/75212 [08:20<00:55, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67754/75212 [08:20<00:55, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67768/75212 [08:20<00:54, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67782/75212 [08:20<00:54, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67796/75212 [08:20<00:54, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67810/75212 [08:21<00:54, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67824/75212 [08:21<00:54, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67838/75212 [08:21<00:54, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67852/75212 [08:21<00:54, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67866/75212 [08:21<00:54, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67880/75212 [08:21<00:54, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67894/75212 [08:21<00:54, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67908/75212 [08:21<00:53, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67922/75212 [08:21<00:53, 135.36it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67936/75212 [08:22<00:53, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67950/75212 [08:22<00:53, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67964/75212 [08:22<00:53, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67978/75212 [08:22<00:53, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 67992/75212 [08:22<00:53, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68006/75212 [08:22<00:53, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68020/75212 [08:22<00:53, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68034/75212 [08:22<00:53, 135.34it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68048/75212 [08:22<00:52, 135.35it/s][A[A

Selecting Coreset Indices.:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68062/75212 [08:22<00:52, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68076/75212 [08:23<00:52, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68090/75212 [08:23<00:52, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68104/75212 [08:23<00:52, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68118/75212 [08:23<00:52, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68132/75212 [08:23<00:52, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68146/75212 [08:23<00:52, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68160/75212 [08:23<00:52, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68174/75212 [08:23<00:51, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68188/75212 [08:23<00:51, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68202/75212 [08:23<00:51, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68216/75212 [08:24<00:51, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68230/75212 [08:24<00:51, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68244/75212 [08:24<00:51, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68258/75212 [08:24<00:51, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68272/75212 [08:24<00:51, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68286/75212 [08:24<00:51, 134.53it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68300/75212 [08:24<00:51, 134.76it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68314/75212 [08:24<00:51, 134.93it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68328/75212 [08:24<00:50, 135.07it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68342/75212 [08:25<00:50, 135.16it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68356/75212 [08:25<00:50, 135.20it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68370/75212 [08:25<00:50, 135.24it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68384/75212 [08:25<00:50, 135.28it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68398/75212 [08:25<00:50, 135.31it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68412/75212 [08:25<00:50, 135.31it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68426/75212 [08:25<00:50, 135.33it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68440/75212 [08:25<00:50, 135.33it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68454/75212 [08:25<00:49, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68468/75212 [08:25<00:49, 135.33it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68482/75212 [08:26<00:49, 135.34it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68496/75212 [08:26<00:49, 135.34it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68510/75212 [08:26<00:49, 135.34it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68524/75212 [08:26<00:49, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68538/75212 [08:26<00:49, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68552/75212 [08:26<00:49, 135.34it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68566/75212 [08:26<00:49, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68580/75212 [08:26<00:48, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68594/75212 [08:26<00:48, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68608/75212 [08:26<00:48, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68622/75212 [08:27<00:48, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68636/75212 [08:27<00:48, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68650/75212 [08:27<00:48, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68664/75212 [08:27<00:48, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68678/75212 [08:27<00:48, 135.34it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68692/75212 [08:27<00:48, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68706/75212 [08:27<00:48, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68720/75212 [08:27<00:47, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68734/75212 [08:27<00:47, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68748/75212 [08:28<00:47, 135.36it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68762/75212 [08:28<00:47, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68776/75212 [08:28<00:47, 135.35it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68790/75212 [08:28<00:47, 135.34it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68804/75212 [08:28<00:47, 135.34it/s][A[A

Selecting Coreset Indices.:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68818/75212 [08:28<00:47, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68832/75212 [08:28<00:47, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68846/75212 [08:28<00:47, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68860/75212 [08:28<00:46, 135.36it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68874/75212 [08:28<00:46, 135.37it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68888/75212 [08:29<00:46, 135.37it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68902/75212 [08:29<00:46, 135.37it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68916/75212 [08:29<00:46, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68930/75212 [08:29<00:46, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68944/75212 [08:29<00:46, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68958/75212 [08:29<00:46, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68972/75212 [08:29<00:46, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68986/75212 [08:29<00:45, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69000/75212 [08:29<00:45, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69014/75212 [08:29<00:45, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69028/75212 [08:30<00:45, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69042/75212 [08:30<00:45, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69056/75212 [08:30<00:45, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69070/75212 [08:30<00:45, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69084/75212 [08:30<00:45, 135.36it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69098/75212 [08:30<00:45, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69112/75212 [08:30<00:45, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69126/75212 [08:30<00:44, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69140/75212 [08:30<00:44, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69154/75212 [08:31<00:44, 135.36it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69168/75212 [08:31<00:44, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69182/75212 [08:31<00:44, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69196/75212 [08:31<00:44, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69210/75212 [08:31<00:44, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69224/75212 [08:31<00:44, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69238/75212 [08:31<00:44, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69252/75212 [08:31<00:44, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69266/75212 [08:31<00:43, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69280/75212 [08:31<00:43, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69294/75212 [08:32<00:43, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69308/75212 [08:32<00:43, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69322/75212 [08:32<00:43, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69336/75212 [08:32<00:43, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69350/75212 [08:32<00:43, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69364/75212 [08:32<00:43, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69378/75212 [08:32<00:43, 135.37it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69392/75212 [08:32<00:42, 135.36it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69406/75212 [08:32<00:42, 135.36it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69420/75212 [08:32<00:42, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69434/75212 [08:33<00:42, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69448/75212 [08:33<00:42, 135.34it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69462/75212 [08:33<00:42, 135.33it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69476/75212 [08:33<00:42, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69490/75212 [08:33<00:42, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69504/75212 [08:33<00:42, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69518/75212 [08:33<00:42, 135.35it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69532/75212 [08:33<00:41, 135.36it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69546/75212 [08:33<00:41, 135.36it/s][A[A

Selecting Coreset Indices.:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69560/75212 [08:34<00:41, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69574/75212 [08:34<00:41, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69588/75212 [08:34<00:41, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69602/75212 [08:34<00:41, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69616/75212 [08:34<00:41, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69630/75212 [08:34<00:41, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69644/75212 [08:34<00:41, 135.37it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69658/75212 [08:34<00:41, 135.37it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69672/75212 [08:34<00:40, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69686/75212 [08:34<00:40, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69700/75212 [08:35<00:40, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69714/75212 [08:35<00:40, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69728/75212 [08:35<00:40, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69742/75212 [08:35<00:40, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69756/75212 [08:35<00:40, 135.33it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69770/75212 [08:35<00:40, 135.33it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69784/75212 [08:35<00:40, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69798/75212 [08:35<00:40, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69812/75212 [08:35<00:39, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69826/75212 [08:35<00:39, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69840/75212 [08:36<00:39, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69854/75212 [08:36<00:39, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69868/75212 [08:36<00:39, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69882/75212 [08:36<00:39, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69896/75212 [08:36<00:39, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69910/75212 [08:36<00:39, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69924/75212 [08:36<00:39, 135.33it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69938/75212 [08:36<00:38, 135.32it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69952/75212 [08:36<00:38, 135.33it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69966/75212 [08:37<00:38, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69980/75212 [08:37<00:38, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 69994/75212 [08:37<00:38, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70008/75212 [08:37<00:38, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70022/75212 [08:37<00:38, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70036/75212 [08:37<00:38, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70050/75212 [08:37<00:38, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70064/75212 [08:37<00:38, 135.33it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70078/75212 [08:37<00:37, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70092/75212 [08:37<00:37, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70106/75212 [08:38<00:37, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70120/75212 [08:38<00:37, 135.36it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70134/75212 [08:38<00:37, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70148/75212 [08:38<00:37, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70162/75212 [08:38<00:37, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70176/75212 [08:38<00:37, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70190/75212 [08:38<00:37, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70204/75212 [08:38<00:37, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70218/75212 [08:38<00:36, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70232/75212 [08:38<00:36, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70246/75212 [08:39<00:36, 135.34it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70260/75212 [08:39<00:36, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70274/75212 [08:39<00:36, 135.35it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70288/75212 [08:39<00:36, 135.33it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70302/75212 [08:39<00:36, 135.33it/s][A[A

Selecting Coreset Indices.:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70316/75212 [08:39<00:36, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70330/75212 [08:39<00:36, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70344/75212 [08:39<00:35, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70358/75212 [08:39<00:35, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70372/75212 [08:40<00:35, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70386/75212 [08:40<00:35, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70400/75212 [08:40<00:35, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70414/75212 [08:40<00:35, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70428/75212 [08:40<00:35, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70442/75212 [08:40<00:35, 135.37it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70456/75212 [08:40<00:35, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70470/75212 [08:40<00:35, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70484/75212 [08:40<00:34, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70498/75212 [08:40<00:34, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70512/75212 [08:41<00:34, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70526/75212 [08:41<00:34, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70540/75212 [08:41<00:34, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70554/75212 [08:41<00:34, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70568/75212 [08:41<00:34, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70582/75212 [08:41<00:34, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70596/75212 [08:41<00:34, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70610/75212 [08:41<00:34, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70624/75212 [08:41<00:33, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70638/75212 [08:41<00:33, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70652/75212 [08:42<00:33, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70666/75212 [08:42<00:33, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70680/75212 [08:42<00:33, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70694/75212 [08:42<00:33, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70708/75212 [08:42<00:33, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70722/75212 [08:42<00:33, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70736/75212 [08:42<00:33, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70750/75212 [08:42<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70764/75212 [08:42<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70778/75212 [08:43<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70792/75212 [08:43<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70806/75212 [08:43<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70820/75212 [08:43<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70834/75212 [08:43<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70848/75212 [08:43<00:32, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70862/75212 [08:43<00:32, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70876/75212 [08:43<00:32, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70890/75212 [08:43<00:31, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70904/75212 [08:43<00:31, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70918/75212 [08:44<00:31, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70932/75212 [08:44<00:31, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70946/75212 [08:44<00:31, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70960/75212 [08:44<00:31, 135.36it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70974/75212 [08:44<00:31, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70988/75212 [08:44<00:31, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71002/75212 [08:44<00:31, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71016/75212 [08:44<00:31, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71030/75212 [08:44<00:30, 135.33it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71044/75212 [08:44<00:30, 135.34it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71058/75212 [08:45<00:30, 135.35it/s][A[A

Selecting Coreset Indices.:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71072/75212 [08:45<00:30, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71086/75212 [08:45<00:30, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71100/75212 [08:45<00:30, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71114/75212 [08:45<00:30, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71128/75212 [08:45<00:30, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71142/75212 [08:45<00:30, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71156/75212 [08:45<00:29, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71170/75212 [08:45<00:29, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71184/75212 [08:46<00:29, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71198/75212 [08:46<00:29, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71212/75212 [08:46<00:29, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71226/75212 [08:46<00:29, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71240/75212 [08:46<00:29, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71254/75212 [08:46<00:29, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71268/75212 [08:46<00:29, 135.37it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71282/75212 [08:46<00:29, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71296/75212 [08:46<00:28, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71310/75212 [08:46<00:28, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71324/75212 [08:47<00:28, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71338/75212 [08:47<00:28, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71352/75212 [08:47<00:28, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71366/75212 [08:47<00:28, 135.37it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71380/75212 [08:47<00:28, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71394/75212 [08:47<00:28, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71408/75212 [08:47<00:28, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71422/75212 [08:47<00:27, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71436/75212 [08:47<00:27, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71450/75212 [08:47<00:27, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71464/75212 [08:48<00:27, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71478/75212 [08:48<00:27, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71492/75212 [08:48<00:27, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71506/75212 [08:48<00:27, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71520/75212 [08:48<00:27, 135.36it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71534/75212 [08:48<00:27, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71548/75212 [08:48<00:27, 135.32it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71562/75212 [08:48<00:26, 135.32it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71576/75212 [08:48<00:26, 135.32it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71590/75212 [08:49<00:26, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71604/75212 [08:49<00:26, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71618/75212 [08:49<00:26, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71632/75212 [08:49<00:26, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71646/75212 [08:49<00:26, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71660/75212 [08:49<00:26, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71674/75212 [08:49<00:26, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71688/75212 [08:49<00:26, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71702/75212 [08:49<00:25, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71716/75212 [08:49<00:25, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71730/75212 [08:50<00:25, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71744/75212 [08:50<00:25, 135.33it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71758/75212 [08:50<00:25, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71772/75212 [08:50<00:25, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71786/75212 [08:50<00:25, 135.34it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71800/75212 [08:50<00:25, 135.35it/s][A[A

Selecting Coreset Indices.:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71814/75212 [08:50<00:25, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71828/75212 [08:50<00:25, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71842/75212 [08:50<00:24, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71856/75212 [08:50<00:24, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71870/75212 [08:51<00:24, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71884/75212 [08:51<00:24, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71898/75212 [08:51<00:24, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71912/75212 [08:51<00:24, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71926/75212 [08:51<00:24, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71940/75212 [08:51<00:24, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71954/75212 [08:51<00:24, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71968/75212 [08:51<00:23, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71982/75212 [08:51<00:23, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 71996/75212 [08:52<00:23, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72010/75212 [08:52<00:23, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72024/75212 [08:52<00:23, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72038/75212 [08:52<00:23, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72052/75212 [08:52<00:23, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72066/75212 [08:52<00:23, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72080/75212 [08:52<00:23, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72094/75212 [08:52<00:23, 135.37it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72108/75212 [08:52<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72122/75212 [08:52<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72136/75212 [08:53<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72150/75212 [08:53<00:22, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72164/75212 [08:53<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72178/75212 [08:53<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72192/75212 [08:53<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72206/75212 [08:53<00:22, 135.37it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72220/75212 [08:53<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72234/75212 [08:53<00:22, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72248/75212 [08:53<00:21, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72262/75212 [08:53<00:21, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72276/75212 [08:54<00:21, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72290/75212 [08:54<00:21, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72304/75212 [08:54<00:21, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72318/75212 [08:54<00:21, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72332/75212 [08:54<00:21, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72346/75212 [08:54<00:21, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72360/75212 [08:54<00:21, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72374/75212 [08:54<00:20, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72388/75212 [08:54<00:20, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72402/75212 [08:55<00:20, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72416/75212 [08:55<00:20, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72430/75212 [08:55<00:20, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72444/75212 [08:55<00:20, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72458/75212 [08:55<00:20, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72472/75212 [08:55<00:20, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72486/75212 [08:55<00:20, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72500/75212 [08:55<00:20, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72514/75212 [08:55<00:19, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72528/75212 [08:55<00:19, 135.36it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72542/75212 [08:56<00:19, 135.34it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72556/75212 [08:56<00:19, 135.35it/s][A[A

Selecting Coreset Indices.:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72570/75212 [08:56<00:19, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72584/75212 [08:56<00:19, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72598/75212 [08:56<00:19, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72612/75212 [08:56<00:19, 135.37it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72626/75212 [08:56<00:19, 135.37it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72640/75212 [08:56<00:19, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72654/75212 [08:56<00:18, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72668/75212 [08:56<00:18, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72682/75212 [08:57<00:18, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72696/75212 [08:57<00:18, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72710/75212 [08:57<00:18, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72724/75212 [08:57<00:18, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72738/75212 [08:57<00:18, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72752/75212 [08:57<00:18, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72766/75212 [08:57<00:18, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72780/75212 [08:57<00:17, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72794/75212 [08:57<00:17, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72808/75212 [08:58<00:17, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72822/75212 [08:58<00:17, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72836/75212 [08:58<00:17, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72850/75212 [08:58<00:17, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72864/75212 [08:58<00:17, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72878/75212 [08:58<00:17, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72892/75212 [08:58<00:17, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72906/75212 [08:58<00:17, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72920/75212 [08:58<00:16, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72934/75212 [08:58<00:16, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72948/75212 [08:59<00:16, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72962/75212 [08:59<00:16, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72976/75212 [08:59<00:16, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 72990/75212 [08:59<00:16, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73004/75212 [08:59<00:16, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73018/75212 [08:59<00:16, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73032/75212 [08:59<00:16, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73046/75212 [08:59<00:16, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73060/75212 [08:59<00:15, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73074/75212 [08:59<00:15, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73088/75212 [09:00<00:15, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73102/75212 [09:00<00:15, 135.33it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73116/75212 [09:00<00:15, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73130/75212 [09:00<00:15, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73144/75212 [09:00<00:15, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73158/75212 [09:00<00:15, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73172/75212 [09:00<00:15, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73186/75212 [09:00<00:14, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73200/75212 [09:00<00:14, 135.34it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73214/75212 [09:01<00:14, 135.33it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73228/75212 [09:01<00:14, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73242/75212 [09:01<00:14, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73256/75212 [09:01<00:14, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73270/75212 [09:01<00:14, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73284/75212 [09:01<00:14, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73298/75212 [09:01<00:14, 135.36it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73312/75212 [09:01<00:14, 135.35it/s][A[A

Selecting Coreset Indices.:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73326/75212 [09:01<00:13, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73340/75212 [09:01<00:13, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73354/75212 [09:02<00:13, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73368/75212 [09:02<00:13, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73382/75212 [09:02<00:13, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73396/75212 [09:02<00:13, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73410/75212 [09:02<00:13, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73424/75212 [09:02<00:13, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73438/75212 [09:02<00:13, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73452/75212 [09:02<00:13, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73466/75212 [09:02<00:12, 135.33it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73480/75212 [09:02<00:12, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73494/75212 [09:03<00:12, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73508/75212 [09:03<00:12, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73522/75212 [09:03<00:12, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73536/75212 [09:03<00:12, 135.33it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73550/75212 [09:03<00:12, 135.33it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73564/75212 [09:03<00:12, 135.33it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73578/75212 [09:03<00:12, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73592/75212 [09:03<00:11, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73606/75212 [09:03<00:11, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73620/75212 [09:04<00:11, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73634/75212 [09:04<00:11, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73648/75212 [09:04<00:11, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73662/75212 [09:04<00:11, 135.36it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73676/75212 [09:04<00:11, 135.36it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73690/75212 [09:04<00:11, 135.36it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73704/75212 [09:04<00:11, 135.37it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73718/75212 [09:04<00:11, 135.36it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73732/75212 [09:04<00:10, 135.36it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73746/75212 [09:04<00:10, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73760/75212 [09:05<00:10, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73774/75212 [09:05<00:10, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73788/75212 [09:05<00:10, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73802/75212 [09:05<00:10, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73816/75212 [09:05<00:10, 135.36it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73830/75212 [09:05<00:10, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73844/75212 [09:05<00:10, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73858/75212 [09:05<00:10, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73872/75212 [09:05<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73886/75212 [09:05<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73900/75212 [09:06<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73914/75212 [09:06<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73928/75212 [09:06<00:09, 135.34it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73942/75212 [09:06<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73956/75212 [09:06<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73970/75212 [09:06<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73984/75212 [09:06<00:09, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 73998/75212 [09:06<00:08, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74012/75212 [09:06<00:08, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74026/75212 [09:07<00:08, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74040/75212 [09:07<00:08, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74054/75212 [09:07<00:08, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74068/75212 [09:07<00:08, 135.35it/s][A[A

Selecting Coreset Indices.:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74082/75212 [09:07<00:08, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74096/75212 [09:07<00:08, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74110/75212 [09:07<00:08, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74124/75212 [09:07<00:08, 135.37it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74138/75212 [09:07<00:07, 135.37it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74152/75212 [09:07<00:07, 135.37it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74166/75212 [09:08<00:07, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74180/75212 [09:08<00:07, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74194/75212 [09:08<00:07, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74208/75212 [09:08<00:07, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74222/75212 [09:08<00:07, 135.37it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74236/75212 [09:08<00:07, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74250/75212 [09:08<00:07, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74264/75212 [09:08<00:07, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74278/75212 [09:08<00:06, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74292/75212 [09:08<00:06, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74306/75212 [09:09<00:06, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74320/75212 [09:09<00:06, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74334/75212 [09:09<00:06, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74348/75212 [09:09<00:06, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74362/75212 [09:09<00:06, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74376/75212 [09:09<00:06, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74390/75212 [09:09<00:06, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74404/75212 [09:09<00:05, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74418/75212 [09:09<00:05, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74432/75212 [09:10<00:05, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74446/75212 [09:10<00:05, 135.33it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74460/75212 [09:10<00:05, 135.33it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74474/75212 [09:10<00:05, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74488/75212 [09:10<00:05, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74502/75212 [09:10<00:05, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74516/75212 [09:10<00:05, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74530/75212 [09:10<00:05, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74544/75212 [09:10<00:04, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74558/75212 [09:10<00:04, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74572/75212 [09:11<00:04, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74586/75212 [09:11<00:04, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74600/75212 [09:11<00:04, 135.33it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74614/75212 [09:11<00:04, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74628/75212 [09:11<00:04, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74642/75212 [09:11<00:04, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74656/75212 [09:11<00:04, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74670/75212 [09:11<00:04, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74684/75212 [09:11<00:03, 135.36it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74698/75212 [09:11<00:03, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74712/75212 [09:12<00:03, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74726/75212 [09:12<00:03, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74740/75212 [09:12<00:03, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74754/75212 [09:12<00:03, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74768/75212 [09:12<00:03, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74782/75212 [09:12<00:03, 135.34it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74796/75212 [09:12<00:03, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74810/75212 [09:12<00:02, 135.35it/s][A[A

Selecting Coreset Indices.:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74824/75212 [09:12<00:02, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74838/75212 [09:13<00:02, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74852/75212 [09:13<00:02, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74866/75212 [09:13<00:02, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74880/75212 [09:13<00:02, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74894/75212 [09:13<00:02, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74908/75212 [09:13<00:02, 135.33it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74922/75212 [09:13<00:02, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74936/75212 [09:13<00:02, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74950/75212 [09:13<00:01, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74964/75212 [09:13<00:01, 135.36it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74978/75212 [09:14<00:01, 135.36it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 74992/75212 [09:14<00:01, 135.36it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75006/75212 [09:14<00:01, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75020/75212 [09:14<00:01, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75034/75212 [09:14<00:01, 135.36it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75048/75212 [09:14<00:01, 135.36it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75062/75212 [09:14<00:01, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75076/75212 [09:14<00:01, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75090/75212 [09:14<00:00, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75104/75212 [09:14<00:00, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75118/75212 [09:15<00:00, 135.36it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75132/75212 [09:15<00:00, 135.36it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75146/75212 [09:15<00:00, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75160/75212 [09:15<00:00, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75174/75212 [09:15<00:00, 135.34it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75188/75212 [09:15<00:00, 135.35it/s][A[A

Selecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75202/75212 [09:15<00:00, 135.35it/s][A[ASelecting Coreset Indices.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75212/75212 [09:15<00:00, 135.32it/s]

Validation:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s][A
Validation DataLoader 0:   4%|â–         | 1/26 [00:00<00:03,  6.40it/s][A
Validation DataLoader 0:   8%|â–Š         | 2/26 [00:00<00:02,  8.80it/s][A
Validation DataLoader 0:  12%|â–ˆâ–        | 3/26 [00:00<00:03,  7.03it/s][A
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 4/26 [00:00<00:04,  5.17it/s][A
Validation DataLoader 0:  19%|â–ˆâ–‰        | 5/26 [00:01<00:04,  4.45it/s][A
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 6/26 [00:01<00:04,  4.05it/s][A
Validation DataLoader 0:  27%|â–ˆâ–ˆâ–‹       | 7/26 [00:01<00:04,  3.81it/s][A
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 8/26 [00:02<00:04,  3.64it/s][A
Validation DataLoader 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 9/26 [00:02<00:04,  3.52it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 10/26 [00:02<00:04,  3.44it/s][A
Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/26 [00:03<00:04,  3.36it/s][A
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/26 [00:03<00:04,  3.31it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 13/26 [00:03<00:03,  3.34it/s][A
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/26 [00:04<00:03,  3.42it/s][A
Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 15/26 [00:04<00:03,  3.50it/s][A
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/26 [00:04<00:02,  3.57it/s][A
Validation DataLoader 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 17/26 [00:04<00:02,  3.64it/s][A
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 18/26 [00:04<00:02,  3.70it/s][A
Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 19/26 [00:05<00:01,  3.75it/s][A
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 20/26 [00:05<00:01,  3.80it/s][A
Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 21/26 [00:05<00:01,  3.85it/s][A
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/26 [00:05<00:01,  3.90it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 23/26 [00:05<00:00,  3.94it/s][A
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 24/26 [00:06<00:00,  3.98it/s][A
Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 25/26 [00:06<00:00,  4.02it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:06<00:00,  4.15it/s][Aâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:161 in <module>    â”‚
â”‚                                                                              â”‚
â”‚   158 â”‚   â”‚   print("Image AUROC: {}, Pixel AUPRO: {}".format(image_AUROC, p â”‚
â”‚   159                                                                        â”‚
â”‚   160 if __name__ == '__main__':                                             â”‚
â”‚ â± 161 â”‚   main()                                                             â”‚
â”‚   162 â”‚   torch.cuda.empty_cache()                                           â”‚
â”‚   163                                                                        â”‚
â”‚   164                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/runner.py:137 in main        â”‚
â”‚                                                                              â”‚
â”‚   134 â”‚                                                                      â”‚
â”‚   135 â”‚   # start training                                                   â”‚
â”‚   136 â”‚   engine = Engine(accelerator=args.gpu_type,task=TaskType.SEGMENTATI â”‚
â”‚ â± 137 â”‚   engine.fit(model=model, datamodule=datamodule)                     â”‚
â”‚   138 â”‚                                                                      â”‚
â”‚   139 â”‚   # load best model from checkpoint before evaluating                â”‚
â”‚   140 â”‚   test_results = engine.test(                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/engine/engine.p â”‚
â”‚ y:549 in fit                                                                 â”‚
â”‚                                                                              â”‚
â”‚    546 â”‚   â”‚   â”‚   # if the model is zero-shot or few-shot, we only need to  â”‚
â”‚    547 â”‚   â”‚   â”‚   self.trainer.validate(model, val_dataloaders, datamodule= â”‚
â”‚    548 â”‚   â”‚   else:                                                         â”‚
â”‚ â±  549 â”‚   â”‚   â”‚   self.trainer.fit(model, train_dataloaders, val_dataloader â”‚
â”‚    550 â”‚                                                                     â”‚
â”‚    551 â”‚   def validate(                                                     â”‚
â”‚    552 â”‚   â”‚   self,                                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:538 in fit              â”‚
â”‚                                                                              â”‚
â”‚    535 â”‚   â”‚   self.state.fn = TrainerFn.FITTING                             â”‚
â”‚    536 â”‚   â”‚   self.state.status = TrainerStatus.RUNNING                     â”‚
â”‚    537 â”‚   â”‚   self.training = True                                          â”‚
â”‚ â±  538 â”‚   â”‚   call._call_and_handle_interrupt(                              â”‚
â”‚    539 â”‚   â”‚   â”‚   self, self._fit_impl, model, train_dataloaders, val_datal â”‚
â”‚    540 â”‚   â”‚   )                                                             â”‚
â”‚    541                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/call.py:47 in                      â”‚
â”‚ _call_and_handle_interrupt                                                   â”‚
â”‚                                                                              â”‚
â”‚    44 â”‚   try:                                                               â”‚
â”‚    45 â”‚   â”‚   if trainer.strategy.launcher is not None:                      â”‚
â”‚    46 â”‚   â”‚   â”‚   return trainer.strategy.launcher.launch(trainer_fn, *args, â”‚
â”‚ â±  47 â”‚   â”‚   return trainer_fn(*args, **kwargs)                             â”‚
â”‚    48 â”‚                                                                      â”‚
â”‚    49 â”‚   except _TunerExitException:                                        â”‚
â”‚    50 â”‚   â”‚   _call_teardown_hook(trainer)                                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:574 in _fit_impl        â”‚
â”‚                                                                              â”‚
â”‚    571 â”‚   â”‚   â”‚   model_provided=True,                                      â”‚
â”‚    572 â”‚   â”‚   â”‚   model_connected=self.lightning_module is not None,        â”‚
â”‚    573 â”‚   â”‚   )                                                             â”‚
â”‚ â±  574 â”‚   â”‚   self._run(model, ckpt_path=ckpt_path)                         â”‚
â”‚    575 â”‚   â”‚                                                                 â”‚
â”‚    576 â”‚   â”‚   assert self.state.stopped                                     â”‚
â”‚    577 â”‚   â”‚   self.training = False                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:981 in _run             â”‚
â”‚                                                                              â”‚
â”‚    978 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    979 â”‚   â”‚   # RUN THE TRAINER                                             â”‚
â”‚    980 â”‚   â”‚   # ----------------------------                                â”‚
â”‚ â±  981 â”‚   â”‚   results = self._run_stage()                                   â”‚
â”‚    982 â”‚   â”‚                                                                 â”‚
â”‚    983 â”‚   â”‚   # ----------------------------                                â”‚
â”‚    984 â”‚   â”‚   # POST-Training CLEAN UP                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/trainer.py:1025 in _run_stage      â”‚
â”‚                                                                              â”‚
â”‚   1022 â”‚   â”‚   â”‚   with isolate_rng():                                       â”‚
â”‚   1023 â”‚   â”‚   â”‚   â”‚   self._run_sanity_check()                              â”‚
â”‚   1024 â”‚   â”‚   â”‚   with torch.autograd.set_detect_anomaly(self._detect_anoma â”‚
â”‚ â± 1025 â”‚   â”‚   â”‚   â”‚   self.fit_loop.run()                                   â”‚
â”‚   1026 â”‚   â”‚   â”‚   return None                                               â”‚
â”‚   1027 â”‚   â”‚   raise RuntimeError(f"Unexpected state {self.state}")          â”‚
â”‚   1028                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:205 in run               â”‚
â”‚                                                                              â”‚
â”‚   202 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   203 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   204 â”‚   â”‚   â”‚   â”‚   self.on_advance_start()                                â”‚
â”‚ â± 205 â”‚   â”‚   â”‚   â”‚   self.advance()                                         â”‚
â”‚   206 â”‚   â”‚   â”‚   â”‚   self.on_advance_end()                                  â”‚
â”‚   207 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   208 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/fit_loop.py:363 in advance           â”‚
â”‚                                                                              â”‚
â”‚   360 â”‚   â”‚   â”‚   )                                                          â”‚
â”‚   361 â”‚   â”‚   with self.trainer.profiler.profile("run_training_epoch"):      â”‚
â”‚   362 â”‚   â”‚   â”‚   assert self._data_fetcher is not None                      â”‚
â”‚ â± 363 â”‚   â”‚   â”‚   self.epoch_loop.run(self._data_fetcher)                    â”‚
â”‚   364 â”‚                                                                      â”‚
â”‚   365 â”‚   def on_advance_end(self) -> None:                                  â”‚
â”‚   366 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:141 in run    â”‚
â”‚                                                                              â”‚
â”‚   138 â”‚   â”‚   while not self.done:                                           â”‚
â”‚   139 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self.advance(data_fetcher)                             â”‚
â”‚ â± 141 â”‚   â”‚   â”‚   â”‚   self.on_advance_end(data_fetcher)                      â”‚
â”‚   142 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   143 â”‚   â”‚   â”‚   except StopIteration:                                      â”‚
â”‚   144 â”‚   â”‚   â”‚   â”‚   break                                                  â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/training_epoch_loop.py:295 in        â”‚
â”‚ on_advance_end                                                               â”‚
â”‚                                                                              â”‚
â”‚   292 â”‚   â”‚   â”‚   â”‚   # clear gradients to not leave any unused memory durin â”‚
â”‚   293 â”‚   â”‚   â”‚   â”‚   call._call_lightning_module_hook(self.trainer, "on_val â”‚
â”‚   294 â”‚   â”‚   â”‚                                                              â”‚
â”‚ â± 295 â”‚   â”‚   â”‚   self.val_loop.run()                                        â”‚
â”‚   296 â”‚   â”‚   â”‚   self.trainer.training = True                               â”‚
â”‚   297 â”‚   â”‚   â”‚   self.trainer._logger_connector._first_loop_iter = first_lo â”‚
â”‚   298                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/utilities.py:178 in _decorator       â”‚
â”‚                                                                              â”‚
â”‚   175 â”‚   â”‚   else:                                                          â”‚
â”‚   176 â”‚   â”‚   â”‚   context_manager = torch.no_grad                            â”‚
â”‚   177 â”‚   â”‚   with context_manager():                                        â”‚
â”‚ â± 178 â”‚   â”‚   â”‚   return loop_run(self, *args, **kwargs)                     â”‚
â”‚   179 â”‚                                                                      â”‚
â”‚   180 â”‚   return _decorator                                                  â”‚
â”‚   181                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:142 in run        â”‚
â”‚                                                                              â”‚
â”‚   139 â”‚   â”‚   â”‚   finally:                                                   â”‚
â”‚   140 â”‚   â”‚   â”‚   â”‚   self._restarting = False                               â”‚
â”‚   141 â”‚   â”‚   self._store_dataloader_outputs()                               â”‚
â”‚ â± 142 â”‚   â”‚   return self.on_run_end()                                       â”‚
â”‚   143 â”‚                                                                      â”‚
â”‚   144 â”‚   def setup_data(self) -> None:                                      â”‚
â”‚   145 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:254 in on_run_end â”‚
â”‚                                                                              â”‚
â”‚   251 â”‚   â”‚   self.trainer._logger_connector._evaluation_epoch_end()         â”‚
â”‚   252 â”‚   â”‚                                                                  â”‚
â”‚   253 â”‚   â”‚   # hook                                                         â”‚
â”‚ â± 254 â”‚   â”‚   self._on_evaluation_epoch_end()                                â”‚
â”‚   255 â”‚   â”‚                                                                  â”‚
â”‚   256 â”‚   â”‚   logged_outputs, self._logged_outputs = self._logged_outputs, [ â”‚
â”‚   257 â”‚   â”‚   # include any logged outputs on epoch_end                      â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/loops/evaluation_loop.py:336 in            â”‚
â”‚ _on_evaluation_epoch_end                                                     â”‚
â”‚                                                                              â”‚
â”‚   333 â”‚   â”‚   call._call_callback_hooks(trainer, hook_name)                  â”‚
â”‚   334 â”‚   â”‚   call._call_lightning_module_hook(trainer, hook_name)           â”‚
â”‚   335 â”‚   â”‚                                                                  â”‚
â”‚ â± 336 â”‚   â”‚   trainer._logger_connector.on_epoch_end()                       â”‚
â”‚   337 â”‚                                                                      â”‚
â”‚   338 â”‚   def _store_dataloader_outputs(self) -> None:                       â”‚
â”‚   339 â”‚   â”‚   trainer = self.trainer                                         â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:195 in on_epoch_end                                            â”‚
â”‚                                                                              â”‚
â”‚   192 â”‚                                                                      â”‚
â”‚   193 â”‚   def on_epoch_end(self) -> None:                                    â”‚
â”‚   194 â”‚   â”‚   assert self._first_loop_iter is None                           â”‚
â”‚ â± 195 â”‚   â”‚   metrics = self.metrics                                         â”‚
â”‚   196 â”‚   â”‚   self._progress_bar_metrics.update(metrics["pbar"])             â”‚
â”‚   197 â”‚   â”‚   self._callback_metrics.update(metrics["callback"])             â”‚
â”‚   198 â”‚   â”‚   self._logged_metrics.update(metrics["log"])                    â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger â”‚
â”‚ _connector.py:234 in metrics                                                 â”‚
â”‚                                                                              â”‚
â”‚   231 â”‚   â”‚   """This function returns either batch or epoch metrics."""     â”‚
â”‚   232 â”‚   â”‚   on_step = self._first_loop_iter is not None                    â”‚
â”‚   233 â”‚   â”‚   assert self.trainer._results is not None                       â”‚
â”‚ â± 234 â”‚   â”‚   return self.trainer._results.metrics(on_step)                  â”‚
â”‚   235 â”‚                                                                      â”‚
â”‚   236 â”‚   @property                                                          â”‚
â”‚   237 â”‚   def callback_metrics(self) -> _OUT_DICT:                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:473 in metrics                                                           â”‚
â”‚                                                                              â”‚
â”‚   470 â”‚   â”‚                                                                  â”‚
â”‚   471 â”‚   â”‚   for _, result_metric in self.valid_items():                    â”‚
â”‚   472 â”‚   â”‚   â”‚   # extract forward_cache or computed from the _ResultMetric â”‚
â”‚ â± 473 â”‚   â”‚   â”‚   value = self._get_cache(result_metric, on_step)            â”‚
â”‚   474 â”‚   â”‚   â”‚   if not isinstance(value, Tensor):                          â”‚
â”‚   475 â”‚   â”‚   â”‚   â”‚   continue                                               â”‚
â”‚   476                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:437 in _get_cache                                                        â”‚
â”‚                                                                              â”‚
â”‚   434 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   " devices.",                                   â”‚
â”‚   435 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   category=PossibleUserWarning,                  â”‚
â”‚   436 â”‚   â”‚   â”‚   â”‚   â”‚   )                                                  â”‚
â”‚ â± 437 â”‚   â”‚   â”‚   â”‚   result_metric.compute()                                â”‚
â”‚   438 â”‚   â”‚   â”‚   â”‚   result_metric.meta.sync.should = should                â”‚
â”‚   439 â”‚   â”‚   â”‚                                                              â”‚
â”‚   440 â”‚   â”‚   â”‚   cache = result_metric._computed                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:288 in wrapped_func                                                      â”‚
â”‚                                                                              â”‚
â”‚   285 â”‚   â”‚   â”‚   # return cached value                                      â”‚
â”‚   286 â”‚   â”‚   â”‚   if self._computed is not None:                             â”‚
â”‚   287 â”‚   â”‚   â”‚   â”‚   return self._computed                                  â”‚
â”‚ â± 288 â”‚   â”‚   â”‚   self._computed = compute(*args, **kwargs)                  â”‚
â”‚   289 â”‚   â”‚   â”‚   return self._computed                                      â”‚
â”‚   290 â”‚   â”‚                                                                  â”‚
â”‚   291 â”‚   â”‚   return wrapped_func                                            â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result â”‚
â”‚ .py:253 in compute                                                           â”‚
â”‚                                                                              â”‚
â”‚   250 â”‚   â”‚   â”‚   â”‚   cumulated_batch_size = self.meta.sync(self.cumulated_b â”‚
â”‚   251 â”‚   â”‚   â”‚   â”‚   return value / cumulated_batch_size                    â”‚
â”‚   252 â”‚   â”‚   â”‚   return value                                               â”‚
â”‚ â± 253 â”‚   â”‚   return self.value.compute()                                    â”‚
â”‚   254 â”‚                                                                      â”‚
â”‚   255 â”‚   @override                                                          â”‚
â”‚   256 â”‚   def reset(self) -> None:                                           â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/metric.py:700 in wrapped_func                   â”‚
â”‚                                                                              â”‚
â”‚    697 â”‚   â”‚   â”‚   â”‚   should_sync=self._to_sync,                            â”‚
â”‚    698 â”‚   â”‚   â”‚   â”‚   should_unsync=self._should_unsync,                    â”‚
â”‚    699 â”‚   â”‚   â”‚   ):                                                        â”‚
â”‚ â±  700 â”‚   â”‚   â”‚   â”‚   value = _squeeze_if_scalar(compute(*args, **kwargs))  â”‚
â”‚    701 â”‚   â”‚   â”‚   â”‚   # clone tensor to avoid in-place operations after com â”‚
â”‚    702 â”‚   â”‚   â”‚   â”‚   value = apply_to_collection(value, Tensor, lambda x:  â”‚
â”‚    703                                                                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:241 in compute                                                             â”‚
â”‚                                                                              â”‚
â”‚   238 â”‚   â”‚   Returns:                                                       â”‚
â”‚   239 â”‚   â”‚   â”‚   Tensor: Value of the AUPRO metric                          â”‚
â”‚   240 â”‚   â”‚   """                                                            â”‚
â”‚ â± 241 â”‚   â”‚   fpr, tpr = self._compute()                                     â”‚
â”‚   242 â”‚   â”‚                                                                  â”‚
â”‚   243 â”‚   â”‚   aupro = auc(fpr, tpr, reorder=True)                            â”‚
â”‚   244 â”‚   â”‚   return aupro / fpr[-1]  # normalize the area                   â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:229 in _compute                                                            â”‚
â”‚                                                                              â”‚
â”‚   226 â”‚   â”‚   Returns:                                                       â”‚
â”‚   227 â”‚   â”‚   â”‚   tuple[torch.Tensor, torch.Tensor]: tuple containing final  â”‚
â”‚   228 â”‚   â”‚   """                                                            â”‚
â”‚ â± 229 â”‚   â”‚   cca = self.perform_cca().flatten()                             â”‚
â”‚   230 â”‚   â”‚   target = dim_zero_cat(self.target).flatten()                   â”‚
â”‚   231 â”‚   â”‚   preds = dim_zero_cat(self.preds).flatten()                     â”‚
â”‚   232                                                                        â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/anomalib/src/anomalib/metrics/aupro.p â”‚
â”‚ y:108 in perform_cca                                                         â”‚
â”‚                                                                              â”‚
â”‚   105 â”‚   â”‚   Returns:                                                       â”‚
â”‚   106 â”‚   â”‚   â”‚   Tensor: Components labeled from 0 to N.                    â”‚
â”‚   107 â”‚   â”‚   """                                                            â”‚
â”‚ â± 108 â”‚   â”‚   target = dim_zero_cat(self.target)                             â”‚
â”‚   109 â”‚   â”‚                                                                  â”‚
â”‚   110 â”‚   â”‚   # check and prepare target for labeling via kornia             â”‚
â”‚   111 â”‚   â”‚   if target.min() < 0 or target.max() > 1:                       â”‚
â”‚                                                                              â”‚
â”‚ /cw/dtaijupiter/NoCsBack/dtai/mariette/miniconda3/envs/new_env/lib/python3.1 â”‚
â”‚ 0/site-packages/torchmetrics/utilities/data.py:36 in dim_zero_cat            â”‚
â”‚                                                                              â”‚
â”‚    33 â”‚   x = [y.unsqueeze(0) if y.numel() == 1 and y.ndim == 0 else y for y â”‚
â”‚    34 â”‚   if not x:  # empty list                                            â”‚
â”‚    35 â”‚   â”‚   raise ValueError("No samples to concatenate")                  â”‚
â”‚ â±  36 â”‚   return torch.cat(x, dim=0)                                         â”‚
â”‚    37                                                                        â”‚
â”‚    38                                                                        â”‚
â”‚    39 def dim_zero_sum(x: Tensor) -> Tensor:                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [09:46<00:00,  0.19it/s]

                                                                        [A